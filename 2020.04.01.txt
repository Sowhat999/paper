==========New Papers==========
1, TITLE:       Recognizing Characters in Art History Using Deep Learning
http://arxiv.org/abs/2003.14171
AUTHORS:        Prathmesh Madhu ; Ronak Kosti ; Lara Mührenberg ; Peter Bell ; Andreas Maier ; Vincent Christlein
HIGHLIGHT:      In this paper, we focus on the problem of recognizing the characters in Art History.

2, TITLE:       Look-into-Object: Self-supervised Structure Modeling for Object Recognition
http://arxiv.org/abs/2003.14142
AUTHORS:        Mohan Zhou ; Yalong Bai ; Wei Zhang ; Tiejun Zhao ; Tao Mei
COMMENTS:       10 pages, 7 figures, accepted by CVPR 2020
HIGHLIGHT:      In this paper, we propose to "look into object" (explicitly yet intrinsically model the object structure) through incorporating self-supervisions into the traditional framework.

3, TITLE:       Learning Cross-domain Semantic-Visual Relation for Transductive Zero-Shot Learning
http://arxiv.org/abs/2003.14105
AUTHORS:        Jianyang Zhang ; Fengmao Lv ; Guowu Yang ; Lei Feng ; Yufeng Yu ; Lixin Duan
HIGHLIGHT:      In this work, we propose a novel approach dubbed Transferrable Semantic-Visual Relation (TSVR) to facilitate the cross-category transfer in transductive ZSL.

4, TITLE:       Disentangling and Unifying Graph Convolutions for Skeleton-Based Action Recognition
http://arxiv.org/abs/2003.14111
AUTHORS:        Ziyu Liu ; Hongwen Zhang ; Zhenghao Chen ; Zhiyong Wang ; Wanli Ouyang
COMMENTS:       CVPR 2020
HIGHLIGHT:      In this work, we present (1) a simple method to disentangle multi-scale graph convolutions and (2) a unified spatial-temporal graph convolutional operator named G3D.

5, TITLE:       Attention-based Assisted Excitation for Salient Object Segmentation
http://arxiv.org/abs/2003.14194
AUTHORS:        Saeed Masoudnia ; Melika Kheirieh ; Abdol-Hossein Vahabie ; Babak Nadjar-Araabi
HIGHLIGHT:      In this paper, object-based attention in human visual cortex inspires us to introduce a mechanism for modification of activations in feature maps of CNNs.

6, TITLE:       Real-Time Camera Pose Estimation for Sports Fields
http://arxiv.org/abs/2003.14109
AUTHORS:        Leonardo Citraro ; Pablo Márquez-Neila ; Stefano Savarè ; Vivek Jayaram ; Charles Dubout ; Félix Renaut ; Andrés Hasfura ; Horesh Ben Shitrit ; Pascal Fua
HIGHLIGHT:      To this end, we propose a novel framework that combines accurate localization and robust identification of specific keypoints in the image by using a fully convolutional deep architecture.

7, TITLE:       AvatarMe: Realistically Renderable 3D Facial Reconstruction "in-the-wild"
http://arxiv.org/abs/2003.13845
AUTHORS:        Alexandros Lattas ; Stylianos Moschoglou ; Baris Gecer ; Stylianos Ploumpis ; Vasileios Triantafyllou ; Abhijeet Ghosh ; Stefanos Zafeiriou
COMMENTS:       Accepted to CVPR2020. Project page: github.com/lattas/AvatarMe with high resolution results, data and more. 10 pages, 9 figures
HIGHLIGHT:      In this paper, we introduce AvatarMe, the first method that is able to reconstruct photorealistic 3D faces from a single "in-the-wild" image with an increasing level of detail.

8, TITLE:       When to Use Convolutional Neural Networks for Inverse Problems
http://arxiv.org/abs/2003.13820
AUTHORS:        Nathaniel Chodosh ; Simon Lucey
COMMENTS:       CVPR 2020 Poster
HIGHLIGHT:      In this work we argue that for some types of inverse problems the CNN approximation breaks down leading to poor performance.

9, TITLE:       Label-Efficient Learning on Point Clouds using Approximate Convex Decompositions
http://arxiv.org/abs/2003.13834
AUTHORS:        Matheus Gadelha ; Aruni RoyChowdhury ; Gopal Sharma ; Evangelos Kalogerakis ; Liangliang Cao ; Erik Learned-Miller ; Rui Wang ; Subhransu Maji
COMMENTS:       18 pages, 5 figures
HIGHLIGHT:      In this work, we investigate the use of Approximate Convex Decompositions (ACD) as a self-supervisory signal for label-efficient learning of point cloud representations.

10, TITLE:      Sign Language Transformers: Joint End-to-end Sign Language Recognition and Translation
http://arxiv.org/abs/2003.13830
AUTHORS:        Necati Cihan Camgoz ; Oscar Koller ; Simon Hadfield ; Richard Bowden
HIGHLIGHT:      We introduce a novel transformer based architecture that jointly learns Continuous Sign Language Recognition and Translation while being trainable in an end-to-end manner.

11, TITLE:      ActGAN: Flexible and Efficient One-shot Face Reenactment
http://arxiv.org/abs/2003.13840
AUTHORS:        Ivan Kosarevych ; Marian Petruk ; Markian Kostiv ; Orest Kupyn ; Mykola Maksymenko ; Volodymyr Budzan
COMMENTS:       accepted by IWBF2020
HIGHLIGHT:      This paper introduces ActGAN - a novel end-to-end generative adversarial network (GAN) for one-shot face reenactment.

12, TITLE:      Co-occurrence of deep convolutional features for image search
http://arxiv.org/abs/2003.13827
AUTHORS:        J. I. Forcen ; Miguel Pagola ; Edurne Barrenechea ; Humberto Bustince
HIGHLIGHT:      We present two different methods to get the co-occurrence representation, the first one based on direct aggregation of activations, and the second one, based on a trainable co-occurrence representation.

13, TITLE:      Explaining Motion Relevance for Activity Recognition in Video Deep Learning Models
http://arxiv.org/abs/2003.14285
AUTHORS:        Liam Hiley ; Alun Preece ; Yulia Hicks ; Supriyo Chakraborty ; Prudhvi Gurram ; Richard Tomsett
HIGHLIGHT:      We propose a selective relevance method for adapting the 2D explanation techniques to provide motion-specific explanations, better aligning them with the human understanding of motion as conceptually separate from static spatial features.

14, TITLE:      Learning from Small Data Through Sampling an Implicit Conditional Generative Latent Optimization Model
http://arxiv.org/abs/2003.14297
AUTHORS:        Idan Azuri ; Daphna Weinshall
COMMENTS:       10 pages, 6 figures
HIGHLIGHT:      We propose a new model based on conditional Generative Latent Optimization (cGLO).

15, TITLE:      HATSUKI : An anime character like robot figure platform with anime-style expressions and imitation learning based action generation
http://arxiv.org/abs/2003.14121
AUTHORS:        Pin-Chu Yang ; Mohammed Al-Sada ; Chang-Chieh Chiu ; Kevin Kuo ; Tito Pradhono Tomo ; Kanata Suzuki ; Nelson Yalta ; Kuo-Hao Shu ; Tetsuya Ogata
COMMENTS:       8 pages, 11 figures, submitted to Ro-MAN 2020
HIGHLIGHT:      We explain our design implementation process of Hatsuki, followed by our evaluations.

16, TITLE:      Take the Scenic Route: Improving Generalization in Vision-and-Language Navigation
http://arxiv.org/abs/2003.14269
AUTHORS:        Felix Yu ; Zhiwei Deng ; Karthik Narasimhan ; Olga Russakovsky
COMMENTS:       4 page short paper
HIGHLIGHT:      In this work, we investigate the popular Room-to-Room (R2R) VLN benchmark and discover that what is important is not only the amount of data you synthesize, but also how you do it.

17, TITLE:      Straight to the Point: Fast-forwarding Videos via Reinforcement Learning Using Textual Data
http://arxiv.org/abs/2003.14229
AUTHORS:        Washington Ramos ; Michel Silva ; Edson Araujo ; Leandro Soriano Marcolino ; Erickson Nascimento
COMMENTS:       CVPR 2020
HIGHLIGHT:      In this paper, we present a novel methodology based on a reinforcement learning formulation to accelerate instructional videos.

18, TITLE:      DISIR: Deep Image Segmentation with Interactive Refinement
http://arxiv.org/abs/2003.14200
AUTHORS:        Gaston Lenczner ; Bertrand Le Saux ; Nicola Luminari ; Adrien Chan Hon Tong ; Guy Le Besnerais
COMMENTS:       8 pages, 12 figures. Accepted for publication in the ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences
HIGHLIGHT:      This paper presents an interactive approach for multi-class segmentation of aerial images.

19, TITLE:      Real-Time Semantic Segmentation via Auto Depth, Downsampling Joint Decision and Feature Aggregation
http://arxiv.org/abs/2003.14226
AUTHORS:        Peng Sun ; Jiaxiang Wu ; Songyuan Li ; Peiwen Lin ; Junzhou Huang ; Xi Li
COMMENTS:       submitted to IJCV
HIGHLIGHT:      In this paper, we propose a joint search framework, called AutoRTNet, to automate the design of these strategies.

20, TITLE:      SCT: Set Constrained Temporal Transformer for Set Supervised Action Segmentation
http://arxiv.org/abs/2003.14266
AUTHORS:        Mohsen Fayyaz ; Juergen Gall
COMMENTS:       CVPR 2020
HIGHLIGHT:      In order to address this task, we propose an approach that can be trained end-to-end on such data.

21, TITLE:      DPGN: Distribution Propagation Graph Network for Few-shot Learning
http://arxiv.org/abs/2003.14247
AUTHORS:        Ling Yang ; Liangliang Li ; Zilun Zhang ;  Zhou ; Erjin Zhou ; Yu Liu
COMMENTS:       Accepted by CVPR 2020
HIGHLIGHT:      We propose a novel approach named distribution propagation graph network (DPGN) for few-shot learning.

22, TITLE:      MUXConv: Information Multiplexing in Convolutional Neural Networks
http://arxiv.org/abs/2003.13880
AUTHORS:        Zhichao Lu ; Kalyanmoy Deb ; Vishnu Naresh Boddeti
COMMENTS:       CVPR 2020
HIGHLIGHT:      To overcome this limitation, we present MUXConv, a layer that is designed to increase the flow of information by progressively multiplexing channel and spatial information in the network, while mitigating computational complexity.

23, TITLE:      TITAN: Future Forecast using Action Priors
http://arxiv.org/abs/2003.13886
AUTHORS:        Srikanth Malla ; Behzad Dariush ; Chiho Choi
HIGHLIGHT:      In an attempt to address this problem, we introduce TITAN (Trajectory Inference using Targeted Action priors Network), a new model that incorporates prior positions, actions, and context to forecast future trajectory of agents and future ego-motion. In the absence of an appropriate dataset for this task, we created the TITAN dataset that consists of 700 labeled video-clips (with odometry) captured from a moving vehicle on highly interactive urban traffic scenes in Tokyo.

24, TITLE:      Edge Guided GANs with Semantic Preserving for Semantic Image Synthesis
http://arxiv.org/abs/2003.13898
AUTHORS:        Hao Tang ; Xiaojuan Qi ; Dan Xu ; Philip H. S. Torr ; Nicu Sebe
COMMENTS:       40 pages, 29 figures
HIGHLIGHT:      We propose a novel Edge guided Generative Adversarial Network (EdgeGAN) for photo-realistic image synthesis from semantic layouts.

25, TITLE:      Learning Oracle Attention for High-fidelity Face Completion
http://arxiv.org/abs/2003.13903
AUTHORS:        Tong Zhou ; Changxing Ding ; Shaowen Lin ; Xinchao Wang ; Dacheng Tao
COMMENTS:       Accepted to CVPR 2020
HIGHLIGHT:      Accordingly, in this paper, we design a comprehensive framework for face completion based on the U-Net structure.

26, TITLE:      Deep Molecular Programming: A Natural Implementation of Binary-Weight ReLU Neural Networks
http://arxiv.org/abs/2003.13720
AUTHORS:        Marko Vasic ; Cameron Chalk ; Sarfraz Khurshid ; David Soloveichik
HIGHLIGHT:      We discover a surprisingly tight connection between a popular class of neural networks (Binary-weight ReLU aka BinaryConnect) and a class of coupled chemical reactions that are absolutely robust to reaction rates.

27, TITLE:      The Operating System of the Neuromorphic BrainScaleS-1 System
http://arxiv.org/abs/2003.13749
AUTHORS:        Eric Müller ; Sebastian Schmitt ; Christian Mauch ; Sebastian Billaudelle ; Andreas Grübl ; Maurice Güttler ; Dan Husmann ; Joscha Ilmberger ; Sebastian Jeltsch ; Jakob Kaiser ; Johann Klähn ; Mitja Kleider ; Christoph Koke ; José Montes ; Paul Müller ; Johannes Partzsch ; Felix Passenberg ; Hartmut Schmidt ; Bernhard Vogginger ; Jonas Weidner ; Christian Mayr ; Johannes Schemmel
HIGHLIGHT:      We present operation and development methodologies implemented for the BrainScaleS-1 neuromorphic architecture and walk through the individual components of BrainScaleS OS constituting the software stack for BrainScaleS-1 platform operation.

28, TITLE:      Extending BrainScaleS OS for BrainScaleS-2
http://arxiv.org/abs/2003.13750
AUTHORS:        Eric Müller ; Christian Mauch ; Philipp Spilger ; Oliver Julien Breitwieser ; Johann Klähn ; David Stöckel ; Timo Wunderlich ; Johannes Schemmel
HIGHLIGHT:      We present and walk through the software-architectural enhancements that were introduced for the BrainScaleS-2 architecture.

29, TITLE:      Recurrent Neural Networks with Longitudinal Pooling and Consistency Regularization
http://arxiv.org/abs/2003.13958
AUTHORS:        Jiahong Ouyang ; Qingyu Zhao ; Edith V Sullivan ; Adolf Pfefferbaum ; Susan F. Tapert ; Ehsan Adeli ; Kilian M Pohl
COMMENTS:       Submitted to MICCAI 2020
HIGHLIGHT:      In this paper, we propose a framework that injects the extracted features from CNNs at each time point to the RNN cells considering the dependencies across different time points in the longitudinal data.

30, TITLE:      Supervised Raw Video Denoising with a Benchmark Dataset on Dynamic Scenes
http://arxiv.org/abs/2003.14013
AUTHORS:        Huanjing Yue ; Cong Cao ; Lei Liao ; Ronghe Chu ; Jingyu Yang
COMMENTS:       CVPR2020 accepted paper
HIGHLIGHT:      In this paper, we solve this problem by creating motions for controllable objects, such as toys, and capturing each static moment for multiple times to generate clean video frames. In this way, we construct a dataset with 55 groups of noisy-clean videos with ISO values ranging from 1600 to 25600.

31, TITLE:      Pathological Retinal Region Segmentation From OCT Images Using Geometric Relation Based Augmentation
http://arxiv.org/abs/2003.14119
AUTHORS:        Dwarikanath Mahapatra ; Behzad Bozorgtabar ; Jean-Philippe Thiran ; Ling Shao
COMMENTS:       Accepted to CVPR 2020
HIGHLIGHT:      We propose improvements over previous GAN-based medical image synthesis methods by jointly encoding the intrinsic relationship of geometry and shape.

32, TITLE:      A Thorough Comparison Study on Adversarial Attacks and Defenses for Common Thorax Disease Classification in Chest X-rays
http://arxiv.org/abs/2003.13969
AUTHORS:        Chendi Rao ; Jiezhang Cao ; Runhao Zeng ; Qi Chen ; Huazhu Fu ; Yanwu Xu ; Mingkui Tan
HIGHLIGHT:      In this paper, we aim to review various adversarial attack and defense methods on chest X-rays.

33, TITLE:      UniformAugment: A Search-free Probabilistic Data Augmentation Approach
http://arxiv.org/abs/2003.14348
AUTHORS:        Tom Ching LingChen ; Ava Khonsari ; Amirreza Lashkari ; Mina Rafi Nazari ; Jaspreet Singh Sambee ; Mario A. Nascimento
HIGHLIGHT:      In this paper we show that, under the assumption that the augmentation space is approximately distribution invariant, a uniform sampling over the continuous space of augmentation transformations is sufficient to train highly effective models.

34, TITLE:      TransMoMo: Invariance-Driven Unsupervised Video Motion Retargeting
http://arxiv.org/abs/2003.14401
AUTHORS:        Zhuoqian Yang ; Wentao Zhu ; Wayne Wu ; Chen Qian ; Qiang Zhou ; Bolei Zhou ; Chen Change Loy
COMMENTS:       CVPR 2020
HIGHLIGHT:      We present a lightweight video motion retargeting approach TransMoMo that is capable of transferring motion of a person in a source video realistically to another video of a target person.

35, TITLE:      Du$^2$Net: Learning Depth Estimation from Dual-Cameras and Dual-Pixels
http://arxiv.org/abs/2003.14299
AUTHORS:        Yinda Zhang ; Neal Wadhwa ; Sergio Orts-Escolano ; Christian Häne ; Sean Fanello ; Rahul Garg
HIGHLIGHT:      We present a novel approach based on neural networks for depth estimation that combines stereo from dual cameras with stereo from a dual-pixel sensor, which is increasingly common on consumer cameras.

36, TITLE:      How Useful is Self-Supervised Pretraining for Visual Tasks?
http://arxiv.org/abs/2003.14323
AUTHORS:        Alejandro Newell ; Jia Deng
COMMENTS:       To appear in CVPR 2020
HIGHLIGHT:      To do this, we evaluate various self-supervised algorithms across a comprehensive array of synthetic datasets and downstream tasks.

37, TITLE:      Semi-supervised Learning for Few-shot Image-to-Image Translation
http://arxiv.org/abs/2003.13853
AUTHORS:        Yaxing Wang ; Salman Khan ; Abel Gonzalez-Garcia ; Joost van de Weijer ; Fahad Shahbaz Khan
COMMENTS:       CVPR2020
HIGHLIGHT:      In this work, we go one step further and reduce the amount of required labeled data also from the source domain during training.

38, TITLE:      3D-MPA: Multi Proposal Aggregation for 3D Semantic Instance Segmentation
http://arxiv.org/abs/2003.13867
AUTHORS:        Francis Engelmann ; Martin Bokeloh ; Alireza Fathi ; Bastian Leibe ; Matthias Nießner
COMMENTS:       CVPR2020, Video: https://youtu.be/ifL8yTbRFDk Project Page: https://www.vision.rwth-aachen.de/3d_instance_segmentation/
HIGHLIGHT:      We present 3D-MPA, a method for instance segmentation on 3D point clouds.

39, TITLE:      Can Deep Learning Recognize Subtle Human Activities?
http://arxiv.org/abs/2003.13852
AUTHORS:        Vincent Jacquot ; Zhuofan Ying ; Gabriel Kreiman
COMMENTS:       poster at CVPR 2020, includes supplementary figures
HIGHLIGHT:      We propose a rigorous method to reduce confounds when creating datasets, and when comparing human versus computer vision performance. In this work, we propose a new action classification challenge that is performed well by humans, but poorly by state-of-the-art Deep Learning models.

40, TITLE:      RetinaTrack: Online Single Stage Joint Detection and Tracking
http://arxiv.org/abs/2003.13870
AUTHORS:        Zhichao Lu ; Vivek Rathod ; Ronny Votel ; Jonathan Huang
COMMENTS:       Accepted to CVPR 2020
HIGHLIGHT:      In this paper we focus on the tracking-by-detection paradigm for autonomous driving where both tasks are mission critical.

41, TITLE:      Initial Design Strategies and their Effects on Sequential Model-Based Optimization
http://arxiv.org/abs/2003.13826
AUTHORS:        Jakob Bossek ; Carola Doerr ; Pascal Kerschke
COMMENTS:       To appear in Proc. of ACM Genetic and Evolutionary Computation Conference (GECCO'20)
HIGHLIGHT:      We analyze in this work how the size and the distribution of the initial sample influences the overall quality of the efficient global optimization~(EGO) algorithm, a well-known SMBO approach.

42, TITLE:      Genetic Algorithmic Parameter Optimisation of a Recurrent Spiking Neural Network Model
http://arxiv.org/abs/2003.13850
AUTHORS:        Ifeatu Ezenwe ; Alok Joshi ; KongFatt Wong-Lin
COMMENTS:       6 pages, 6 figures
HIGHLIGHT:      In this work, we investigated the use of GAs to search for optimal parameters in recurrent SNNs to reach targeted neuronal population firing rates, e.g. as in experimental observations.

43, TITLE:      Anytime and Efficient Coalition Formation with Spatial and Temporal Constraints
http://arxiv.org/abs/2003.13806
AUTHORS:        Luca Capezzuto ; Danesh Tarapore ; Sarvapali D. Ramchurn
COMMENTS:       17 pages, 1 figure, accepted at EUMAS 2020
HIGHLIGHT:      Motivated by this, we propose an extension of CFLA, which we call Coalition Formation with Improved Look-Ahead (CFLA+).

44, TITLE:      Optimising Lockdown Policies for Epidemic Control using Reinforcement Learning
http://arxiv.org/abs/2003.14093
AUTHORS:        Harshad Khadilkar ; Tanuja Ganu ; Deva P Seetharam
HIGHLIGHT:      In this working paper, we present a quantitative way to compute lockdown decisions for individual cities or regions, while balancing health and economic considerations.

45, TITLE:      Enhanced Rolling Horizon Evolution Algorithm with Opponent Model Learning: Results for the Fighting Game AI Competition
http://arxiv.org/abs/2003.13949
AUTHORS:        Zhentao Tang ; Yuanheng Zhu ; Dongbin Zhao ; Simon M. Lucas
COMMENTS:       10 pages, 7 figures
HIGHLIGHT:      In this paper, we propose a novel algorithm that combines Rolling Horizon Evolution Algorithm (RHEA) with opponent model learning.

46, TITLE:      State-of-Art-Reviewing: A Radical Proposal to Improve Scientific Publication
http://arxiv.org/abs/2003.14415
AUTHORS:        Samuel Albanie ; Jaime Thewmore ; Robert McCraith ; Joao F. Henriques
COMMENTS:       SIGBOVIK 2020
HIGHLIGHT:      In this work, we answer this question in the negative (strong reject, high confidence) and propose instead State-Of-the-Art Review (SOAR), a neoteric reviewing pipeline that serves as a 'plug-and-play' replacement for peer review.

47, TITLE:      Mining International Political Norms from the GDELT Database
http://arxiv.org/abs/2003.14027
AUTHORS:        Rohit Murali ; Suravi Patnaik ; Stephen Cranefield
COMMENTS:       16 pages, 2 figures, pre-print for International Workshop on Coordination, Organizations, Institutions, Norms and Ethics for Governance of Multi-Agent Systems (COINE), co-located with AAMAS 2020
HIGHLIGHT:      This work investigates this issue in the context of international politics.

48, TITLE:      Artificial chemistry experiments with chemlambda, lambda calculus, interaction combinators
http://arxiv.org/abs/2003.14332
AUTHORS:        Marius Buliga
HIGHLIGHT:      Given a graph rewrite system, a graph G is a quine graph if it has a non-void maximal collection of non-conflicting matches of left patterns of graphs rewrites, such that after the parallel application of the rewrites we obtain a graph isomorphic with G.

49, TITLE:      Will we ever have Conscious Machines?
http://arxiv.org/abs/2003.14132
AUTHORS:        Patrick Krauss ; Andreas Maier
HIGHLIGHT:      We review the current state-of-the-art regarding these developments and investigate common machine learning approaches with respect to their potential ability to become self-aware.

50, TITLE:      3D Sketch-aware Semantic Scene Completion via Semi-supervised Structure Prior
http://arxiv.org/abs/2003.14052
AUTHORS:        Xiaokang Chen ; Kwan-Yee Lin ; Chen Qian ; Gang Zeng ; Hongsheng Li
COMMENTS:       Accepted by CVPR 2020
HIGHLIGHT:      In this paper, we propose to devise a new geometry-based strategy to embed depth information with low-resolution voxel representation, which could still be able to encode sufficient geometric information, e.g., room layout, object's sizes and shapes, to infer the invisible areas of the scene with well structure-preserving details.

51, TITLE:      X-Linear Attention Networks for Image Captioning
http://arxiv.org/abs/2003.14080
AUTHORS:        Yingwei Pan ; Ting Yao ; Yehao Li ; Tao Mei
COMMENTS:       CVPR 2020; The source code and model are publicly available at: https://github.com/Panda-Peter/image-captioning
HIGHLIGHT:      In this paper, we introduce a unified attention block -- X-Linear attention block, that fully employs bilinear pooling to selectively capitalize on visual information or perform multi-modal reasoning.

52, TITLE:      Inverting Gradients -- How easy is it to break privacy in federated learning?
http://arxiv.org/abs/2003.14053
AUTHORS:        Jonas Geiping ; Hartmut Bauermeister ; Hannah Dröge ; Michael Moeller
COMMENTS:       26 pages, 17 figures. The first three authors contributed equally
HIGHLIGHT:      In this paper we show that sharing parameter gradients is by no means secure: By exploiting a cosine similarity loss along with optimization methods from adversarial attacks, we are able to faithfully reconstruct images at high resolution from the knowledge of their parameter gradients, and demonstrate that such a break of privacy is possible even for trained deep networks.

53, TITLE:      Long Short-Term Relation Networks for Video Action Detection
http://arxiv.org/abs/2003.14065
AUTHORS:        Dong Li ; Ting Yao ; Zhaofan Qiu ; Houqiang Li ; Tao Mei
COMMENTS:       Accepted as a full paper for ACMMM 2019
HIGHLIGHT:      In this paper, we present a new Long Short-Term Relation Networks, dubbed as LSTR, that novelly aggregates and propagates relation to augment features for video action detection.

54, TITLE:      Prediction Confidence from Neighbors
http://arxiv.org/abs/2003.14047
AUTHORS:        Mark Philip Philipsen ; Thomas Baltzer Moeslund
COMMENTS:       work in progress
HIGHLIGHT:      We show that feature space distance is a meaningful measure that can provide confidence in predictions.

55, TITLE:      Parallelization of Monte Carlo Tree Search in Continuous Domains
http://arxiv.org/abs/2003.13741
AUTHORS:        Karl Kurzer ; Christoph Hörtnagl ; J. Marius Zöllner
HIGHLIGHT:      These studies focused on versions of MCTS for the discrete case.

56, TITLE:      The European Language Technology Landscape in 2020: Language-Centric and Human-Centric AI for Cross-Cultural Communication in Multilingual Europe
http://arxiv.org/abs/2003.13833
AUTHORS:        Georg Rehm ; Katrin Marheinecke ; Stefanie Hegele ; Stelios Piperidis ; Kalina Bontcheva ; Jan Hajič ; Khalid Choukri ; Andrejs Vasiļjevs ; Gerhard Backfried ; Christoph Prinz ; José Manuel Gómez Pérez ; Luc Meertens ; Paul Lukowicz ; Josef van Genabith ; Andrea Lösch ; Philipp Slusallek ; Morten Irgens ; Patrick Gatellier ; Joachim Köhler ; Laure Le Bars ; Dimitra Anastasiou ; Albina Auksoriūtė ; Núria Bel ; António Branco ; Gerhard Budin ; Walter Daelemans ; Koenraad De Smedt ; Radovan Garabík ; Maria Gavriilidou ; Dagmar Gromann ; Svetla Koeva ; Simon Krek ; Cvetana Krstev ; Krister Lindén ; Bernardo Magnini ; Jan Odijk ; Maciej Ogrodniczuk ; Eiríkur Rögnvaldsson ; Mike Rosner ; Bolette Sandford Pedersen ; Inguna Skadiņa ; Marko Tadić ; Dan Tufiş ; Tamás Váradi ; Kadri Vider ; Andy Way ; François Yvon
COMMENTS:       Proceedings of the 12th Language Resources and Evaluation Conference (LREC 2020). To appear
HIGHLIGHT:      We present an overview of the European LT landscape, describing funding programmes, activities, actions and challenges in the different countries with regard to LT, including the current state of play in industry and the LT market.

57, TITLE:      Appraisal Theories for Emotion Classification in Text
http://arxiv.org/abs/2003.14155
AUTHORS:        Jan Hofmann ; Enrica Troiano ; Kai Sassenberg ; Roman Klinger
HIGHLIGHT:      With this paper, we propose to make such interpretations of events explicit, following theories of cognitive appraisal of events and show their potential for emotion classification when being encoded in classification models.

58, TITLE:      Procedural Reading Comprehension with Attribute-Aware Context Flow
http://arxiv.org/abs/2003.13878
AUTHORS:        Aida Amini ; Antoine Bosselut ; Bhavana Dalvi Mishra ; Yejin Choi ; Hannaneh Hajishirzi
HIGHLIGHT:      In this paper, we introduce an algorithm for procedural reading comprehension by translating the text into a general formalism that represents processes as a sequence of transitions over entity attributes (e.g., location, temperature).

59, TITLE:      Understanding Cross-Lingual Syntactic Transfer in Multilingual Recurrent Neural Networks
http://arxiv.org/abs/2003.14056
AUTHORS:        Prajit Dhar ; Arianna Bisazza
COMMENTS:       9 pages single column with 6 figures
HIGHLIGHT:      In this paper we dissect different forms of cross-lingual transfer and look for its most determining factors, using a variety of models and probing tasks.

60, TITLE:      MULTEXT-East
http://arxiv.org/abs/2003.14026
AUTHORS:        Tomaž Erjavec
HIGHLIGHT:      This case study gives a history of the development of the MULTEXT-East resources, presents their encoding and components, discusses related work and gives some conclusions.

61, TITLE:      SPARQA: Skeleton-based Semantic Parsing for Complex Questions over Knowledge Bases
http://arxiv.org/abs/2003.13956
AUTHORS:        Yawei Sun ; Lingling Zhang ; Gong Cheng ; Yuzhong Qu
COMMENTS:       Accepted to AAAI 2020
HIGHLIGHT:      In this paper, we propose a novel skeleton grammar to represent the high-level structure of a complex question.

62, TITLE:      Span-based discontinuous constituency parsing: a family of exact chart-based algorithms with time complexities from O(n^6) down to O(n^3)
http://arxiv.org/abs/2003.13785
AUTHORS:        Caio Corro
HIGHLIGHT:      We introduce a novel chart-based algorithm for span-based parsing of discontinuous constituency trees of block degree two, including ill-nested structures.

63, TITLE:      EvolveGraph: Heterogeneous Multi-Agent Multi-Modal Trajectory Prediction with Evolving Interaction Graphs
http://arxiv.org/abs/2003.13924
AUTHORS:        Jiachen Li ; Fan Yang ; Masayoshi Tomizuka ; Chiho Choi
COMMENTS:       18 pages
HIGHLIGHT:      In this paper, we propose a generic trajectory forecasting framework (named EvolveGraph) with explicit interaction modeling via a latent interaction graph among multiple heterogeneous, interactive agents.

64, TITLE:      Y-net: Multi-scale feature aggregation network with wavelet structure similarity loss function for single image dehazing
http://arxiv.org/abs/2003.13912
AUTHORS:        Hao-Hsiang Yang ; Chao-Han Huck Yang ; Yi-Chang James Tsai
COMMENTS:       Accepted to IEEE ICASSP 2020
HIGHLIGHT:      In this paper, we propose a Y-net that is named for its structure.

65, TITLE:      Attention-based Multi-modal Fusion Network for Semantic Scene Completion
http://arxiv.org/abs/2003.13910
AUTHORS:        Siqi Li ; Changqing Zou ; Yipeng Li ; Xibin Zhao ; Yue Gao1
COMMENTS:       Accepted by AAAI 2020
HIGHLIGHT:      This paper presents an end-to-end 3D convolutional network named attention-based multi-modal fusion network (AMFNet) for the semantic scene completion (SSC) task of inferring the occupancy and semantic labels of a volumetric 3D scene from single-view RGB-D images.

66, TITLE:      Proxy Anchor Loss for Deep Metric Learning
http://arxiv.org/abs/2003.13911
AUTHORS:        Sungyeon Kim ; Dongwon Kim ; Minsu Cho ; Suha Kwak
COMMENTS:       Accepted to CVPR 2020
HIGHLIGHT:      This paper presents a new proxy-based loss that takes advantages of both pair- and proxy-based methods and overcomes their limitations.

67, TITLE:      Attack of the Genes: Finding Keys and Parameters of Locked Analog ICs Using Genetic Algorithm
http://arxiv.org/abs/2003.13904
AUTHORS:        Rabin Yu Acharya ; Sreeja Chowdhury ; Fatemeh Ganji ; Domenic Forte
HIGHLIGHT:      In this paper, we use algorithms based on evolutionary strategies to investigate the security of analog obfuscation/locking techniques.

68, TITLE:      Ranger: Boosting Error Resilience of Deep Neural Networks through Range Restriction
http://arxiv.org/abs/2003.13874
AUTHORS:        Zitao Chen ; Guanpeng Li ; Karthik Pattabiraman
COMMENTS:       12 pages, 10 figures
HIGHLIGHT:      In this work, we exploit the inherent resilience of DNNs to protect the DNNs from critical faults.

69, TITLE:      Dataless Model Selection with the Deep Frame Potential
http://arxiv.org/abs/2003.13866
AUTHORS:        Calvin Murdock ; Simon Lucey
COMMENTS:       Oral presentation at the Conference on Computer Vision and Pattern Recognition (CVPR), 2020
HIGHLIGHT:      Building upon theoretical connections between deep learning and sparse approximation, we propose the deep frame potential: a measure of coherence that is approximately related to representation stability but has minimizers that depend only on network structure.

70, TITLE:      A Hierarchical Transformer for Unsupervised Parsing
http://arxiv.org/abs/2003.13841
AUTHORS:        Ashok Thillaisundaram
COMMENTS:       ICLR 2020: AfricaNLP Workshop
HIGHLIGHT:      In this paper, we extend the recent transformer model (Vaswani et al., 2017) by enabling it to learn hierarchical representations.

71, TITLE:      COVID-CT-Dataset: A CT Scan Dataset about COVID-19
http://arxiv.org/abs/2003.13865
AUTHORS:        Jinyu Zhao ; Yichen Zhang ; Xuehai He ; Pengtao Xie
HIGHLIGHT:      In this paper, we build a publicly available COVID-CT dataset, containing 275 CT scans that are positive for COVID-19, to foster the research and development of deep learning methods which predict whether a person is affected with COVID-19 by analyzing his/her CTs.

72, TITLE:      Application and Assessment of Deep Learning for the Generation of Potential NMDA Receptor Antagonists
http://arxiv.org/abs/2003.14360
AUTHORS:        Katherine J. Schultz ; Sean M. Colby ; Yasemin Yesiltepe ; Jamie R. Nuñez ; Monee Y. McGrady ; Ryan R. Renslow
HIGHLIGHT:      In this study, we assess the application of a generative model to the NMDAR to achieve two primary objectives: (i) the creation and release of a comprehensive library of experimentally validated NMDAR phencyclidine (PCP) site antagonists to assist the drug discovery community and (ii) an analysis of both the advantages conferred by applying such generative artificial intelligence models to drug design and the current limitations of the approach.

73, TITLE:      Optical Non-Line-of-Sight Physics-based 3D Human Pose Estimation
http://arxiv.org/abs/2003.14414
AUTHORS:        Mariko Isogawa ; Ye Yuan ; Matthew O'Toole ; Kris Kitani
COMMENTS:       CVPR 2020. Video: https://youtu.be/4HFulrdmLE8. Project page: https://marikoisogawa.github.io/project/nlos_pose
HIGHLIGHT:      We describe a method for 3D human pose estimation from transient images (i.e., a 3D spatio-temporal histogram of photons) acquired by an optical non-line-of-sight (NLOS) imaging system.

74, TITLE:      Probabilistic Pixel-Adaptive Refinement Networks
http://arxiv.org/abs/2003.14407
AUTHORS:        Anne S. Wannenwetsch ; Stefan Roth
COMMENTS:       To appear at CVPR 2020
HIGHLIGHT:      We introduce probabilistic pixel-adaptive convolutions (PPACs), which not only depend on image guidance data for filtering, but also respect the reliability of per-pixel predictions.

75, TITLE:      Segmenting Transparent Objects in the Wild
http://arxiv.org/abs/2003.13948
AUTHORS:        Enze Xie ; Wenjia Wang ; Wenhai Wang ; Mingyu Ding ; Chunhua Shen ; Ping Luo
HIGHLIGHT:      To evaluate the effectiveness of Trans10K, we propose a novel boundary-aware segmentation method, termed TransLab, which exploits boundary as the clue to improve segmentation of transparent objects. To address this important problem, this work proposes a large-scale dataset for transparent object segmentation, named Trans10K, consisting of 10,428 images of real scenarios with carefully manual annotations, which are 10 times larger than the existing datasets.

76, TITLE:      Self-supervised Monocular Trained Depth Estimation using Self-attention and Discrete Disparity Volume
http://arxiv.org/abs/2003.13951
AUTHORS:        Adrian Johnston ; Gustavo Carneiro
HIGHLIGHT:      In this paper, we propose two new ideas to improve self-supervised monocular trained depth estimation: 1) self-attention, and 2) discrete disparity prediction.

77, TITLE:      A Simple Class Decision Balancing for Incremental Learning
http://arxiv.org/abs/2003.13947
AUTHORS:        Hongjoon Ahn ; Taesup Moon
HIGHLIGHT:      In this paper, we propose two simple modifications for the vanilla FT, separated softmax (SS) layer and ratio-preserving (RP) mini-batches for SGD updates.

78, TITLE:      Multi-Modal Graph Neural Network for Joint Reasoning on Vision and Scene Text
http://arxiv.org/abs/2003.13962
AUTHORS:        Difei Gao ; Ke Li ; Ruiping Wang ; Shiguang Shan ; Xilin Chen
COMMENTS:       Published as a CVPR2020 paper
HIGHLIGHT:      Following this idea, we propose a novel VQA approach, Multi-Modal Graph Neural Network (MM-GNN).

79, TITLE:      Neural Networks Are More Productive Teachers Than Human Raters: Active Mixup for Data-Efficient Knowledge Distillation from a Blackbox Model
http://arxiv.org/abs/2003.13960
AUTHORS:        Dongdong Wang ; Yandong Li ; Liqiang Wang ; Boqing Gong
COMMENTS:       Accepted to CVPR 2020
HIGHLIGHT:      To tackle these challenges, we propose an approach that blends mixup and active learning.

80, TITLE:      Spatio-Temporal Graph for Video Captioning with Knowledge Distillation
http://arxiv.org/abs/2003.13942
AUTHORS:        Boxiao Pan ; Haoye Cai ; De-An Huang ; Kuan-Hui Lee ; Adrien Gaidon ; Ehsan Adeli ; Juan Carlos Niebles
COMMENTS:       CVPR 2020
HIGHLIGHT:      In this paper, we propose a novel spatio-temporal graph model for video captioning that exploits object interactions in space and time.

81, TITLE:      FGN: Fully Guided Network for Few-Shot Instance Segmentation
http://arxiv.org/abs/2003.13954
AUTHORS:        Zhibo Fan ; Jin-Gang Yu ; Zhihao Liang ; Jiarong Ou ; Changxin Gao ; Gui-Song Xia ; Yuanqing Li
COMMENTS:       Accepted by CVPR 2020, 10 pages, 6 figures,
HIGHLIGHT:      This paper presents a Fully Guided Network (FGN) for few-shot instance segmentation.

82, TITLE:      Autonomous discovery in the chemical sciences part II: Outlook
http://arxiv.org/abs/2003.13755
AUTHORS:        Connor W. Coley ; Natalie S. Eyke ; Klavs F. Jensen
COMMENTS:       Revised version available at 10.1002/anie.201909989
HIGHLIGHT:      This two-part review examines how automation has contributed to different aspects of discovery in the chemical sciences.

83, TITLE:      Autonomous discovery in the chemical sciences part I: Progress
http://arxiv.org/abs/2003.13754
AUTHORS:        Connor W. Coley ; Natalie S. Eyke ; Klavs F. Jensen
COMMENTS:       Revised version available at 10.1002/anie.201909987
HIGHLIGHT:      This two-part review examines how automation has contributed to different aspects of discovery in the chemical sciences. We then introduce a set of questions and considerations relevant to assessing the extent of autonomy.

84, TITLE:      SPARE3D: A Dataset for SPAtial REasoning on Three-View Line Drawings
http://arxiv.org/abs/2003.14034
AUTHORS:        Wenyu Han ; Siyuan Xiang ; Chenhui Liu ; Ruoyu Wang ; Chen Feng
COMMENTS:       This paper has been accepted in CVPR'20. The first two authors contributed equally. Chen Feng is the corresponding author
HIGHLIGHT:      To answer these questions, we present the SPARE3D dataset.

85, TITLE:      PolarNet: An Improved Grid Representation for Online LiDAR Point Clouds Semantic Segmentation
http://arxiv.org/abs/2003.14032
AUTHORS:        Yang Zhang ; Zixiang Zhou ; Philip David ; Xiangyu Yue ; Zerong Xi ; Hassan Foroosh
COMMENTS:       Accepted by CVPR 2020
HIGHLIGHT:      The combination of the aforementioned challenges motivates us to propose a new LiDAR-specific, KNN-free segmentation algorithm - PolarNet.

86, TITLE:      Distilled Semantics for Comprehensive Scene Understanding from Videos
http://arxiv.org/abs/2003.14030
AUTHORS:        Fabio Tosi ; Filippo Aleotti ; Pierluigi Zama Ramirez ; Matteo Poggi ; Samuele Salti ; Luigi Di Stefano ; Stefano Mattoccia
COMMENTS:       CVPR 2020. Code will be available at https://github.com/CVLAB-Unibo/omeganet
HIGHLIGHT:      In this paper, we take an additional step toward holistic scene understanding with monocular cameras by learning depth and motion alongside with semantics, with supervision for the latter provided by a pre-trained network distilling proxy ground truth images.

87, TITLE:      BANet: Bidirectional Aggregation Network with Occlusion Handling for Panoptic Segmentation
http://arxiv.org/abs/2003.14031
AUTHORS:        Yifeng Chen ; Guangchen Lin ; Songyuan Li ; Bourahla Omar ; Yiming Wu ; Fangfang Wang ; Junyi Feng ; Mingliang Xu ; Xi Li
COMMENTS:       to be published in CVPR2020, oral paper
HIGHLIGHT:      Motivated by these observations, we propose a novel deep panoptic segmentation scheme based on a bidirectional learning pipeline.

88, TITLE:      Distance in Latent Space as Novelty Measure
http://arxiv.org/abs/2003.14043
AUTHORS:        Mark Philip Philipsen ; Thomas Baltzer Moeslund
COMMENTS:       work in progress
HIGHLIGHT:      We propose to intelligently select samples when constructing data sets in order to best utilize the available labeling budget.

89, TITLE:      Measuring Generalisation to Unseen Viewpoints, Articulations, Shapes and Objects for 3D Hand Pose Estimation under Hand-Object Interaction
http://arxiv.org/abs/2003.13764
AUTHORS:        Anil Armagan ; Guillermo Garcia-Hernando ; Seungryul Baek ; Shreyas Hampali ; Mahdi Rad ; Zhaohui Zhang ; Shipeng Xie ; MingXiu Chen ; Boshen Zhang ; Fu Xiong ; Yang Xiao ; Zhiguo Cao ; Junsong Yuan ; Pengfei Ren ; Weiting Huang ; Haifeng Sun ; Marek Hrúz ; Jakub Kanis ; Zdeněk Krňoul ; Qingfu Wan ; Shile Li ; Linlin Yang ; Dongheui Lee ; Angela Yao ; Weiguo Zhou ; Sijia Mei ; Yunhui Liu ; Adrian Spurr ; Umar Iqbal ; Pavlo Molchanov ; Philippe Weinzaepfel ; Romain Brégier ; Gregory Rogez ; Vincent Lepetit ; Tae-Kyun Kim
HIGHLIGHT:      In this work, we study how well different type of approaches generalise in the task of 3D hand pose estimation under hand-object interaction and single hand scenarios.

90, TITLE:      Understanding the impact of mistakes on background regions in crowd counting
http://arxiv.org/abs/2003.13759
AUTHORS:        Davide Modolo ; Bing Shuai ; Rahul Rama Varior ; Joseph Tighe
HIGHLIGHT:      In this paper we analyze this problem in depth.

91, TITLE:      Domain Balancing: Face Recognition on Long-Tailed Domains
http://arxiv.org/abs/2003.13791
AUTHORS:        Dong Cao ; Xiangyu Zhu ; Xingyu Huang ; Jianzhu Guo ; Zhen Lei
COMMENTS:       Accepted to CVPR2020
HIGHLIGHT:      In this paper, we propose a novel Domain Balancing (DB) mechanism to handle this problem.

92, TITLE:      Combining detection and tracking for human pose estimation in videos
http://arxiv.org/abs/2003.13743
AUTHORS:        Manchen Wang ; Joseph Tighe ; Davide Modolo
COMMENTS:       Accepted to CVPR 2020 as oral
HIGHLIGHT:      We propose a novel top-down approach that tackles the problem of multi-person human pose estimation and tracking in videos.

93, TITLE:      MTL-NAS: Task-Agnostic Neural Architecture Search towards General-Purpose Multi-Task Learning
http://arxiv.org/abs/2003.14058
AUTHORS:        Yuan Gao ; Haoping Bai ; Zequn Jie ; Jiayi Ma ; Kui Jia ; Wei Liu
COMMENTS:       Accepted to CVPR2020. The first two authors contribute equally
HIGHLIGHT:      We propose to incorporate neural architecture search (NAS) into general-purpose multi-task learning (GP-MTL).

94, TITLE:      Non-dimensional Star-Identification
http://arxiv.org/abs/2003.13736
AUTHORS:        Carl Leake ; David Arnas ; Daniele Mortari
COMMENTS:       14 pages, 17 figures, 4 tables
HIGHLIGHT:      This study introduces a new "Non-Dimensional" star identification algorithm to reliably identify the stars observed by a wide field-of-view star tracker when the focal length and optical axis offset values are known with poor accuracy.

95, TITLE:      An Open-Source, Industrial-Strength Optimizing Compiler for Quantum Programs
http://arxiv.org/abs/2003.13961
AUTHORS:        Robert S. Smith ; Eric C. Peterson ; Mark G. Skilbeck ; Erik J. Davis
HIGHLIGHT:      In this paper, we describe many of the principles behind Quilc's design, and demonstrate the compiler with various examples.

96, TITLE:      On the Integration of LinguisticFeatures into Statistical and Neural Machine Translation
http://arxiv.org/abs/2003.14324
AUTHORS:        Eva Vanmassenhove
HIGHLIGHT:      We cover a series of problems related to the integration of specific linguistic features into statistical and neural MT, aiming to analyse and provide a solution to some of them.

97, TITLE:      Inherent Dependency Displacement Bias of Transition-Based Algorithms
http://arxiv.org/abs/2003.14282
AUTHORS:        Mark Anderson ; Carlos Gómez-Rodríguez
COMMENTS:       To be published in proceedings of the 12th Language Resources and Evaluation Conference. Earlier versions were rejected at the 57th Annual Conference of the Association for Computational Linguistics and the SIGNLL Conference on Computational Natural Language Learning, 2019
HIGHLIGHT:      In this paper we shed some light on this by introducing the concept of an algorithm's inherent dependency displacement distribution.

98, TITLE:      Low Resource Neural Machine Translation: A Benchmark for Five African Languages
http://arxiv.org/abs/2003.14402
AUTHORS:        Surafel M. Lakew ; Matteo Negri ; Marco Turchi
COMMENTS:       Accepted for AfricaNLP workshop at ICLR 2020
HIGHLIGHT:      In this work, we benchmark NMT between English and five African LRL pairs (Swahili, Amharic, Tigrigna, Oromo, Somali [SATOS]).

99, TITLE:      Graph Enhanced Representation Learning for News Recommendation
http://arxiv.org/abs/2003.14292
AUTHORS:        Suyu Ge ; Chuhan Wu ; Fangzhao Wu ; Tao Qi ; Yongfeng Huang
HIGHLIGHT:      Here we propose a news recommendation method which can enhance the representation learning of users and news by modeling their relatedness in a graph setting.

100, TITLE:     Adaptive Group Sparse Regularization for Continual Learning
http://arxiv.org/abs/2003.13726
AUTHORS:        Sangwon Jung ; Hongjoon Ahn ; Sungmin Cha ; Taesup Moon
HIGHLIGHT:      We propose a novel regularization-based continual learning method, dubbed as Adaptive Group Sparsity based Continual Learning (AGS-CL), using two group sparsity-based penalties.

101, TITLE:     Amharic Abstractive Text Summarization
http://arxiv.org/abs/2003.13721
AUTHORS:        Amr M. Zaki ; Mahmoud I. Khalil ; Hazem M. Abbas
COMMENTS:       content 3 pages, reference 2 pages, 2 figures, presented to AfricaNLP workshop ICLR 2020
HIGHLIGHT:      In this work we discuss one of these new novel approaches which combines curriculum learning with Deep Learning, this model is called Scheduled Sampling.

102, TITLE:     Evaluating Amharic Machine Translation
http://arxiv.org/abs/2003.14386
AUTHORS:        Asmelash Teka Hadgu ; Adam Beaudoin ; Abel Aregawi
COMMENTS:       4 pages
HIGHLIGHT:      In this paper, we develop and share a dataset to automatically evaluate the quality of MT systems for Amharic.

103, TITLE:     A Pebble in the AI Race
http://arxiv.org/abs/2003.13861
AUTHORS:        Toby Walsh
COMMENTS:       To appear in the Druk Journal
HIGHLIGHT:      A Pebble in the AI Race

104, TITLE:     DeepLPF: Deep Local Parametric Filters for Image Enhancement
http://arxiv.org/abs/2003.13985
AUTHORS:        Sean Moran ; Pierre Marza ; Steven McDonagh ; Sarah Parisot ; Gregory Slabaugh
COMMENTS:       Accepted for publication at CVPR2020
HIGHLIGHT:      In this paper, we introduce a novel approach to automatically enhance images using learned spatially local filters of three different types (Elliptical Filter, Graduated Filter, Polynomial Filter).

105, TITLE:     SK-Net: Deep Learning on Point Cloud via End-to-end Discovery of Spatial Keypoints
http://arxiv.org/abs/2003.14014
AUTHORS:        Weikun Wu ; Yan Zhang ; David Wang ; Yunqi Lei
HIGHLIGHT:      This paper presents an end-to-end framework, SK-Net, to jointly optimize the inference of spatial keypoint with the learning of feature representation of a point cloud for a specific point cloud task.

106, TITLE:     Learning Human-Object Interaction Detection using Interaction Points
http://arxiv.org/abs/2003.14023
AUTHORS:        Tiancai Wang ; Tong Yang ; Martin Danelljan ; Fahad Shahbaz Khan ; Xiangyu Zhang ; Jian Sun
COMMENTS:       Accepted to CVPR 2020
HIGHLIGHT:      In this paper, we therefore propose a novel fully-convolutional approach that directly detects the interactions between human-object pairs.

107, TITLE:     FaceScape: a Large-scale High Quality 3D Face Dataset and Detailed Riggable 3D Face Prediction
http://arxiv.org/abs/2003.13989
AUTHORS:        Haotian Yang ; Hao Zhu ; Yanru Wang ; Mingkai Huang ; Qiu Shen ; Ruigang Yang ; Xun Cao
HIGHLIGHT:      In this paper, we present a large-scale detailed 3D face dataset, FaceScape, and propose a novel algorithm that is able to predict elaborate riggable 3D face models from a single image input.

108, TITLE:     Fashion Meets Computer Vision: A Survey
http://arxiv.org/abs/2003.13988
AUTHORS:        Wen-Huang Cheng ; Sijie Song ; Chieh-Yun Chen ; Shintami Chusnul Hidayati ; Jiaying Liu
COMMENTS:       35 pages including 5 pages of reference
HIGHLIGHT:      Fashion is the way we present ourselves to the world and has become one of the world's largest industries.

109, TITLE:     Certifiable Relative Pose Estimation
http://arxiv.org/abs/2003.13732
AUTHORS:        Mercedes Garcia-Salguero ; Jesus Briales ; Javier Gonzalez-Jimenez
HIGHLIGHT:      In this paper we present the first fast optimality certifier for the non-minimal version of the Relative Pose problem for calibrated cameras from epipolar constraints.

110, TITLE:     Regularizing Class-wise Predictions via Self-knowledge Distillation
http://arxiv.org/abs/2003.13964
AUTHORS:        Sukmin Yun ; Jongjin Park ; Kimin Lee ; Jinwoo Shin
COMMENTS:       Accepted to CVPR 2020
HIGHLIGHT:      To mitigate the issue, we propose a new regularization method that penalizes the predictive distribution between similar samples.

111, TITLE:     A Spatio-Temporal Spot-Forecasting Framework forUrban Traffic Prediction
http://arxiv.org/abs/2003.13977
AUTHORS:        Rodrigo de Medrano ; José L. Aznarte
COMMENTS:       16 pages, 14 figures
HIGHLIGHT:      In this work we focus on creating a complex deep neural framework for spatio-temporal traffic forecasting with comparatively very good performance and that shows to be adaptable over several spatio-temporal conditions while remaining easy to understand and interpret.

112, TITLE:     COVID-ResNet: A Deep Learning Framework for Screening of COVID19 from Radiographs
http://arxiv.org/abs/2003.14395
AUTHORS:        Muhammad Farooq ; Abdul Hafeez
COMMENTS:       6 pages, 3 Figures,
HIGHLIGHT:      The goal of this work is to build open source and open access datasets and present an accurate Convolutional Neural Network framework for differentiating COVID19 cases from other pneumonia cases.

113, TITLE:     Characterizing Speech Adversarial Examples Using Self-Attention U-Net Enhancement
http://arxiv.org/abs/2003.13917
AUTHORS:        Chao-Han Huck Yang ; Jun Qi ; Pin-Yu Chen ; Xiaoli Ma ; Chin-Hui Lee
COMMENTS:       The first draft was finished in August 2019. Accepted to IEEE ICASSP 2020
HIGHLIGHT:      In this work, we present a U-Net based attention model, U-Net$_{At}$, to enhance adversarial speech signals.

114, TITLE:     Automated Methods for Detection and Classification Pneumonia based on X-Ray Images Using Deep Learning
http://arxiv.org/abs/2003.14363
AUTHORS:        Khalid El Asnaoui ; Youness Chawki ; Ali Idri
HIGHLIGHT:      In this paper, we present a comparison of recent Deep Convolutional Neural Network (DCNN) architectures for automatic binary classification of pneumonia images based fined tuned versions of (VGG16, VGG19, DenseNet201, Inception_ResNet_V2, Inception_V3, Resnet50, MobileNet_V2 and Xception).

115, TITLE:     Radiologist-level stroke classification on non-contrast CT scans with Deep U-Net
http://arxiv.org/abs/2003.14287
AUTHORS:        Manvel Avetisian ; Vladimir Kokh ; Alex Tuzhilin ; Dmitry Umerenkov
HIGHLIGHT:      In this paper, we modified the U-Net CNN architecture for the stroke identification problem using non-contrast CT.

116, TITLE:     Lesion Conditional Image Generation for Improved Segmentation of Intracranial Hemorrhage from CT Images
http://arxiv.org/abs/2003.13868
AUTHORS:        Manohar Karki ; Junghwan Cho
HIGHLIGHT:      We present a lesion conditional Generative Adversarial Network LcGAN to generate synthetic Computed Tomography (CT) images for data augmentation.



==========Updates to Previous Papers==========
1, TITLE:       Domain Adaptation Regularization for Spectral Pruning
http://arxiv.org/abs/1912.11853
AUTHORS:        Laurent Dillard ; Yosuke Shinya ; Taiji Suzuki
HIGHLIGHT:      In this paper, we investigate on possible improvements of compression methods in DA setting.

2, TITLE:       Predicting Sharp and Accurate Occlusion Boundaries in Monocular Depth Estimation Using Displacement Fields
http://arxiv.org/abs/2002.12730
AUTHORS:        Michael Ramamonjisoa ; Yuming Du ; Vincent Lepetit
COMMENTS:       Accepted to CVPR 2020
HIGHLIGHT:      We instead learn to predict, given a depth map predicted by some reconstruction method, a 2D displacement field able to re-sample pixels around the occlusion boundaries into sharper reconstructions.

3, TITLE:       Why Having 10,000 Parameters in Your Camera Model is Better Than Twelve
http://arxiv.org/abs/1912.02908
AUTHORS:        Thomas Schöps ; Viktor Larsson ; Marc Pollefeys ; Torsten Sattler
COMMENTS:       15 pages, 12 figures, accepted to CVPR 2020 as an oral
HIGHLIGHT:      In this paper, we argue that this should change.

4, TITLE:       MineGAN: effective knowledge transfer from GANs to target domains with few images
http://arxiv.org/abs/1912.05270
AUTHORS:        Yaxing Wang ; Abel Gonzalez-Garcia ; David Berga ; Luis Herranz ; Fahad Shahbaz Khan ; Joost van de Weijer
COMMENTS:       CVPR2020
HIGHLIGHT:      Given the often enormous effort required to train GANs, both computationally as well as in the dataset collection, the re-use of pretrained GANs is a desirable objective.

5, TITLE:       Context R-CNN: Long Term Temporal Context for Per-Camera Object Detection
http://arxiv.org/abs/1912.03538
AUTHORS:        Sara Beery ; Guanhang Wu ; Vivek Rathod ; Ronny Votel ; Jonathan Huang
COMMENTS:       CVPR 2020
HIGHLIGHT:      In this paper we propose a method that leverages temporal context from the unlabeled frames of a novel camera to improve performance at that camera.

6, TITLE:       Hyperbolic Image Embeddings
http://arxiv.org/abs/1904.02239
AUTHORS:        Valentin Khrulkov ; Leyla Mirvakhabova ; Evgeniya Ustinova ; Ivan Oseledets ; Victor Lempitsky
HIGHLIGHT:      In this work, we demonstrate that in many practical scenarios hyperbolic embeddings provide a better alternative.

7, TITLE:       Towards Best Practice in Explaining Neural Network Decisions with LRP
http://arxiv.org/abs/1910.09840
AUTHORS:        Maximilian Kohlbrenner ; Alexander Bauer ; Shinichi Nakajima ; Alexander Binder ; Wojciech Samek ; Sebastian Lapuschkin
COMMENTS:       7 pages, 4 figures, 1 table. Presented at IJCNN 2020
HIGHLIGHT:      In this paper, we focus on a popular and widely used method of XAI, the Layer-wise Relevance Propagation (LRP).

8, TITLE:       Soccer Team Vectors
http://arxiv.org/abs/1908.00698
AUTHORS:        Robert Müller ; Stefan Langer ; Fabian Ritz ; Christoph Roch ; Steffen Illium ; Claudia Linnhoff-Popien
COMMENTS:       11 pages, 1 figure; This paper was presented at the 6th Workshop on Machine Learning and Data Mining for Sports Analytics at ECML/PKDD 2019, W\"urzburg, Germany, 2019
HIGHLIGHT:      In this work we present STEVE - Soccer TEam VEctors, a principled approach for learning real valued vectors for soccer teams where similar teams are close to each other in the resulting vector space.

9, TITLE:       On robot compliance. A cerebellar control approach
http://arxiv.org/abs/2003.01033
AUTHORS:        Ignacio Abadia ; Francisco Naveros ; Jesus A. Garrido ; Eduardo Ros ; Niceto R. Luque
HIGHLIGHT:      We propose a natural integration of a bio inspired control scheme, based on the cerebellum, with a compliant robot.

10, TITLE:      Towards Large yet Imperceptible Adversarial Image Perturbations with Perceptual Color Distance
http://arxiv.org/abs/1911.02466
AUTHORS:        Zhengyu Zhao ; Zhuoran Liu ; Martha Larson
COMMENTS:       Accepted at CVPR 2020; Code is available at https://github.com/ZhengyuZhao/PerC-Adversarial
HIGHLIGHT:      In this work, we drop this assumption by pursuing an approach that exploits human color perception, and more specifically, minimizing perturbation size with respect to perceptual color distance.

11, TITLE:      Rethinking the Distribution Gap of Person Re-identification with Camera-based Batch Normalization
http://arxiv.org/abs/2001.08680
AUTHORS:        Zijie Zhuang ; Longhui Wei ; Lingxi Xie ; Tianyu Zhang ; Hengheng Zhang ; Haozhe Wu ; Haizhou Ai ; Qi Tian
HIGHLIGHT:      Rethinking the Distribution Gap of Person Re-identification with Camera-based Batch Normalization

12, TITLE:      MonoGRNet: A Geometric Reasoning Network for Monocular 3D Object Localization
http://arxiv.org/abs/1811.10247
AUTHORS:        Zengyi Qin ; Jinglu Wang ; Yan Lu
COMMENTS:       8 pages, accepted by AAAI 2019, oral
HIGHLIGHT:      Unlike the pixel-level depth estimation that needs per-pixel annotations, we propose a novel IDE method that directly predicts the depth of the targeting 3D bounding box's center using sparse supervision.

13, TITLE:      Central Similarity Quantization for Efficient Image and Video Retrieval
http://arxiv.org/abs/1908.00347
AUTHORS:        Li Yuan ; Tao Wang ; Xiaopeng Zhang ; Francis EH Tay ; Zequn Jie ; Wei Liu ; Jiashi Feng
COMMENTS:       CVPR2020, Codes: https://github.com/yuanli2333/Hadamard-Matrix-for-hashing
HIGHLIGHT:      In this work, we propose a new \emph{global} similarity metric, termed as \emph{central similarity}, with which the hash codes of similar data pairs are encouraged to approach a common center and those for dissimilar pairs to converge to different centers, to improve hash learning efficiency and retrieval accuracy.

14, TITLE:      What You See is What You Get: Exploiting Visibility for 3D Object Detection
http://arxiv.org/abs/1912.04986
AUTHORS:        Peiyun Hu ; Jason Ziglar ; David Held ; Deva Ramanan
COMMENTS:       To be published in CVPR'20. More at https://www.cs.cmu.edu/~peiyunh/wysiwyg
HIGHLIGHT:      In this paper, we demonstrate such knowledge can be efficiently recovered through 3D raycasting and readily incorporated into batch-based gradient learning.

15, TITLE:      Local Class-Specific and Global Image-Level Generative Adversarial Networks for Semantic-Guided Scene Generation
http://arxiv.org/abs/1912.12215
AUTHORS:        Hao Tang ; Dan Xu ; Yan Yan ; Philip H. S. Torr ; Nicu Sebe
COMMENTS:       Accepted to CVPR 2020, camera ready (10 pages) + supplementary (18 pages)
HIGHLIGHT:      In this paper, we address the task of semantic-guided scene generation.

16, TITLE:      ALFRED: A Benchmark for Interpreting Grounded Instructions for Everyday Tasks
http://arxiv.org/abs/1912.01734
AUTHORS:        Mohit Shridhar ; Jesse Thomason ; Daniel Gordon ; Yonatan Bisk ; Winson Han ; Roozbeh Mottaghi ; Luke Zettlemoyer ; Dieter Fox
COMMENTS:       Computer Vision and Pattern Recognition (CVPR) 2020 ; https://askforalfred.com/
HIGHLIGHT:      We present ALFRED (Action Learning From Realistic Environments and Directives), a benchmark for learning a mapping from natural language instructions and egocentric vision to sequences of actions for household tasks.

17, TITLE:      What's Hidden in a Randomly Weighted Neural Network?
http://arxiv.org/abs/1911.13299
AUTHORS:        Vivek Ramanujan ; Mitchell Wortsman ; Aniruddha Kembhavi ; Ali Farhadi ; Mohammad Rastegari
COMMENTS:       Accepted to CVPR 2020
HIGHLIGHT:      We empirically show that as randomly weighted neural networks with fixed weights grow wider and deeper, an "untrained subnetwork" approaches a network with learned weights in accuracy.

18, TITLE:      Synthesizing Structured CAD Models with Equality Saturation and Inverse Transformations
http://arxiv.org/abs/1909.12252
AUTHORS:        Chandrakana Nandi ; Max Willsey ; Adam Anderson ; James R. Wilcox ; Eva Darulova ; Dan Grossman ; Zachary Tatlock
COMMENTS:       14 pages
HIGHLIGHT:      We present Szalinski, a tool that uses Equality Saturation with semantics-preserving CAD rewrites to efficiently search for smaller equivalent programs.

19, TITLE:      Exploiting Deep Generative Prior for Versatile Image Restoration and Manipulation
http://arxiv.org/abs/2003.13659
AUTHORS:        Xingang Pan ; Xiaohang Zhan ; Bo Dai ; Dahua Lin ; Chen Change Loy ; Ping Luo
COMMENTS:       1) Precise GAN-inversion by discriminator-guided generator finetuning. 2) A versatile way for high-quality image restoration and manipulation. Code: https://github.com/XingangPan/deep-generative-prior
HIGHLIGHT:      This work presents an effective way to exploit the image prior captured by a generative adversarial network (GAN) trained on large-scale natural images.

20, TITLE:      3D U-Net Based Brain Tumor Segmentation and Survival Days Prediction
http://arxiv.org/abs/1909.12901
AUTHORS:        Feifan Wang ; Runzhou Jiang ; Liqin Zheng ; Chun Meng ; Bharat Biswal
COMMENTS:       Third place award of the 2019 MICCAI BraTS challenge survival task [BraTS 2019](https://www.med.upenn.edu/cbica/brats2019.html)
HIGHLIGHT:      In this paper, a 3D U-net based deep learning model has been trained with the help of brain-wise normalization and patching strategies for the brain tumor segmentation task in the BraTS 2019 competition.

21, TITLE:      Light Field Synthesis by Training Deep Network in the Refocused Image Domain
http://arxiv.org/abs/1910.06072
AUTHORS:        Chang-Le Liu ; Kuang-Tsu Shih ; Homer H. Chen
COMMENTS:       submitted to IEEE Transactions on Image Processing
HIGHLIGHT:      In this paper, we propose a new loss function called refocused image error (RIE) to address the issue.

22, TITLE:      GrappaNet: Combining Parallel Imaging with Deep Learning for Multi-Coil MRI Reconstruction
http://arxiv.org/abs/1910.12325
AUTHORS:        Anuroop Sriram ; Jure Zbontar ; Tullie Murrell ; C. Lawrence Zitnick ; Aaron Defazio ; Daniel K. Sodickson
HIGHLIGHT:      In this paper, we present a novel method to integrate traditional parallel imaging methods into deep neural networks that is able to generate high quality reconstructions even for high acceleration factors.

23, TITLE:      Three-dimensional Generative Adversarial Nets for Unsupervised Metal Artifact Reduction
http://arxiv.org/abs/1911.08105
AUTHORS:        Megumi Nakao ; Keiho Imanishi ; Nobuhiro Ueda ; Yuichiro Imai ; Tadaaki Kirita ; Tetsuya Matsuda
HIGHLIGHT:      In this paper, we introduce metal artifact reduction methods based on an unsupervised volume-to-volume translation learned from clinical CT images.

24, TITLE:      Noise Modeling, Synthesis and Classification for Generic Object Anti-Spoofing
http://arxiv.org/abs/2003.13043
AUTHORS:        Joel Stehouwer ; Amin Jourabloo ; Yaojie Liu ; Xiaoming Liu
COMMENTS:       In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2020
HIGHLIGHT:      In this work, we define and tackle the problem of Generic Object Anti-Spoofing (GOAS) for the first time.

25, TITLE:      Noise Robust Generative Adversarial Networks
http://arxiv.org/abs/1911.11776
AUTHORS:        Takuhiro Kaneko ; Tatsuya Harada
COMMENTS:       Accepted to CVPR 2020. Project page: https://takuhirok.github.io/NR-GAN/
HIGHLIGHT:      As an alternative, we propose a novel family of GANs called noise robust GANs (NR-GANs), which can learn a clean image generator even when training images are noisy.

26, TITLE:      ASFD: Automatic and Scalable Face Detector
http://arxiv.org/abs/2003.11228
AUTHORS:        Bin Zhang ; Jian Li ; Yabiao Wang ; Ying Tai ; Chengjie Wang ; Jilin Li ; Feiyue Huang ; Yili Xia ; Wenjiang Pei ; Rongrong Ji
COMMENTS:       Ranked No.1 on WIDER Face (http://shuoyang1213.me/WIDERFACE/WiderFace_Results.html)
HIGHLIGHT:      In this paper, we propose a novel Automatic and Scalable Face Detector (ASFD), which is based on a combination of neural architecture search techniques as well as a new loss design.

27, TITLE:      Depth Potentiality-Aware Gated Attention Network for RGB-D Salient Object Detection
http://arxiv.org/abs/2003.08608
AUTHORS:        Zuyao Chen ; Qingming Huang
COMMENTS:       rewrite the paper
HIGHLIGHT:      In this paper, we address these two issues in a holistic model synergistically, and propose a novel network named DPANet to explicitly model the potentiality of the depth map and effectively integrate the cross-modal complementarity.

28, TITLE:      Analysis of the hands in egocentric vision: A survey
http://arxiv.org/abs/1912.10867
AUTHORS:        Andrea Bandini ; José Zariffa
HIGHLIGHT:      In this survey, we review the literature that focuses on the hands using egocentric vision, categorizing the existing approaches into: localization (where are the hands or parts of them?)

29, TITLE:      MMTM: Multimodal Transfer Module for CNN Fusion
http://arxiv.org/abs/1911.08670
AUTHORS:        Hamid Reza Vaezi Joze ; Amirreza Shaban ; Michael L. Iuzzolino ; Kazuhito Koishida
HIGHLIGHT:      In this paper, we present a simple neural network module for leveraging the knowledge from multiple modalities in convolutional neural networks.

30, TITLE:      RandLA-Net: Efficient Semantic Segmentation of Large-Scale Point Clouds
http://arxiv.org/abs/1911.11236
AUTHORS:        Qingyong Hu ; Bo Yang ; Linhai Xie ; Stefano Rosa ; Yulan Guo ; Zhihua Wang ; Niki Trigoni ; Andrew Markham
COMMENTS:       CVPR 2020 Oral. Code and data are available at: https://github.com/QingyongHu/RandLA-Net
HIGHLIGHT:      In this paper, we introduce RandLA-Net, an efficient and lightweight neural architecture to directly infer per-point semantics for large-scale point clouds.

31, TITLE:      Neural Data Server: A Large-Scale Search Engine for Transfer Learning Data
http://arxiv.org/abs/2001.02799
AUTHORS:        Xi Yan ; David Acuna ; Sanja Fidler
HIGHLIGHT:      We introduce Neural Data Server (NDS), a large-scale search engine for finding the most useful transfer learning data to the target domain.

32, TITLE:      Learning to Transfer Texture from Clothing Images to 3D Humans
http://arxiv.org/abs/2003.02050
AUTHORS:        Aymen Mir ; Thiemo Alldieck ; Gerard Pons-Moll
COMMENTS:       IEEE Conference on Computer Vision and Pattern Recognition
HIGHLIGHT:      In this paper, we present a simple yet effective method to automatically transfer textures of clothing images (front and back) to 3D garments worn on top SMPL, in real time.

33, TITLE:      Detecting Attended Visual Targets in Video
http://arxiv.org/abs/2003.02501
AUTHORS:        Eunji Chong ; Yongxin Wang ; Nataniel Ruiz ; James M. Rehg
COMMENTS:       Accepted to CVPR 2020
HIGHLIGHT:      Our goal is to identify where each person in each frame of a video is looking, and correctly handle the case where the gaze target is out-of-frame. We introduce a new annotated dataset, VideoAttentionTarget, containing complex and dynamic patterns of real-world gaze behavior.

34, TITLE:      Image Hashing by Minimizing Independent Relaxed Wasserstein Distance
http://arxiv.org/abs/2003.00134
AUTHORS:        Khoa D. Doan ; Amir Kimiyaie ; Saurav Manchanda ; Chandan K. Reddy
HIGHLIGHT:      In this paper, we propose an Independent Relaxed Wasserstein Autoencoder, which presents a novel, efficient hashing method that can implicitly learn the optimal hash function by directly training the adversarial autoencoder without any discriminator/critic.

35, TITLE:      Modeling Historical AIS Data For Vessel Path Prediction: A Comprehensive Treatment
http://arxiv.org/abs/2001.01592
AUTHORS:        Enmei Tu ; Guanghao Zhang ; Shangbo Mao ; Lily Rachmawati ; Guang-Bin Huang
COMMENTS:       11 pages
HIGHLIGHT:      In this paper, we propose a comprehensive framework to model massive historical AIS trajectory segments for accurate vessel path prediction.

36, TITLE:      UG$^{2+}$ Track 2: A Collective Benchmark Effort for Evaluating and Advancing Image Understanding in Poor Visibility Environments
http://arxiv.org/abs/1904.04474
AUTHORS:        Ye Yuan ; Wenhan Yang ; Wenqi Ren ; Jiaying Liu ; Walter J. Scheirer ; Zhangyang Wang
COMMENTS:       A summary paper on datasets, fact sheets, baseline results, challenge results, and winning methods in UG$^{2+}$ Challenge (Track 2). More materials are provided in http://www.ug2challenge.org/index.html
HIGHLIGHT:      To provide a more thorough examination and fair comparison, we introduce three benchmark sets collected in real-world hazy, rainy, and low-light conditions, respectively, with annotate objects/faces annotated.

37, TITLE:      Interpreting the Latent Space of GANs for Semantic Face Editing
http://arxiv.org/abs/1907.10786
AUTHORS:        Yujun Shen ; Jinjin Gu ; Xiaoou Tang ; Bolei Zhou
COMMENTS:       CVPR2020 camera-ready
HIGHLIGHT:      In this work, we propose a novel framework, called InterFaceGAN, for semantic face editing by interpreting the latent semantics learned by GANs.

38, TITLE:      Learning Fast and Robust Target Models for Video Object Segmentation
http://arxiv.org/abs/2003.00908
AUTHORS:        Andreas Robinson ; Felix Järemo Lawin ; Martin Danelljan ; Fahad Shahbaz Khan ; Michael Felsberg
COMMENTS:       CVPR 2020. arXiv admin note: substantial text overlap with arXiv:1904.08630
HIGHLIGHT:      We propose a novel VOS architecture consisting of two network components.

39, TITLE:      Image Processing Using Multi-Code GAN Prior
http://arxiv.org/abs/1912.07116
AUTHORS:        Jinjin Gu ; Yujun Shen ; Bolei Zhou
COMMENTS:       CVPR2020 camera-ready
HIGHLIGHT:      In this work, we propose a novel approach, called mGANprior, to incorporate the well-trained GANs as effective prior to a variety of image processing tasks.

40, TITLE:      Random CapsNet Forest Model for Imbalanced Malware Type Classification Task
http://arxiv.org/abs/1912.10836
AUTHORS:        Aykut Çayır ; Uğur Ünal ; Hasan Dağ
COMMENTS:       22 pages, 9 figures, typos are corrected, references are added
HIGHLIGHT:      This paper proposes an ensemble capsule network model based on bootstrap aggregating technique.

41, TITLE:      VOR Adaptation on a Humanoid iCub Robot Using a Spiking Cerebellar Model
http://arxiv.org/abs/2003.01409
AUTHORS:        Francisco Naveros ; Niceto R. Luque ; Eduardo Ros ; Angelo Arleo
HIGHLIGHT:      We aim to elucidate the manner in which the combination of the cerebellar neural substrate and the distributed plasticity shapes the cerebellar neural activity to mediate motor adaptation.

42, TITLE:      Inexact Proximal-Point Penalty Methods for Constrained Non-Convex Optimization
http://arxiv.org/abs/1908.11518
AUTHORS:        Qihang Lin ; Runchao Ma ; Yangyang Xu
COMMENTS:       submitted to journal; corrected a few ? in references
HIGHLIGHT:      In this paper, an inexact proximal-point penalty method is studied for constrained optimization problems, where the objective function is non-convex, and the constraint functions can also be non-convex.

43, TITLE:      REST: A Thread Embedding Approach for Identifying and Classifying User-specified Information in Security Forums
http://arxiv.org/abs/2001.02660
AUTHORS:        Joobin Gharibshah ; Evangelos E. Papalexakis ; Michalis Faloutsos
COMMENTS:       Accepted in ICWSM 2020
HIGHLIGHT:      We propose, REST, a systematic methodology to: (a) identify threads of interest based on a, possibly incomplete, bag of words, and (b) classify them into one of the four classes above.

44, TITLE:      NP-completeness of the game Kingdomino
http://arxiv.org/abs/1909.02849
AUTHORS:        Viet-Ha Nguyen ; Kevin Perrot ; Mathieu Vallet
HIGHLIGHT:      We prove that even with full knowledge of the future of the game, in order to maximize their score at Kingdomino, players are faced with an NP-complete optimization problem.

45, TITLE:      Peeking into occluded joints: A novel framework for crowd pose estimation
http://arxiv.org/abs/2003.10506
AUTHORS:        Lingteng Qiu ; Xuanye Zhang ; Yanran Li ; Guanbin Li ; Xiaojun Wu ; Zixiang Xiong ; Xiaoguang Han ; Shuguang Cui
COMMENTS:       The code of OPEC-Net is available at: https://lingtengqiu.github.io/2020/03/22/OPEC-Net/
HIGHLIGHT:      Therefore, we thoroughly pursue this problem and propose a novel OPEC-Net framework together with a new Occluded Pose (OCPose) dataset with 9k annotated images.

46, TITLE:      Few-Shot Object Detection with Attention-RPN and Multi-Relation Detector
http://arxiv.org/abs/1908.01998
AUTHORS:        Qi Fan ; Wei Zhuo ; Chi-Keung Tang ; Yu-Wing Tai
COMMENTS:       CVPR2020 Camera Ready. (Fix Figure 3 and Table 5. More implementation details in the supplementary material.)
HIGHLIGHT:      In this paper, we propose a novel few-shot object detection network that aims at detecting objects of unseen categories with only a few annotated examples.

47, TITLE:      Learning to Discriminate Information for Online Action Detection
http://arxiv.org/abs/1912.04461
AUTHORS:        Hyunjun Eun ; Jinyoung Moon ; Jongyoul Park ; Chanho Jung ; Changick Kim
COMMENTS:       To appear in CVPR 2020
HIGHLIGHT:      For online action detection, in this paper, we propose a novel recurrent unit to explicitly discriminate the information relevant to an ongoing action from others.

48, TITLE:      Active stereo vision three-dimensional reconstruction by RGB dot pattern projection and ray intersection
http://arxiv.org/abs/2003.13322
AUTHORS:        Yongcan Shuang ; Zhenzhou Wang
HIGHLIGHT:      In this paper, we propose a new pattern extraction method and a new stereo vision matching method based on our novel structured light pattern.

49, TITLE:      ParSeNet: A Parametric Surface Fitting Network for 3D Point Clouds
http://arxiv.org/abs/2003.12181
AUTHORS:        Gopal Sharma ; Difan Liu ; Evangelos Kalogerakis ; Subhransu Maji ; Siddhartha Chaudhuri ; Radomír Měch
HIGHLIGHT:      We propose a novel, end-to-end trainable, deep network called ParSeNet that decomposes a 3D point cloud into parametric surface patches, including B-spline patches as well as basic geometric primitives.

50, TITLE:      Adversarial Imitation Attack
http://arxiv.org/abs/2003.12760
AUTHORS:        Mingyi Zhou ; Jing Wu ; Yipeng Liu ; Xiaolin Huang ; Shuaicheng Liu ; Xiang Zhang ; Ce Zhu
COMMENTS:       8 pages
HIGHLIGHT:      In this study, we propose a novel adversarial imitation attack.

51, TITLE:      Sideways: Depth-Parallel Training of Video Models
http://arxiv.org/abs/2001.06232
AUTHORS:        Mateusz Malinowski ; Grzegorz Swirszcz ; Joao Carreira ; Viorica Patraucean
COMMENTS:       Accepted at CVPR'20
HIGHLIGHT:      We propose Sideways, an approximate backpropagation scheme for training video models.

52, TITLE:      Public Bayesian Persuasion: Being Almost Optimal and Almost Persuasive
http://arxiv.org/abs/2002.05156
AUTHORS:        Matteo Castiglioni ; Andrea Celli ; Nicola Gatti
HIGHLIGHT:      We focus on the fundamental multi-receiver model by Arieli and Babichenko (2019), in which there are no inter-agent externalities.

53, TITLE:      Unsupervised Learning of Probably Symmetric Deformable 3D Objects from Images in the Wild
http://arxiv.org/abs/1911.11130
AUTHORS:        Shangzhe Wu ; Christian Rupprecht ; Andrea Vedaldi
COMMENTS:       CVPR 2020 Oral. Project page: https://elliottwu.com/projects/unsup3d/
HIGHLIGHT:      We propose a method to learn 3D deformable object categories from raw single-view images, without external supervision.

54, TITLE:      Semantically Multi-modal Image Synthesis
http://arxiv.org/abs/2003.12697
AUTHORS:        Zhen Zhu ; Zhiliang Xu ; Ansheng You ; Xiang Bai
COMMENTS:       To appear in CVPR 2020
HIGHLIGHT:      In this paper, we focus on semantically multi-modal image synthesis (SMIS) task, namely, generating multi-modal images at the semantic level.

55, TITLE:      Towards Optimal Off-Policy Evaluation for Reinforcement Learning with Marginalized Importance Sampling
http://arxiv.org/abs/1906.03393
AUTHORS:        Tengyang Xie ; Yifei Ma ; Yu-Xiang Wang
COMMENTS:       Published at the Neural Information Processing Systems (NeurIPS) 2019
HIGHLIGHT:      Motivated by the many real-world applications of reinforcement learning (RL) that require safe-policy iterations, we consider the problem of off-policy evaluation (OPE) -- the problem of evaluating a new policy using the historical data obtained by different behavior policies -- under the model of nonstationary episodic Markov Decision Processes (MDP) with a long horizon and a large action space.

56, TITLE:      Balanced One-shot Neural Architecture Optimization
http://arxiv.org/abs/1909.10815
AUTHORS:        Renqian Luo ; Tao Qin ; Enhong Chen
COMMENTS:       Code and model checkpoints are publicly available at https://github.com/renqianluo/NAO_pytorch
HIGHLIGHT:      Consequently, we propose Balanced NAO where we introduce balanced training of the supernet during the search procedure to encourage more updates for large architectures than small architectures by sampling architectures in proportion to their model sizes.

57, TITLE:      Large-scale Pretraining for Visual Dialog: A Simple State-of-the-Art Baseline
http://arxiv.org/abs/1912.02379
AUTHORS:        Vishvak Murahari ; Dhruv Batra ; Devi Parikh ; Abhishek Das
HIGHLIGHT:      Instead, we present an approach to leverage pretraining on related vision-language datasets before transferring to visual dialog.

58, TITLE:      Seeing Around Street Corners: Non-Line-of-Sight Detection and Tracking In-the-Wild Using Doppler Radar
http://arxiv.org/abs/1912.06613
AUTHORS:        Nicolas Scheiner ; Florian Kraus ; Fangyin Wei ; Buu Phan ; Fahim Mannan ; Nils Appenrodt ; Werner Ritter ; Jürgen Dickmann ; Klaus Dietmayer ; Bernhard Sick ; Felix Heide
COMMENTS:       First three authors contributed equally; Accepted at CVPR 2020
HIGHLIGHT:      In this work, we depart from visible-wavelength approaches and demonstrate detection, classification, and tracking of hidden objects in large-scale dynamic environments using Doppler radars that can be manufactured at low-cost in series production.

59, TITLE:      Cross-Spectral Face Hallucination via Disentangling Independent Factors
http://arxiv.org/abs/1909.04365
AUTHORS:        Boyan Duan ; Chaoyou Fu ; Yi Li ; Xingguang Song ; Ran He
HIGHLIGHT:      Rather than building a monolithic but complex structure, this paper proposes a Pose Aligned Cross-spectral Hallucination (PACH) approach to disentangle the independent factors and deal with them in individual stages.

60, TITLE:      Rethinking Depthwise Separable Convolutions: How Intra-Kernel Correlations Lead to Improved MobileNets
http://arxiv.org/abs/2003.13549
AUTHORS:        Daniel Haase ; Manuel Amthor
COMMENTS:       Accepted by CVPR 2020
HIGHLIGHT:      We introduce blueprint separable convolutions (BSConv) as highly efficient building blocks for CNNs.

61, TITLE:      Benchmarking Robustness in Object Detection: Autonomous Driving when Winter is Coming
http://arxiv.org/abs/1907.07484
AUTHORS:        Claudio Michaelis ; Benjamin Mitzkus ; Robert Geirhos ; Evgenia Rusak ; Oliver Bringmann ; Alexander S. Ecker ; Matthias Bethge ; Wieland Brendel
COMMENTS:       21 pages, 10 figures, 1 dragon
HIGHLIGHT:      We here provide an easy-to-use benchmark to assess how object detection models perform when image quality degrades.

62, TITLE:      Image Generation Via Minimizing Fréchet Distance in Discriminator Feature Space
http://arxiv.org/abs/2003.11774
AUTHORS:        Khoa D. Doan ; Saurav Manchanda ; Fengjiao Wang ; Sathiya Keerthi ; Avradeep Bhowmik ; Chandan K. Reddy
HIGHLIGHT:      We propose an efficient, numerically stable approach to calculate the Fr\'{e}chet distance and its gradient.

63, TITLE:      xMUDA: Cross-Modal Unsupervised Domain Adaptation for 3D Semantic Segmentation
http://arxiv.org/abs/1911.12676
AUTHORS:        Maximilian Jaritz ; Tuan-Hung Vu ; Raoul de Charette ; Émilie Wirbel ; Patrick Pérez
COMMENTS:       Accepted at CVPR 2020. For a demo video, see http://tiny.cc/xmuda
HIGHLIGHT:      In this work, we explore how to learn from multi-modality and propose cross-modal UDA (xMUDA) where we assume the presence of 2D images and 3D point clouds for 3D semantic segmentation.

64, TITLE:      ManiGAN: Text-Guided Image Manipulation
http://arxiv.org/abs/1912.06203
AUTHORS:        Bowen Li ; Xiaojuan Qi ; Thomas Lukasiewicz ; Philip H. S. Torr
COMMENTS:       CVPR 2020
HIGHLIGHT:      The goal of our paper is to semantically edit parts of an image matching a given text that describes desired attributes (e.g., texture, colour, and background), while preserving other contents that are irrelevant to the text.

65, TITLE:      Big Transfer (BiT): General Visual Representation Learning
http://arxiv.org/abs/1912.11370
AUTHORS:        Alexander Kolesnikov ; Lucas Beyer ; Xiaohua Zhai ; Joan Puigcerver ; Jessica Yung ; Sylvain Gelly ; Neil Houlsby
COMMENTS:       The first three authors contributed equally. Low data regime results are updated in v2 due to a bug in the data input pipeline
HIGHLIGHT:      We scale up pre-training, and propose a simple recipe that we call Big Transfer (BiT).

66, TITLE:      HybridPose: 6D Object Pose Estimation under Hybrid Representations
http://arxiv.org/abs/2001.01869
AUTHORS:        Chen Song ; Jiaru Song ; Qixing Huang
HIGHLIGHT:      We introduce HybridPose, a novel 6D object pose estimation approach.

67, TITLE:      MERL: Multi-Head Reinforcement Learning
http://arxiv.org/abs/1909.11939
AUTHORS:        Yannis Flet-Berliac ; Philippe Preux
COMMENTS:       Deep Reinforcement Learning Workshop, NeurIPS 2019
HIGHLIGHT:      Taking advantage of $\mathcal{V}^{ex}$, we propose MERL, a general framework for structuring reinforcement learning by injecting problem knowledge into policy gradient updates.

68, TITLE:      Distant Supervision and Noisy Label Learning for Low Resource Named Entity Recognition: A Study on Hausa and Yorùbá
http://arxiv.org/abs/2003.08370
AUTHORS:        David Ifeoluwa Adelani ; Michael A. Hedderich ; Dawei Zhu ; Esther van den Berg ; Dietrich Klakow
COMMENTS:       Accepted to ICLR 2020 Workshop
HIGHLIGHT:      In this work, we perform named entity recognition for Hausa and Yor\`ub\'a, two languages that are widely spoken in several developing countries.

69, TITLE:      Improving the Robustness of Capsule Networks to Image Affine Transformations
http://arxiv.org/abs/1911.07968
AUTHORS:        Jindong Gu ; Volker Tresp
HIGHLIGHT:      On our benchmark task, where models are trained on the MNIST dataset and tested on the AffNIST dataset, our Aff-CapsNets improve the benchmark performance by a large margin (from 79% to 93.21%), without using any routing mechanism.

70, TITLE:      Learning multiview 3D point cloud registration
http://arxiv.org/abs/2001.05119
AUTHORS:        Zan Gojcic ; Caifa Zhou ; Jan D. Wegner ; Leonidas J. Guibas ; Tolga Birdal
COMMENTS:       CVPR2020 - Camera Ready
HIGHLIGHT:      We present a novel, end-to-end learnable, multiview 3D point cloud registration algorithm.

71, TITLE:      ASR is all you need: cross-modal distillation for lip reading
http://arxiv.org/abs/1911.12747
AUTHORS:        Triantafyllos Afouras ; Joon Son Chung ; Andrew Zisserman
COMMENTS:       ICASSP 2020
HIGHLIGHT:      The goal of this work is to train strong models for visual speech recognition without requiring human annotated ground truth data.

72, TITLE:      SketchyCOCO: Image Generation from Freehand Scene Sketches
http://arxiv.org/abs/2003.02683
AUTHORS:        Chengying Gao ; Qi Liu ; Qi Xu ; Limin Wang ; Jianzhuang Liu ; Changqing Zou
HIGHLIGHT:      We introduce the first method for automatic image generation from scene-level freehand sketches. We have built a large-scale composite dataset called SketchyCOCO to support and evaluate the solution.

73, TITLE:      DaST: Data-free Substitute Training for Adversarial Attacks
http://arxiv.org/abs/2003.12703
AUTHORS:        Mingyi Zhou ; Jing Wu ; Yipeng Liu ; Shuaicheng Liu ; Ce Zhu
COMMENTS:       Accepted by CVPR2020
HIGHLIGHT:      In this paper, we propose a data-free substitute training method (DaST) to obtain substitute models for adversarial black-box attacks without the requirement of any real data.

74, TITLE:      On the Detection of Digital Face Manipulation
http://arxiv.org/abs/1910.01717
AUTHORS:        Hao Dang ; Feng Liu ; Joel Stehouwer ; Xiaoming Liu ; Anil Jain
COMMENTS:       To appear in CVPR 2020
HIGHLIGHT:      Instead of simply using multi-task learning to simultaneously detect manipulated images and predict the manipulated mask (regions), we propose to utilize an attention mechanism to process and improve the feature maps for the classification task. To enable our study of manipulated face detection and localization, we collect a large-scale database that contains numerous types of facial forgeries.

75, TITLE:      Generating Accurate Pseudo-labels in Semi-Supervised Learning and Avoiding Overconfident Predictions via Hermite Polynomial Activations
http://arxiv.org/abs/1909.05479
AUTHORS:        Vishnu Suresh Lokhande ; Songwong Tasneeyapant ; Abhay Venkatesh ; Sathya N. Ravi ; Vikas Singh
COMMENTS:       Accepted at 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)
HIGHLIGHT:      Motivated by some of these results, we explore the use of Hermite polynomial expansions as a substitute for ReLUs in deep networks.

76, TITLE:      Few-Shot Learning via Embedding Adaptation with Set-to-Set Functions
http://arxiv.org/abs/1812.03664
AUTHORS:        Han-Jia Ye ; Hexiang Hu ; De-Chuan Zhan ; Fei Sha
COMMENTS:       Accepted by CVPR 2020; The code is available at https://github.com/Sha-Lab/FEAT
HIGHLIGHT:      In this paper, we propose a novel approach to adapt the instance embeddings to the target classification task with a set-to-set function, yielding embeddings that are task-specific and are discriminative.

77, TITLE:      Learning for Video Compression with Hierarchical Quality and Recurrent Enhancement
http://arxiv.org/abs/2003.01966
AUTHORS:        Ren Yang ; Fabian Mentzer ; Luc Van Gool ; Radu Timofte
COMMENTS:       Published in CVPR 2020
HIGHLIGHT:      In this paper, we propose a Hierarchical Learned Video Compression (HLVC) method with three hierarchical quality layers and a recurrent enhancement network.

78, TITLE:      COVID-Net: A Tailored Deep Convolutional Neural Network Design for Detection of COVID-19 Cases from Chest Radiography Images
http://arxiv.org/abs/2003.09871
AUTHORS:        Linda Wang ; Alexander Wong
COMMENTS:       7 pages
HIGHLIGHT:      Therefore, in this study we introduce COVID-Net, a deep convolutional neural network design tailored for the detection of COVID-19 cases from chest radiography images that is open source and available to the general public.

79, TITLE:      Optimization of Operation Strategy for Primary Torque based hydrostatic Drivetrain using Artificial Intelligence
http://arxiv.org/abs/2003.10011
AUTHORS:        Yusheng Xiang ; Marcus Geimer
COMMENTS:       9 pages, 23 figures
HIGHLIGHT:      Alternatively, we use deep learning algorithms to improve machines' regeneration performance.
