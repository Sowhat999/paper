==========New Papers==========
1, TITLE:       Improving Vision-and-Language Navigation with Image-Text Pairs from the Web
http://arxiv.org/abs/2004.14973
AUTHORS:        Arjun Majumdar ; Ayush Shrivastava ; Stefan Lee ; Peter Anderson ; Devi Parikh ; Dhruv Batra
HIGHLIGHT:      Specifically, we develop VLN-BERT, a visiolinguistic transformer-based model for scoring the compatibility between an instruction ('...stop at the brown sofa') and a sequence of panoramic RGB images captured by the agent.

2, TITLE:       Learning to Ask Screening Questions for Job Postings
http://arxiv.org/abs/2004.14969
AUTHORS:        Baoxu Shi ; Shan Li ; Jaewon Yang ; Mustafa Emre Kazdagli ; Qi He
COMMENTS:       10 pages, to appear in SIGIR2020
HIGHLIGHT:      To add screening questions to all $20$M active jobs at LinkedIn, we propose a new task that aims to automatically generate screening questions for a given job posting.

3, TITLE:       PlotMachines: Outline-Conditioned Generation with Dynamic Plot State Tracking
http://arxiv.org/abs/2004.14967
AUTHORS:        Hannah Rashkin ; Asli Celikyilmaz ; Yejin Choi ; Jianfeng Gao
HIGHLIGHT:      We present PlotMachines, a neural narrative model that learns to transform an outline into a coherent story by tracking the dynamic plot states.

4, TITLE:       Named Entity Recognition without Labelled Data: A Weak Supervision Approach
http://arxiv.org/abs/2004.14723
AUTHORS:        Pierre Lison ; Aliaksandr Hubin ; Jeremy Barnes ; Samia Touileb
COMMENTS:       Accepted to ACL 2020 (long paper)
HIGHLIGHT:      This paper presents a simple but powerful approach to learn NER models in the absence of labelled data through weak supervision.

5, TITLE:       Use of Machine Translation to Obtain Labeled Datasets for Resource-Constrained Languages
http://arxiv.org/abs/2004.14963
AUTHORS:        Emrah Budur ; Rıza Özçelik ; Tunga Güngör ; Christopher Potts
HIGHLIGHT:      In this paper, we offer a positive response to this for natural language inference (NLI) in Turkish.

6, TITLE:       Mutlitask Learning for Cross-Lingual Transfer of Semantic Dependencies
http://arxiv.org/abs/2004.14961
AUTHORS:        Maryam Aminian ; Mohammad Sadegh Rasooli ; Mona Diab
HIGHLIGHT:      We describe a method for developing broad-coverage semantic dependency parsers for languages for which no semantically annotated resource is available.

7, TITLE:       Improving Semantic Segmentation via Self-Training
http://arxiv.org/abs/2004.14960
AUTHORS:        Yi Zhu ; Zhongyue Zhang ; Chongruo Wu ; Zhi Zhang ; Tong He ; Hang Zhang ; R. Manmatha ; Mu Li ; Alexander Smola
HIGHLIGHT:      In this paper, we show that we can obtain state-of-the-art results using a semi-supervised approach, specifically a self-training paradigm.

8, TITLE:       Natural Language Premise Selection: Finding Supporting Statements for Mathematical Text
http://arxiv.org/abs/2004.14959
AUTHORS:        Deborah Ferreira ; Andre Freitas
COMMENTS:       12th Language Resources and Evaluation Conference (LREC), Marseille, France, 2020 (Language Resource Paper)
HIGHLIGHT:      In this work, we propose a new NLP task, the natural premise selection, which is used to retrieve supporting definitions and supporting propositions that are useful for generating an informal mathematical proof for a particular statement.

9, TITLE:       A Call for More Rigor in Unsupervised Cross-lingual Learning
http://arxiv.org/abs/2004.14958
AUTHORS:        Mikel Artetxe ; Sebastian Ruder ; Dani Yogatama ; Gorka Labaka ; Eneko Agirre
COMMENTS:       ACL 2020
HIGHLIGHT:      We review motivations, definition, approaches, and methodology for unsupervised cross-lingual learning and call for a more rigorous position in each of them.

10, TITLE:      Inability of spatial transformations of CNN feature maps to support invariant recognition
http://arxiv.org/abs/2004.14716
AUTHORS:        Ylva Jansson ; Maksim Maydanskiy ; Lukas Finnveden ; Tony Lindeberg
COMMENTS:       22 pages, 3 figures
HIGHLIGHT:      In this paper, we prove that spatial transformations of CNN feature maps cannot align the feature maps of a transformed image to match those of its original, for general affine transformations, unless the extracted features are themselves invariant.

11, TITLE:      Parallel processor scheduling: formulation as multi-objective linguistic optimization and solution using Perceptual Reasoning based methodology
http://arxiv.org/abs/2004.14955
AUTHORS:        Prashant K Gupta ; Pranab K. Muhuri
HIGHLIGHT:      Thus, we feel that our work is novel and will provide directions for the future research.

12, TITLE:      Towards Unsupervised Language Understanding and Generation by Joint Dual Learning
http://arxiv.org/abs/2004.14710
AUTHORS:        Shang-Yu Su ; Chao-Wei Huang ; Yun-Nung Chen
COMMENTS:       Accepted by ACL 2020
HIGHLIGHT:      The prior work is the first attempt that utilized the duality between NLU and NLG to improve the performance via a dual supervised learning framework.

13, TITLE:      How do Decisions Emerge across Layers in Neural Models? Interpretation with Differentiable Masking
http://arxiv.org/abs/2004.14992
AUTHORS:        Nicola De Cao ; Michael Schlichtkrull ; Wilker Aziz ; Ivan Titov
COMMENTS:       19 pages, 14 figures, 4 tables
HIGHLIGHT:      To deal with these two challenges, we introduce Differentiable Masking.

14, TITLE:      Proceedings 16th International Conference on Quantum Physics and Logic
http://arxiv.org/abs/2004.14750
AUTHORS:        Bob Coecke ; Matthew Leifer
HIGHLIGHT:      Work that applies structures and methods inspired by quantum theory to other fields (including computer science) is also welcome.

15, TITLE:      Counterfactual Off-Policy Training for Neural Response Generation
http://arxiv.org/abs/2004.14507
AUTHORS:        Qingfu Zhu ; Weinan Zhang ; Ting Liu ; William Yang Wang
HIGHLIGHT:      In this paper, we propose a counterfactual off-policy method to learn on a better synthesis of data.

16, TITLE:      Explicit Representation of the Translation Space: Automatic Paraphrasing for Machine Translation Evaluation
http://arxiv.org/abs/2004.14989
AUTHORS:        Rachel Bawden ; Biao Zhang ; Lisa Yankovskaya ; Andre Tättar ; Matt Post
HIGHLIGHT:      We compare both approaches to human-produced references in terms of diversity and the improvement in BLEU's correlation with human judgements of MT quality.

17, TITLE:      Pedestrian Path, Pose and Intention Prediction through Gaussian Process Dynamical Models and Pedestrian Activity Recognition
http://arxiv.org/abs/2004.14747
AUTHORS:        Raul Quintero ; Ignacio Parra ; David Fernandez Llorca ; Miguel Angel Sotelo
COMMENTS:       12 pages
HIGHLIGHT:      For this reason, this paper proposes a method to predict future pedestrian paths, poses and intentions up to 1s in advance.

18, TITLE:      Zero-shot Neural Retrieval via Domain-targeted Synthetic Query Generation
http://arxiv.org/abs/2004.14503
AUTHORS:        Ji Ma ; Ivan Korotkov ; Yinfei Yang ; Keith Hall ; Ryan McDonald
COMMENTS:       5 pages, 2 figures
HIGHLIGHT:      In this paper, we pro-pose an approach to zero-shot learning (Xianet al., 2018) for ad-hoc retrieval models that relies on synthetic query generation.

19, TITLE:      Posterior Calibrated Training on Sentence Classification Tasks
http://arxiv.org/abs/2004.14500
AUTHORS:        Taehee Jung ; Dongyeop Kang ; Hua Cheng ; Lucas Mentch ; Thomas Schaaf
COMMENTS:       Accepted at ACL 2020
HIGHLIGHT:      Here we propose an end-to-end training procedure called posterior calibrated (PosCal) training that directly optimizes the objective while minimizing the difference between the predicted and empirical posterior probabilities.We show that PosCal not only helps reduce the calibration error but also improve task performance by penalizing drops in performance of both objectives.

20, TITLE:      Control, Generate, Augment: A Scalable Framework for Multi-Attribute Text Generation
http://arxiv.org/abs/2004.14983
AUTHORS:        Giuseppe Russo ; Nora Hollenstein ; Claudiu Musat ; Ce Zhang
HIGHLIGHT:      In this work, we present a text generation approach with multi-attribute control for data augmentation.

21, TITLE:      Paraphrasing vs Coreferring: Two Sides of the Same Coin
http://arxiv.org/abs/2004.14979
AUTHORS:        Yehudit Meged ; Avi Caciularu ; Vered Shwartz ; Ido Dagan
HIGHLIGHT:      We study the potential synergy between two different NLP tasks, both confronting lexical variability: identifying predicate paraphrases and event coreference resolution.

22, TITLE:      Proceedings Eighth Workshop on Mathematically Structured Functional Programming
http://arxiv.org/abs/2004.14735
AUTHORS:        Max S. New ; Sam Lindley
HIGHLIGHT:      The MSFP workshop highlights applications of mathematical structures to programming applications.

23, TITLE:      Investigating Transferability in Pretrained Language Models
http://arxiv.org/abs/2004.14975
AUTHORS:        Alex Tamkin ; Trisha Singh ; Davide Giovanardi ; Noah Goodman
HIGHLIGHT:      To address this question, we compare probing with a different measure of transferability: the decrease in finetuning performance of a partially-reinitialized model.

24, TITLE:      Fact or Fiction: Verifying Scientific Claims
http://arxiv.org/abs/2004.14974
AUTHORS:        David Wadden ; Kyle Lo ; Lucy Lu Wang ; Shanchuan Lin ; Madeleine van Zuylen ; Arman Cohan ; Hannaneh Hajishirzi
COMMENTS:       16 pages (including appendices), 10 figures, 7 tables. Website: https://scifact.apps.allenai.org. GitHub: https://github.com/allenai/scifact
HIGHLIGHT:      We present a baseline model and assess its performance on SciFact.

25, TITLE:      Hierarchical Encoders for Modeling and Interpreting Screenplays
http://arxiv.org/abs/2004.14532
AUTHORS:        Gayatri Bhat ; Avneesh Saluja ; Melody Dye ; Jan Florjanczyk
COMMENTS:       12 pages, including references and appendix
HIGHLIGHT:      In this work, we propose a neural architecture for encoding this structure, which performs robustly on a pair of multi-label tag classification datasets, without the need for handcrafted features.

26, TITLE:      Stay Hungry, Stay Focused: Generating Informative and Specific Questions in Information-Seeking Conversations
http://arxiv.org/abs/2004.14530
AUTHORS:        Peng Qi ; Yuhao Zhang ; Christopher D. Manning
HIGHLIGHT:      To generate pragmatic questions, we use reinforcement learning to optimize an informativeness metric we propose, combined with a reward function designed to promote more specific questions.

27, TITLE:      Bias-corrected estimator for intrinsic dimension and differential entropy--a visual multiscale approach
http://arxiv.org/abs/2004.14528
AUTHORS:        Jugurta Montalvão ; Jânio Canuto ; Luiz Miranda
COMMENTS:       10 pages, 11 figures
HIGHLIGHT:      Intrinsic dimension and differential entropy estimators are studied in this paper, including their systematic bias.

28, TITLE:      Conditional Augmentation for Aspect Term Extraction via Masked Sequence-to-Sequence Generation
http://arxiv.org/abs/2004.14769
AUTHORS:        Kun Li ; Chengbo Chen ; Xiaojun Quan ; Qing Ling ; Yan Song
COMMENTS:       To appear at ACL 2020
HIGHLIGHT:      In this paper, we formulate the data augmentation as a conditional generation task: generating a new sentence while preserving the original opinion targets and labels.

29, TITLE:      MobileDets: Searching for Object Detection Architectures for Mobile Accelerators
http://arxiv.org/abs/2004.14525
AUTHORS:        Yunyang Xiong ; Hanxiao Liu ; Suyog Gupta ; Berkin Akin ; Gabriel Bender ; Pieter-Jan Kindermans ; Mingxing Tan ; Vikas Singh ; Bo Chen
HIGHLIGHT:      In this work, we question the optimality of this design pattern over a broad range of mobile accelerators by revisiting the usefulness of regular convolutions.

30, TITLE:      Simulated Multiple Reference Training Improves Low-Resource Machine Translation
http://arxiv.org/abs/2004.14524
AUTHORS:        Huda Khayrallah ; Brian Thompson ; Matt Post ; Philipp Koehn
HIGHLIGHT:      We introduce a novel MT training method that approximates the full space of possible translations by: sampling a paraphrase of the reference sentence from a paraphraser and training the MT model to predict the paraphraser's distribution over possible tokens.

31, TITLE:      Exploiting Sentence Order in Document Alignment
http://arxiv.org/abs/2004.14523
AUTHORS:        Brian Thompson ; Philipp Koehn
HIGHLIGHT:      In this work, we exploit the simple idea that a document and its translation should contain approximately the same information, in approximately the same order.

32, TITLE:      Pruning artificial neural networks: a way to find well-generalizing, high-entropy sharp minima
http://arxiv.org/abs/2004.14765
AUTHORS:        Enzo Tartaglione ; Andrea Bragagnolo ; Marco Grangetto
HIGHLIGHT:      In this work, we are going to compare and analyze pruned solutions with two different pruning approaches, one-shot and gradual, showing the higher effectiveness of the latter.

33, TITLE:      A Focused Study to Compare Arabic Pre-training Models on Newswire IE Tasks
http://arxiv.org/abs/2004.14519
AUTHORS:        Wuwei Lan ; Yang Chen ; Wei Xu ; Alan Ritter
HIGHLIGHT:      In this work, we pre-train a Gigaword-based bilingual language model (GigaBERT) to study these two distant languages as well as zero-short transfer learning on the information extraction tasks.

34, TITLE:      Bilingual Text Extraction as Reading Comprehension
http://arxiv.org/abs/2004.14517
AUTHORS:        Katsuki Chousa ; Masaaki Nagata ; Masaaki Nishino
COMMENTS:       7 pages
HIGHLIGHT:      In this paper, we propose a method to extract bilingual texts automatically from noisy parallel corpora by framing the problem as a token-level span prediction, such as SQuAD-style Reading Comprehension.

35, TITLE:      A Supervised Word Alignment Method based on Cross-Language Span Prediction using Multilingual BERT
http://arxiv.org/abs/2004.14516
AUTHORS:        Masaaki Nagata ; Chousa Katsuki ; Masaaki Nishino
HIGHLIGHT:      We present a novel supervised word alignment method based on cross-language span prediction.

36, TITLE:      Preventing Posterior Collapse with Levenshtein Variational Autoencoder
http://arxiv.org/abs/2004.14758
AUTHORS:        Serhii Havrylov ; Ivan Titov
HIGHLIGHT:      In our Levenstein VAE, we propose to replace the evidence lower bound (ELBO) with a new objective which is simple to optimize and prevents posterior collapse.

37, TITLE:      A Matter of Framing: The Impact of Linguistic Formalism on Probing Results
http://arxiv.org/abs/2004.14999
AUTHORS:        Ilia Kuznetsov ; Iryna Gurevych
HIGHLIGHT:      To investigate, we conduct an in-depth cross-formalism layer probing study in role semantics.

38, TITLE:      Instance-Based Learning of Span Representations: A Case Study through Named Entity Recognition
http://arxiv.org/abs/2004.14514
AUTHORS:        Hiroki Ouchi ; Jun Suzuki ; Sosuke Kobayashi ; Sho Yokoi ; Tatsuki Kuribayashi ; Ryuto Konno ; Kentaro Inui
COMMENTS:       Accepted by ACL2020
HIGHLIGHT:      In this study, we develop models possessing interpretable inference process for structured prediction.

39, TITLE:      Robustness Certification of Generative Models
http://arxiv.org/abs/2004.14756
AUTHORS:        Matthew Mirman ; Timon Gehr ; Martin Vechev
COMMENTS:       Prior version submitted to ICLR 2020
HIGHLIGHT:      We present ApproxLine, a scalable certification method that successfully verifies non-trivial specifications involving generative models and classifiers.

40, TITLE:      Asking without Telling: Exploring Latent Ontologies in Contextual Representations
http://arxiv.org/abs/2004.14513
AUTHORS:        Julian Michael ; Jan A. Botha ; Ian Tenney
COMMENTS:       18 pages, 6 figures, 11 tables
HIGHLIGHT:      To investigate this, we introduce latent subclass learning (LSL): a modification to existing classifier-based probing methods that induces a latent categorization (or ontology) of the probe's inputs.

41, TITLE:      SegaBERT: Pre-training of Segment-aware BERT for Language Understanding
http://arxiv.org/abs/2004.14996
AUTHORS:        He Bai ; Peng Shi ; Jimmy Lin ; Luchen Tan ; Kun Xiong ; Wen Gao ; Ming Li
HIGHLIGHT:      To verify this, we propose a segment-aware BERT, by replacing the token position embedding of Transformer with a combination of paragraph index, sentence index, and token index embeddings.

42, TITLE:      Self-Supervised and Controlled Multi-Document Opinion Summarization
http://arxiv.org/abs/2004.14754
AUTHORS:        Hady Elsahar ; Maximin Coavoux ; Matthias Gallé ; Jos Rozen
COMMENTS:       18 pages including 5 pages appendix
HIGHLIGHT:      We propose a self-supervised setup that consider an individual document as a target summary for a set of similar documents.

43, TITLE:      STARC: Structured Annotations for Reading Comprehension
http://arxiv.org/abs/2004.14797
AUTHORS:        Yevgeni Berzak ; Jonathan Malmaud ; Roger Levy
COMMENTS:       ACL 2020. OneStopQA dataset, STARC guidelines and human experiments data are available at https://github.com/berzak/onestop-qa
HIGHLIGHT:      We present STARC (Structured Annotations for Reading Comprehension), a new annotation framework for assessing reading comprehension with multiple choice questions.

44, TITLE:      User-Guided Aspect Classification for Domain-Specific Texts
http://arxiv.org/abs/2004.14555
AUTHORS:        Peiran Li ; Fang Guo ; Jingbo Shang
HIGHLIGHT:      We propose a novel framework, ARYA, which enables mutual enhancements between pre-defined aspects and the misc aspect via iterative classifier training and seed updating.

45, TITLE:      Indirect Identification of Psychosocial Risks from Natural Language
http://arxiv.org/abs/2004.14554
AUTHORS:        Kristen C. Allen ; Alex Davis ; Tamar Krishnamurti
COMMENTS:       12 pages, 4 figures
HIGHLIGHT:      We examine indirect methods of eliciting and analyzing information that could indicate psychosocial risks.

46, TITLE:      A Novel Perspective to Zero-shot Learning: Towards an Alignment of Manifold Structures via Semantic Feature Expansion
http://arxiv.org/abs/2004.14795
AUTHORS:        Jingcai Guo ; Song Guo
HIGHLIGHT:      To address this issue, we propose a novel model called AMS-SFE.

47, TITLE:      Salient Object Detection Combining a Self-attention Module and a Feature Pyramid Network
http://arxiv.org/abs/2004.14552
AUTHORS:        Guangyu Ren ; Tianhong Dai ; Panagiotis Barmpoutis ; Tania Stathaki
HIGHLIGHT:      To this end, in order to overcome this limitation, we propose a novel pyramid self-attention module (PSAM) and the adoption of an independent feature-complementing strategy.

48, TITLE:      Filtering before Iteratively Referring for Knowledge-Grounded Response Selection in Retrieval-Based Chatbots
http://arxiv.org/abs/2004.14550
AUTHORS:        Jia-Chen Gu ; Zhen-Hua Ling ; Quan Liu ; Si Wei ; Xiaodan Zhu
HIGHLIGHT:      This paper proposes a method named Filtering before Iteratively REferring (FIRE) for presenting the background knowledge of dialogue agents in retrieval-based chatbots.

49, TITLE:      Distributional Soft Actor Critic for Risk Sensitive Learning
http://arxiv.org/abs/2004.14547
AUTHORS:        Xiaoteng Ma ; Qiyuan Zhang ; Li Xia ; Zhengyuan Zhou ; Jun Yang ; Qianchuan Zhao
HIGHLIGHT:      In this paper, we present a new RL algorithm named Distributional Soft Actor Critic (DSAC), combining distributional RL and maximum entropy RL together.

50, TITLE:      Character-Level Translation with Self-attention
http://arxiv.org/abs/2004.14788
AUTHORS:        Yingqiang Gao ; Nikola I. Nikolov ; Yuhuang Hu ; Richard H. R. Hahnloser
COMMENTS:       ACL 2020
HIGHLIGHT:      We explore the suitability of self-attention models for character-level neural machine translation.

51, TITLE:      WT5?! Training Text-to-Text Models to Explain their Predictions
http://arxiv.org/abs/2004.14546
AUTHORS:        Sharan Narang ; Colin Raffel ; Katherine Lee ; Adam Roberts ; Noah Fiedel ; Karishma Malkan
HIGHLIGHT:      In this paper, we leverage the text-to-text framework proposed by Raffel et al.(2019) to train language models to output a natural text explanation alongside their prediction.

52, TITLE:      Explainable Deep Learning: A Field Guide for the Uninitiated
http://arxiv.org/abs/2004.14545
AUTHORS:        Ning Xie ; Gabrielle Ras ; Marcel van Gerven ; Derek Doran
COMMENTS:       Survey paper on Explainable Deep Learning, 54 pages including references
HIGHLIGHT:      To alleviate this problem, this article offers a "field guide" to deep learning explainability for those uninitiated in the field.

53, TITLE:      Perturbed Masking: Parameter-free Probing for Analyzing and Interpreting BERT
http://arxiv.org/abs/2004.14786
AUTHORS:        Zhiyong Wu ; Yun Chen ; Ben Kao ; Qun Liu
COMMENTS:       Accepted to ACL2020 as a long paper
HIGHLIGHT:      Complementary to those works, we propose a parameter-free probing technique for analyzing pre-trained language models (e.g., BERT).

54, TITLE:      TextAT: Adversarial Training for Natural Language Understanding with Token-Level Perturbation
http://arxiv.org/abs/2004.14543
AUTHORS:        Linyang Li ; Xipeng Qiu
COMMENTS:       8 pages, 3 figures
HIGHLIGHT:      Therefore, to incorporate adversarial training in sequence-level tasks, we introduce a novel training strategy: Text Adversarial Training with token-level perturbation.

55, TITLE:      Semantic Triple Encoder for Fast Open-Set Link Prediction
http://arxiv.org/abs/2004.14781
AUTHORS:        Bo Wang ; Tao Shen ; Guodong Long ; Tianyi Zhou ; Yi Chang
HIGHLIGHT:      In this paper, we partition each graph triple and develop a novel context-based encoder that separately maps each part and its context into a latent semantic space.

56, TITLE:      Physarum Powered Differentiable Linear Programming Layers and Applications
http://arxiv.org/abs/2004.14539
AUTHORS:        Zihang Meng ; Sathya N. Ravi ; Vikas Singh
HIGHLIGHT:      We propose an efficient and differentiable solver for general linear programming problems which can be used in a plug and play manner within deep neural networks as a layer.

57, TITLE:      Text Segmentation by Cross Segment Attention
http://arxiv.org/abs/2004.14535
AUTHORS:        Michal Lukasik ; Boris Dadachev ; Gonçalo Simões ; Kishore Papineni
COMMENTS:       10 pages, 4 figures
HIGHLIGHT:      In this work, we propose three transformer-based architectures and provide comprehensive comparisons with previously proposed approaches on three standard datasets.

58, TITLE:      MLSUM: The Multilingual Summarization Corpus
http://arxiv.org/abs/2004.14900
AUTHORS:        Thomas Scialom ; Paul-Alexis Dray ; Sylvain Lamprier ; Benjamin Piwowarski ; Jacopo Staiano
HIGHLIGHT:      We present MLSUM, the first large-scale MultiLingual SUMmarization dataset.

59, TITLE:      You are right. I am ALARMED -- But by Climate Change Counter Movement
http://arxiv.org/abs/2004.14907
AUTHORS:        Shraey Bhatia ; Jey Han Lau ; Timothy Baldwin
COMMENTS:       5 pages
HIGHLIGHT:      These articles are carefully constructed by climate change counter movement (cccm) organizations to influence the narrative around climate change.

60, TITLE:      Modelling Suspense in Short Stories as Uncertainty Reduction over Neural Representation
http://arxiv.org/abs/2004.14905
AUTHORS:        David Wilmot ; Frank Keller
COMMENTS:       9 pages, 3 figures, accepted as long paper to ACL 2020
HIGHLIGHT:      We propose a hierarchical language model that encodes stories and computes surprise and uncertainty reduction.

61, TITLE:      Bridging linguistic typology and multilingual machine translation with multi-view language representations
http://arxiv.org/abs/2004.14923
AUTHORS:        Arturo Oncevay ; Barry Haddow ; Alexandra Birch
COMMENTS:       15 pages, 6 figures
HIGHLIGHT:      We propose to fuse both views using singular vector canonical correlation analysis and study what kind of information is induced from each source.

62, TITLE:      Language Model Prior for Low-Resource Neural Machine Translation
http://arxiv.org/abs/2004.14928
AUTHORS:        Christos Baziotis ; Barry Haddow ; Alexandra Birch
HIGHLIGHT:      In this work, we propose a novel approach to incorporate a LM as prior in a neural translation model (TM).

63, TITLE:      Addressing Zero-Resource Domains Using Document-Level Context in Neural Machine Translation
http://arxiv.org/abs/2004.14927
AUTHORS:        Dario Stojanovski ; Alexander Fraser
HIGHLIGHT:      We present two document-level Transformer models which are capable of using large context sizes and we compare these models against strong Transformer baselines.

64, TITLE:      Tired of Topic Models? Clusters of Pretrained Word Embeddings Make for Fast and Good Topics too!
http://arxiv.org/abs/2004.14914
AUTHORS:        Suzanna Sia ; Ayush Dalmia ; Sabrina J. Mielke
HIGHLIGHT:      We propose an alternative approach based on clustering readily available pre-trained word embeddings while incorporating document information for weighted clustering and reranking top words. We provide benchmarks for the combination of different word embeddings and clustering algorithms, and analyse their performance under dimensionality reduction with PCA.

65, TITLE:      Recipes for Adapting Pre-trained Monolingual and Multilingual Models to Machine Translation
http://arxiv.org/abs/2004.14911
AUTHORS:        Asa Cooper Stickland ; Xian Li ; Marjan Ghazvininejad
HIGHLIGHT:      This paper investigates the benefits and drawbacks of freezing parameters, and adding new ones, when fine-tuning a pre-trained model on MT. We focus on 1) Fine-tuning a model trained only on English monolingual data, BART.

66, TITLE:      Multi-View Spectral Clustering Tailored Tensor Low-Rank Representation
http://arxiv.org/abs/2004.14705
AUTHORS:        Yuheng Jia ; Hui Liu ; Junhui Hou ; Sam Kwong ; Qingfu Zhang
HIGHLIGHT:      Unlike the existing methods that all adopt an off-the-shelf tensor low-rank norm without considering the special characteristics of the tensor in MVSC, we design a novel structured tensor low-rank norm tailored to MVSC.

67, TITLE:      A Span-based Linearization for Constituent Trees
http://arxiv.org/abs/2004.14704
AUTHORS:        Yang Wei ; Yuanbin Wu ; Man Lan
COMMENTS:       Accepted to ACL 2020
HIGHLIGHT:      We propose a novel linearization of a constituent tree, together with a new locally normalized model.

68, TITLE:      Memristors -- from In-memory computing, Deep Learning Acceleration, Spiking Neural Networks, to the Future of Neuromorphic and Bio-inspired Computing
http://arxiv.org/abs/2004.14942
AUTHORS:        Adnan Mehonic ; Abu Sebastian ; Bipin Rajendran ; Osvaldo Simeone ; Eleni Vasilaki ; Anthony J. Kenyon
COMMENTS:       Keywords: memristor, neuromorphic, AI, deep learning, spiking neural networks, in-memory computing
HIGHLIGHT:      This paper reviews the case for a novel beyond CMOS hardware technology, memristors, as a potential solution for the implementation of power-efficient in-memory computing, deep learning accelerators, and spiking neural networks.

69, TITLE:      Generative Adversarial Networks in Digital Pathology: A Survey on Trends and Future Potential
http://arxiv.org/abs/2004.14936
AUTHORS:        Maximilian Ernst Tschuchnig ; Gertie Janneke Oostingh ; Michael Gadermayr
HIGHLIGHT:      In this paper, we focus on a particularly powerful class of architectures, called Generative Adversarial Networks (GANs), applied to histological image data.

70, TITLE:      Perceptual reasoning based solution methodology for linguistic optimization problems
http://arxiv.org/abs/2004.14933
AUTHORS:        Prashant K Gupta ; Pranab K. Muhuri
HIGHLIGHT:      As, the semantics of linguistic information are best modeled using the interval type-2 fuzzy sets, hence we propose solution methodologies for LOPs based on CWW approach of perceptual computing, in this paper.

71, TITLE:      The Complexity of Dynamic Data Race Prediction
http://arxiv.org/abs/2004.14931
AUTHORS:        Umang Mathur ; Andreas Pavlogiannis ; Mahesh Viswanathan
HIGHLIGHT:      In this work, we address this lacuna, identifying sources of intractability and conditions under which the problem is efficiently solvable.

72, TITLE:      PeerNomination: Relaxing Exactness for Increased Accuracy in Peer Selection
http://arxiv.org/abs/2004.14939
AUTHORS:        Nicholas Mattei ; Paolo Turrini ; Stanislav Zhydkov
COMMENTS:       7 pages, 5 figures, submitted to IJCAI 2020
HIGHLIGHT:      Here, we present a novel algorithm for impartial peer selection, PeerNomination, and provide a theoretical analysis of its accuracy.

73, TITLE:      Crisscrossed Captions: Extended Intramodal and Intermodal Semantic Similarity Judgments for MS-COCO
http://arxiv.org/abs/2004.15020
AUTHORS:        Zarana Parekh ; Jason Baldridge ; Daniel Cer ; Austin Waters ; Yinfei Yang
HIGHLIGHT:      To address this gap, we create the \textit{Crisscrossed Captions} (CxC) dataset, extending MS-COCO with new semantic similarity judgments for \textbf{247,315} intra- and inter-modality pairs.

74, TITLE:      Consistent Video Depth Estimation
http://arxiv.org/abs/2004.15021
AUTHORS:        Xuan Luo ; Jia-Bin Huang ; Richard Szeliski ; Kevin Matzen ; Johannes Kopf
COMMENTS:       SIGGRAPH 2020. Video: https://www.youtube.com/watch?v=5Tia2oblJAg Project page: https://roxanneluo.github.io/Consistent-Video-Depth-Estimation/
HIGHLIGHT:      We present an algorithm for reconstructing dense, geometrically consistent depth for all pixels in a monocular video.

75, TITLE:      WiC-TSV: An Evaluation Benchmark for Target Sense Verification of Words in Context
http://arxiv.org/abs/2004.15016
AUTHORS:        Anna Breit ; Artem Revenko ; Kiamehr Rezaee ; Mohammad Taher Pilehvar ; Jose Camacho-Collados
COMMENTS:       10 pages. Reference paper of the SemDeep WiC-TSV challenge: https://competitions.codalab.org/competitions/23683
HIGHLIGHT:      In this paper, we present WiC-TSV (\textit{Target Sense Verification for Words in Context}), a new multi-domain evaluation benchmark for Word Sense Disambiguation (WSD) and Entity Linking (EL).

76, TITLE:      Imitation Attacks and Defenses for Black-box Machine Translation Systems
http://arxiv.org/abs/2004.15015
AUTHORS:        Eric Wallace ; Mitchell Stern ; Dawn Song
HIGHLIGHT:      To mitigate these vulnerabilities, we propose a defense that modifies translation outputs in order to misdirect the optimization of imitation models.

77, TITLE:      SimPropNet: Improved Similarity Propagation for Few-shot Image Segmentation
http://arxiv.org/abs/2004.15014
AUTHORS:        Siddhartha Gairola ; Mayur Hemani ; Ayush Chopra ; Balaji Krishnamurthy
COMMENTS:       An updated version of this work was accepted at IJCAI 2020
HIGHLIGHT:      In this work, we demonstrate gaps in the utilization of this similarity information in existing methods, and present a framework - SimPropNet, to bridge those gaps.

78, TITLE:      When does data augmentation help generalization in NLP?
http://arxiv.org/abs/2004.15012
AUTHORS:        Rohan Jha ; Charles Lovering ; Ellie Pavlick
HIGHLIGHT:      Recent work has proposed using data augmentation--that is, generating training examples on which these weak features fail--as a means of encouraging models to prefer the stronger features.

79, TITLE:      TLDR: Extreme Summarization of Scientific Documents
http://arxiv.org/abs/2004.15011
AUTHORS:        Isabel Cachola ; Kyle Lo ; Arman Cohan ; Daniel S. Weld
HIGHLIGHT:      We introduce TLDR generation for scientific papers, a new automatic summarization task with high source compression requiring expert background knowledge and complex language understanding.

80, TITLE:      From communication complexity to an entanglement spread area law in the ground state of gapped local Hamiltonians
http://arxiv.org/abs/2004.15009
AUTHORS:        Anurag Anshu ; Aram W. Harrow ; Mehdi Soleimanifar
COMMENTS:       29 pages, 1 figure
HIGHLIGHT:      In this work, we make a connection between two seemingly different problems.

81, TITLE:      Lexical Semantic Recognition
http://arxiv.org/abs/2004.15008
AUTHORS:        Nelson F. Liu ; Daniel Hershcovich ; Michael Kranzlein ; Nathan Schneider
COMMENTS:       9 pages, 2 figures
HIGHLIGHT:      We evaluate a neural CRF model along all annotation axes available in version 4.3 of the STREUSLE corpus: lexical unit segmentation (multiword expressions), word-level syntactic tags, and supersense classes for noun, verb, and preposition/possessive units.

82, TITLE:      Exploring Contextualized Neural Language Models for Temporal Dependency Parsing
http://arxiv.org/abs/2004.14577
AUTHORS:        Hayley Ross ; Jonathan Cai ; Bonan Min
HIGHLIGHT:      In this paper, we developed several variants of BERT-based temporal dependency parser, and show that BERT significantly improves temporal dependency parsing (Zhang and Xue,2018a).

83, TITLE:      memeBot: Towards Automatic Image Meme Generation
http://arxiv.org/abs/2004.14571
AUTHORS:        Aadhavan Sadasivam ; Kausic Gunasekar ; Hasan Davulcu ; Yezhou Yang
HIGHLIGHT:      The model learns the dependencies between the meme captions and the meme template images and generates new memes using the learned dependencies.

84, TITLE:      APB2Face: Audio-guided face reenactment with auxiliary pose and blink signals
http://arxiv.org/abs/2004.14569
AUTHORS:        Jiangning Zhang ; Liang Liu ; Zhucun Xue ; Yong Liu
COMMENTS:       ICASSP 2020
HIGHLIGHT:      To solve those problems, we propose a novel deep neural network named APB2Face, which consists of GeometryPredictor and FaceReenactor modules.

85, TITLE:      TRP: Trained Rank Pruning for Efficient Deep Neural Networks
http://arxiv.org/abs/2004.14566
AUTHORS:        Yuhui Xu ; Yuxi Li ; Shuai Zhang ; Wei Wen ; Botao Wang ; Yingyong Qi ; Yiran Chen ; Weiyao Lin ; Hongkai Xiong
COMMENTS:       Accepted by IJCAI2020, An extension version of arXiv:1812.02402
HIGHLIGHT:      We propose Trained Rank Pruning (TRP), which alternates between low rank approximation and training.

86, TITLE:      Boosting Naturalness of Language in Task-oriented Dialogues via Adversarial Training
http://arxiv.org/abs/2004.14565
AUTHORS:        Chenguang Zhu
COMMENTS:       7 pages, 1 figure
HIGHLIGHT:      We propose to integrate adversarial training to produce more human-like responses.

87, TITLE:      Automatic Machine Translation Evaluation in Many Languages via Zero-Shot Paraphrasing
http://arxiv.org/abs/2004.14564
AUTHORS:        Brian Thompson ; Matt Post
HIGHLIGHT:      We propose the use of a sequence-to-sequence paraphraser for automatic machine translation evaluation.

88, TITLE:      RikiNet: Reading Wikipedia Pages for Natural Question Answering
http://arxiv.org/abs/2004.14560
AUTHORS:        Dayiheng Liu ; Yeyun Gong ; Jie Fu ; Yu Yan ; Jiusheng Chen ; Daxin Jiang ; Jiancheng Lv ; Nan Duan
COMMENTS:       Accepted at ACL 2020
HIGHLIGHT:      In this paper, we introduce a new model, called RikiNet, which reads Wikipedia pages for natural question answering.

89, TITLE:      A Multi-scale Optimization Learning Framework for Diffeomorphic Deformable Registration
http://arxiv.org/abs/2004.14557
AUTHORS:        Risheng Liu ; Zi Li ; Yuxi Zhang ; Chenying Zhao ; Hao Huang ; Zhongxuan Luo ; Xin Fan
HIGHLIGHT:      Conventional deformable registration methods aim at solving a specifically designed optimization model on image pairs and offer a rigorous theoretical treatment.

90, TITLE:      EXACT: A collaboration toolset for algorithm-aided annotation of almost everything
http://arxiv.org/abs/2004.14595
AUTHORS:        Christian Marzahl ; Marc Aubreville ; Christof A. Bertram ; Jennifer Maier ; Christian Bergler ; Christine Kröger ; Jörn Voigt ; Robert Klopfleisch ; Andreas Maier
HIGHLIGHT:      We developed the open-source online platform EXACT (EXpert Algorithm Cooperation Tool) that enables the collaborative interdisciplinary analysis of images from different domains online and offline.

91, TITLE:      EnsembleGAN: Adversarial Learning for Retrieval-Generation Ensemble Model on Short-Text Conversation
http://arxiv.org/abs/2004.14592
AUTHORS:        Jiayi Zhang ; Chongyang Tao ; Zhenjing Xu ; Qiaojing Xie ; Wei Chen ; Rui Yan
COMMENTS:       10 pages, SIGIR 2019
HIGHLIGHT:      In this paper, we propose ensembleGAN, an adversarial learning framework for enhancing a retrieval-generation ensemble model in open-domain conversation scenario.

92, TITLE:      Improved Natural Language Generation via Loss Truncation
http://arxiv.org/abs/2004.14589
AUTHORS:        Daniel Kang ; Tatsunori Hashimoto
COMMENTS:       NAACL Camera Ready Submission
HIGHLIGHT:      In this work, we show that the distinguishability of the models and reference serves as a principled and robust alternative for handling invalid references.

93, TITLE:      Out-of-the-box channel pruned networks
http://arxiv.org/abs/2004.14584
AUTHORS:        Ragav Venkatesan ; Gurumurthy Swaminathan ; Xiong Zhou ; Anna Luo
COMMENTS:       Under review at ECCV 2020
HIGHLIGHT:      In this paper, we conduct several baseline experiments and establish that profiles from random channel-wise pruning policies are as good as metric-based ones.

94, TITLE:      Bilateral Attention Network for RGB-D Salient Object Detection
http://arxiv.org/abs/2004.14582
AUTHORS:        Zhao Zhang ; Zheng Lin ; Jun Xu ; Wenda Jin ; Shao-Ping Lu ; Deng-Ping Fan
HIGHLIGHT:      To better explore salient information in both foreground and background regions, this paper proposes a Bilateral Attention Network (BiANet) for the RGB-D SOD task.

95, TITLE:      Feedback U-net for Cell Image Segmentation
http://arxiv.org/abs/2004.14581
AUTHORS:        Eisuke Shibuya ; Kazuhiro Hotta
COMMENTS:       Accepted by CVPR2020 Workshop "Computer Vision for Microscopy Image Analysis (CVMI)"
HIGHLIGHT:      Therefore, in this paper, we propose Feedback U-Net using Convolutional LSTM which is the segmentation method using Convolutional LSTM and feedback process.

96, TITLE:      Logic2Text: High-Fidelity Natural Language Generation from Logical Forms
http://arxiv.org/abs/2004.14579
AUTHORS:        Zhiyu Chen ; Wenhu Chen ; Hanwen Zha ; Xiyou Zhou ; Yunkai Zhang ; Sairam Sundaresan ; William Yang Wang
COMMENTS:       9 pages, 6 figures
HIGHLIGHT:      In this work, we formulate logical level NLG as generation from logical forms in order to obtain controllable, high-fidelity, and faithful generations. We present a new large-scale dataset, \textsc{Logic2Text}, with 10,753 descriptions involving common logic types paired with the underlying logical forms.

97, TITLE:      Few-Shot Natural Language Generation by Rewriting Templates
http://arxiv.org/abs/2004.15006
AUTHORS:        Mihir Kale ; Abhinav Rastogi
HIGHLIGHT:      In this work, we propose a template rewriting method for Natural Language Generation (NLG), where the number of templates scales only linearly with the number of slots.

98, TITLE:      CNN Explainer: Learning Convolutional Neural Networks with Interactive Visualization
http://arxiv.org/abs/2004.15004
AUTHORS:        Zijie J. Wang ; Robert Turko ; Omar Shaikh ; Haekyu Park ; Nilaksh Das ; Fred Hohman ; Minsuk Kahng ; Duen Horng Chau
COMMENTS:       11 pages, 14 figures. For a demo video, see https://youtu.be/udVN7fPvGe0 . For a live demo, visit https://poloclub.github.io/cnn-explainer/
HIGHLIGHT:      We present CNN Explainer, an interactive visualization tool designed for non-experts to learn and examine convolutional neural networks (CNNs), a foundational deep learning model architecture.

99, TITLE:      Word Rotator's Distance: Decomposing Vectors Gives Better Representations
http://arxiv.org/abs/2004.15003
AUTHORS:        Sho Yokoi ; Ryo Takahashi ; Reina Akama ; Jun Suzuki ; Kentaro Inui
HIGHLIGHT:      To solve this, we propose to separate word importance and word meaning by decomposing word vectors into their norm and direction, then compute the alignment-based similarity with the help of earth mover's distance.

100, TITLE:     On the Evaluation of Contextual Embeddings for Zero-Shot Cross-Lingual Transfer Learning
http://arxiv.org/abs/2004.15001
AUTHORS:        Phillip Keung ; Yichao Lu ; Julian Salazar ; Vikas Bhardwaj
HIGHLIGHT:      We show that the standard practice of using English dev accuracy for model selection in the zero-shot setting makes it difficult to obtain reproducible results on the MLDoc and XNLI tasks.

101, TITLE:     6G White Paper on Edge Intelligence
http://arxiv.org/abs/2004.14850
AUTHORS:        Ella Peltonen ; Mehdi Bennis ; Michele Capobianco ; Merouane Debbah ; Aaron Ding ; Felipe Gil-Castiñeira ; Marko Jurmu ; Teemu Karvonen ; Markus Kelanti ; Adrian Kliks ; Teemu Leppänen ; Lauri Lovén ; Tommi Mikkonen ; Ashwin Rao ; Sumudu Samarakoon ; Kari Seppänen ; Paweł Sroka ; Sasu Tarkoma ; Tingting Yang
HIGHLIGHT:      In this white paper we provide a vision for 6G Edge Intelligence.

102, TITLE:     Can Your Context-Aware MT System Pass the DiP Benchmark Tests? : Evaluation Benchmarks for Discourse Phenomena in Machine Translation
http://arxiv.org/abs/2004.14607
AUTHORS:        Prathyusha Jwalapuram ; Barbara Rychalska ; Shafiq Joty ; Dominika Basaj
HIGHLIGHT:      We introduce the first of their kind MT benchmark datasets that aim to track and hail improvements across four main discourse phenomena: anaphora, lexical consistency, coherence and readability, and discourse connective translation.

103, TITLE:     Enriched Pre-trained Transformers for Joint Slot Filling and Intent Detection
http://arxiv.org/abs/2004.14848
AUTHORS:        Momchil Hardalov ; Ivan Koychev ; Preslav Nakov
HIGHLIGHT:      Here, we leverage such model, namely BERT, and we design a novel architecture on top it.

104, TITLE:     The role of context in neural pitch accent detection in English
http://arxiv.org/abs/2004.14846
AUTHORS:        Elizabeth Nielsen ; Mark Steedman ; Sharon Goldwater
HIGHLIGHT:      We propose a new model for pitch accent detection, inspired by the work of Stehwien et al. (2018), who presented a CNN-based model for this task.

105, TITLE:     Dynamic Language Binding in Relational Visual Reasoning
http://arxiv.org/abs/2004.14603
AUTHORS:        Thao Minh Le ; Vuong Le ; Svetha Venkatesh ; Truyen Tran
COMMENTS:       Early version accepted by IJCAI20
HIGHLIGHT:      We present Language-binding Object Graph Network, the first neural reasoning method with dynamic relational structures across both visual and textual domains with applications in visual question answering.

106, TITLE:     Look at the First Sentence: Position Bias in Question Answering
http://arxiv.org/abs/2004.14602
AUTHORS:        Miyoung Ko ; Jinhyuk Lee ; Hyunjae Kim ; Gangwoo Kim ; Jaewoo Kang
COMMENTS:       14 pages
HIGHLIGHT:      In this study, we hypothesize that when the distribution of the answer positions is highly skewed in the training set (e.g., answers lie only in the k-th sentence of each passage), QA models predicting answers as positions learn spurious positional cues and fail to give answers in different positions.

107, TITLE:     Knowledge Graph Embeddings and Explainable AI
http://arxiv.org/abs/2004.14843
AUTHORS:        Federico Bianchi ; Gaetano Rossiello ; Luca Costabello ; Matteo Palmonari ; Pasquale Minervini
COMMENTS:       Federico Bianchi, Gaetano Rossiello, Luca Costabello, Matteo Plamonari, Pasquale Minervini, Knowledge Graph Embeddings and Explainable AI. In: Ilaria Tiddi, Freddy Lecue, Pascal Hitzler (eds.), Knowledge Graphs for eXplainable AI -- Foundations, Applications and Challenges. Studies on the Semantic Web, IOS Press, Amsterdam, 2020
HIGHLIGHT:      In this chapter, we introduce the reader to the concept of knowledge graph embeddings by explaining what they are, how they can be generated and how they can be evaluated.

108, TITLE:     Pretraining on Non-linguistic Structure as a Tool for Analyzing Learning Bias in Language Models
http://arxiv.org/abs/2004.14601
AUTHORS:        Isabel Papadimitriou ; Dan Jurafsky
HIGHLIGHT:      We propose a novel methodology for analyzing the encoding of grammatical structure in neural language models through transfer learning.

109, TITLE:     Accurate Word Alignment Induction from Neural Machine Translation
http://arxiv.org/abs/2004.14837
AUTHORS:        Yun Chen ; Yang Liu ; Guanhua Chen ; Xin Jiang ; Qun Liu
HIGHLIGHT:      In this paper, we show that attention weights do capture accurate word alignment, which could only be revealed if we choose the correct decoding step and layer to induce word alignment.

110, TITLE:     Do Neural Models Learn Systematicity of Monotonicity Inference in Natural Language?
http://arxiv.org/abs/2004.14839
AUTHORS:        Hitomi Yanaka ; Koji Mineshima ; Daisuke Bekki ; Kentaro Inui
COMMENTS:       accepted by ACL2020 as a long paper
HIGHLIGHT:      In this paper, we introduce a method for evaluating whether neural models can learn systematicity of monotonicity inference in natural language, namely, the regularity for performing arbitrary inferences with generalization on composition.

111, TITLE:     Progressive Transformers for End-to-End Sign Language Production
http://arxiv.org/abs/2004.14874
AUTHORS:        Ben Saunders ; Necati Cihan Camgoz ; Richard Bowden
HIGHLIGHT:      In this paper, we propose Progressive Transformers, a novel architecture that can translate from discrete spoken language sentences to continuous 3D skeleton pose outputs representing sign language.

112, TITLE:     Multi-Domain Spoken Language Understanding Using Domain- and Task-Aware Parameterization
http://arxiv.org/abs/2004.14871
AUTHORS:        Libo Qin ; Minheng Ni ; Yue Zhang ; Wanxiang Che ; Yangming Li ; Ting Liu
HIGHLIGHT:      We propose to improve the parameterization of this method by using domain-specific and task-specific model parameters to improve knowledge learning and transfer.

113, TITLE:     Mind Your Inflections! Improving NLP for Non-Standard English with Base-Inflection Encoding
http://arxiv.org/abs/2004.14870
AUTHORS:        Samson Tan ; Shafiq Joty ; Lav R. Varshney ; Min-Yen Kan
HIGHLIGHT:      We introduce a new Base-Inflection Encoding of English text that is achieved by combining linguistic and statistical techniques.

114, TITLE:     CohEval: Benchmarking Coherence Models
http://arxiv.org/abs/2004.14626
AUTHORS:        Tasnim Mohiuddin ; Prathyusha Jwalapuram ; Xiang Lin ; Shafiq Joty
HIGHLIGHT:      In this paper, we propose to benchmark coherence models on a number of synthetic and downstream tasks.

115, TITLE:     Modular Representation Underlies Systematic Generalization in Neural Natural Language Inference Models
http://arxiv.org/abs/2004.14623
AUTHORS:        Atticus Geiger ; Kyle Richardson ; Christopher Potts
HIGHLIGHT:      In this paper, we argue that an essential factor is the ability to form modular representations.

116, TITLE:     Universal Dependencies according to BERT: both more specific and more general
http://arxiv.org/abs/2004.14620
AUTHORS:        Tomasz Limisiewicz ; Rudolf Rosa ; David Mare\v{cek}
HIGHLIGHT:      We suggest a method for relation identification and syntactic tree construction.

117, TITLE:     MuSe 2020 -- The First International Multimodal Sentiment Analysis in Real-life Media Challenge and Workshop
http://arxiv.org/abs/2004.14858
AUTHORS:        Lukas Stappen ; Alice Baird ; Georgios Rizos ; Panagiotis Tzirakis ; Xinchen Du ; Felix Hafner ; Lea Schumann ; Adria Mallol-Ragolta ; Björn W. Schuller ; Iulia Lefter ; Erik Cambria ; Ioannis Kompatsiaris
COMMENTS:       Baseline Paper MuSe 2020, MuSe Workshop Challenge, ACM Multimedia
HIGHLIGHT:      In this paper, we provide detailed information on MuSe-CaR, the first of its kind in-the-wild database, which is utilised for the challenge, as well as the state-of-the-art features and modelling approaches applied.

118, TITLE:     Unsupervised Injection of Knowledge into Dialogue Generation via Language Models
http://arxiv.org/abs/2004.14614
AUTHORS:        Yi-Lin Tuan ; Wei Wei ; William Yang Wang
HIGHLIGHT:      To achieve this, we propose a unified training method, Decoupling, which induces a knowledge-related sentence and couples it with the dialogue history to generate a response in an unsupervised fashion.

119, TITLE:     TACRED Revisited: A Thorough Evaluation of the TACRED Relation Extraction Task
http://arxiv.org/abs/2004.14855
AUTHORS:        Christoph Alt ; Aleksandra Gabryszak ; Leonhard Hennig
COMMENTS:       Accepted at ACL 2020
HIGHLIGHT:      In this paper, we investigate the questions: Have we reached a performance ceiling or is there still room for improvement?

120, TITLE:     The 4th AI City Challenge
http://arxiv.org/abs/2004.14619
AUTHORS:        Milind Naphade ; Shuo Wang ; David Anastasiu ; Zheng Tang ; Ming-Ching Chang ; Xiaodong Yang ; Liang Zheng ; Anuj Sharma ; Rama Chellappa ; Pranamesh Chakraborty
COMMENTS:       Organization summary of the 4th AI City Challenge Workshop @ CVPR 2020
HIGHLIGHT:      The 4th AI City Challenge

121, TITLE:     An empirical study of computing with words approaches for multi-person and single-person systems
http://arxiv.org/abs/2004.14892
AUTHORS:        Prashant K Gupta ; Pranab K. Muhuri
HIGHLIGHT:      Thus, the aim of this work is to empirically establish that EIA is suitable for multi-person systems and HMA for single-person systems.

122, TITLE:     Capsule-Transformer for Neural Machine Translation
http://arxiv.org/abs/2004.14649
AUTHORS:        Sufeng Duan ; Juncheng Cao ; Hai Zhao
HIGHLIGHT:      In this paper, we thus propose the capsule-Transformer, which extends the linear transformation into a more general capsule routing algorithm by taking SAN as a special case of capsule network.

123, TITLE:     Robust Question Answering Through Sub-part Alignment
http://arxiv.org/abs/2004.14648
AUTHORS:        Jifan Chen ; Greg Durrett
HIGHLIGHT:      To make a more robust and understandable QA system, we model question answering as an alignment problem.

124, TITLE:     Bootstrap Latent-Predictive Representations for Multitask Reinforcement Learning
http://arxiv.org/abs/2004.14646
AUTHORS:        Daniel Guo ; Bernardo Avila Pires ; Bilal Piot ; Jean-bastien Grill ; Florent Altché ; Rémi Munos ; Mohammad Gheshlaghi Azar
HIGHLIGHT:      Here we introduce Prediction of Bootstrap Latents (PBL), a simple and flexible self-supervised representation learning algorithm for multitask deep RL.

125, TITLE:     DIABLO: Dictionary-based Attention Block for Deep Metric Learning
http://arxiv.org/abs/2004.14644
AUTHORS:        Pierre Jacob ; David Picard ; Aymeric Histace ; Edouard Klein
COMMENTS:       Pre-print. Accepted for publication at Pattern Recognition Letters
HIGHLIGHT:      In this paper, we propose DIABLO, a dictionary-based attention method for image embedding.

126, TITLE:     Few-Shot Learning for Abstractive Multi-Document Opinion Summarization
http://arxiv.org/abs/2004.14884
AUTHORS:        Arthur Bražinskas ; Mirella Lapata ; Ivan Titov
HIGHLIGHT:      In this work, we show that even a handful of summaries is sufficient to bootstrap generation of the summary text with all expected properties, such as writing style, informativeness, fluency, and sentiment preservation.

127, TITLE:     Towards Embodied Scene Description
http://arxiv.org/abs/2004.14638
AUTHORS:        Sinan Tan ; Huaping Liu ; Di Guo ; Fuchun Sun
HIGHLIGHT:      In this work, we propose the Embodied Scene Description, which exploits the embodiment ability of the agent to find an optimal viewpoint in its environment for scene description tasks.

128, TITLE:     PreCNet: Next Frame Video Prediction Based on Predictive Coding
http://arxiv.org/abs/2004.14878
AUTHORS:        Zdenek Straka ; Tomas Svoboda ; Matej Hoffmann
HIGHLIGHT:      In this work, we transform the seminal model of Rao and Ballard (1999) into a modern deep learning framework while remaining maximally faithful to the original schema.

129, TITLE:     Analyzing the Surprising Variability in Word Embedding Stability Across Languages
http://arxiv.org/abs/2004.14876
AUTHORS:        Laura Burdick ; Jonathan K. Kummerfeld ; Rada Mihalcea
HIGHLIGHT:      To gain further insight into word embeddings in multiple languages, we explore their stability, defined as the overlap between the nearest neighbors of a word in different embedding spaces.

130, TITLE:     Polygonal Building Segmentation by Frame Field Learning
http://arxiv.org/abs/2004.14875
AUTHORS:        Nicolas Girard ; Dmitriy Smirnov ; Justin Solomon ; Yuliya Tarabalka
HIGHLIGHT:      We propose adding a frame field output to a deep image segmentation model for extracting buildings from remote sensing images.

131, TITLE:     End-to-End Neural Word Alignment Outperforms GIZA++
http://arxiv.org/abs/2004.14675
AUTHORS:        Thomas Zenkel ; Joern Wuebker ; John DeNero
COMMENTS:       Accepted at ACL 2020
HIGHLIGHT:      We present the first end-to-end neural word alignment method that consistently outperforms GIZA++ on three data sets.

132, TITLE:     SS3D: Single Shot 3D Object Detector
http://arxiv.org/abs/2004.14674
AUTHORS:        Aniket Limaye ; Manu Mathew ; Soyeb Nagori ; Pramod Kumar Swami ; Debapriya Maji ; Kumar Desappan
HIGHLIGHT:      In this paper we present Single Shot 3D Object Detection (SS3D) - a single stage 3D object detection algorithm which combines a straight forward, statistically computed input representation and a single shot object detector based on PointPillars.

133, TITLE:     Attentive Weakly Supervised land cover mapping for object-based satellite image time series data with spatial interpretation
http://arxiv.org/abs/2004.14672
AUTHORS:        Dino Ienco ; Yawogan Jean Eudes Gbodjo ; Roberto Interdonato ; Raffaele Gaetano
COMMENTS:       Under submission to Elsevier journal
HIGHLIGHT:      To cope with such issues, in the context of object-based SITS land cover mapping, we propose a new deep learning framework, named TASSEL (aTtentive weAkly Supervised Satellite image time sEries cLassifier), that is able to intelligently exploit the weak supervision provided by the coarse granularity labels.

134, TITLE:     NUBIA: NeUral Based Interchangeability Assessor for Text Generation
http://arxiv.org/abs/2004.14667
AUTHORS:        Hassan Kane ; Muhammed Yusuf Kocyigit ; Ali Abdalla ; Pelkins Ajanoh ; Mohamed Coulibali
COMMENTS:       8 pages, 5 tables, and 2 figures
HIGHLIGHT:      We present NUBIA, a methodology to build automatic evaluation metrics for text generation using only machine learning models as core components.

135, TITLE:     A Benchmark Dataset of Check-worthy Factual Claims
http://arxiv.org/abs/2004.14425
AUTHORS:        Fatma Arslan ; Naeemul Hassan ; Chengkai Li ; Mark Tremayne
COMMENTS:       Accepted to ICWSM 2020
HIGHLIGHT:      In this paper we present the ClaimBuster dataset of 23,533 statements extracted from all U.S. general election presidential debates and annotated by human coders.

136, TITLE:     UAV and Machine Learning Based Refinement of a Satellite-Driven Vegetation Index for Precision Agriculture
http://arxiv.org/abs/2004.14421
AUTHORS:        Vittorio Mazzia ; Lorenzo Comba ; Aleem Khaliq ; Marcello Chiaberge ; Paolo Gay
HIGHLIGHT:      This paper presents a novel satellite imagery refinement framework, based on a deep learning technique which exploits information properly derived from high resolution images acquired by unmanned aerial vehicle (UAV) airborne multispectral sensors.

137, TITLE:     Polarization Human Shape and Pose Dataset
http://arxiv.org/abs/2004.14899
AUTHORS:        Shihao Zou ; Xinxin Zuo ; Yiming Qian ; Sen Wang ; Chi Xu ; Minglun Gong ; Li Cheng
HIGHLIGHT:      Polarization Human Shape and Pose Dataset

138, TITLE:     Vocabulary Adaptation for Distant Domain Adaptation in Neural Machine Translation
http://arxiv.org/abs/2004.14821
AUTHORS:        Shoetsu Sato ; Jin Sakuma ; Naoki Yoshinaga ; Masashi Toyoda ; Masaru Kitsuregawa
COMMENTS:       8pages + citations
HIGHLIGHT:      In this study, aiming to solve these vocabulary mismatches in distant domain adaptation, we propose vocabulary adaptation, a simple method for effective fine-tuning that adapts embedding layers in a given pre-trained NMT model to the target domain.

139, TITLE:     Knowledge Graph Empowered Entity Description Generation
http://arxiv.org/abs/2004.14813
AUTHORS:        Liying Cheng ; Yan Zhang ; Dekun Wu ; Zhanming Jie ; Lidong Bing ; Wei Lu ; Luo Si
COMMENTS:       10 pages, 5 figures
HIGHLIGHT:      In this paper, we introduce a large-scale and challenging dataset to facilitate the study of such practical scenario in KG-to-text.

140, TITLE:     AIBench: An Industry Standard AI Benchmark Suite from Internet Services
http://arxiv.org/abs/2004.14690
AUTHORS:        Fei Tang ; Wanling Gao ; Jianfeng Zhan ; Chuanxin Lan ; Xu Wen ; Lei Wang ; Chunjie Luo ; Jiahui Dai ; Zheng Cao ; Xingwang Xiong ; Zihan Jiang ; Tianshu Hao ; Fanda Fan ; Fan Zhang ; Yunyou Huang ; Jianan Chen ; Mengjia Du ; Rui Ren ; Chen Zheng ; Daoyi Zheng ; Haoning Tang ; Kunlin Zhan ; Biao Wang ; Defei Kong ; Minghe Yu ; Chongkang Tan ; Huan Li ; Xinhui Tian ; Yatao Li ; Gang Lu ; Junchao Shao ; Zhenyu Wang ; Xiaoyu Wang ; Hainan Ye
HIGHLIGHT:      In this paper, we present a balanced AI benchmarking methodology for meeting the subtly different requirements of different stages in developing a new system/architecture and ranking/purchasing commercial off-the-shelf ones.

141, TITLE:     A Large-Scale Semi-Supervised Dataset for Offensive Language Identification
http://arxiv.org/abs/2004.14454
AUTHORS:        Sara Rosenthal ; Pepa Atanasova ; Georgi Karadzhov ; Marcos Zampieri ; Preslav Nakov
HIGHLIGHT:      The use of offensive language is a major problem in social media which has led to an abundance of research in detecting content such as hate speech, cyberbulling, and cyber-aggression.

142, TITLE:     Semi-Supervised Text Simplification with Back-Translation and Asymmetric Denoising Autoencoders
http://arxiv.org/abs/2004.14693
AUTHORS:        Yanbin Zhao ; Lu Chen ; Zhi Chen ; Kai Yu
HIGHLIGHT:      To tackle this problem, we propose asymmetric denoising methods for sentences with separate complexity.

143, TITLE:     Pragmatic Issue-Sensitive Image Captioning
http://arxiv.org/abs/2004.14451
AUTHORS:        Allen Nie ; Reuben Cohn-Gordon ; Christopher Potts
HIGHLIGHT:      To address this, we propose Issue-Sensitive Image Captioning (ISIC).

144, TITLE:     What Happens To BERT Embeddings During Fine-tuning?
http://arxiv.org/abs/2004.14448
AUTHORS:        Amil Merchant ; Elahe Rahimtoroghi ; Ellie Pavlick ; Ian Tenney
COMMENTS:       9 pages (not including references), 5 figures
HIGHLIGHT:      Using a suite of analysis techniques (probing classifiers, Representational Similarity Analysis, and model ablations), we investigate how fine-tuning affects the representations of the BERT model.

145, TITLE:     The Effect of Natural Distribution Shift on Question Answering Models
http://arxiv.org/abs/2004.14444
AUTHORS:        John Miller ; Karl Krauth ; Benjamin Recht ; Ludwig Schmidt
HIGHLIGHT:      We build four new test sets for the Stanford Question Answering Dataset (SQuAD) and evaluate the ability of question-answering systems to generalize to new data.

146, TITLE:     Distantly-Supervised Neural Relation Extraction with Side Information using BERT
http://arxiv.org/abs/2004.14443
AUTHORS:        Johny Moreira ; Chaina Oliveira ; David Macedo ; Cleber Zanchettin ; Luciano Barbosa
HIGHLIGHT:      Considering that this method outperformed state-of-the-art baselines, in this paper, we propose a related approach to RESIDE also using additional side information, but simplifying the sentence encoding with BERT embeddings.

147, TITLE:     Sim-to-Real Transfer with Incremental Environment Complexity for Reinforcement Learning of Depth-Based Robot Navigation
http://arxiv.org/abs/2004.14684
AUTHORS:        Thomas Chaffre ; Julien Moras ; Adrien Chan-Hon-Tong ; Julien Marzat
HIGHLIGHT:      In this paper, a Soft-Actor Critic (SAC) training strategy using incremental environment complexity is proposed to drastically reduce the need for additional training in the real world.

148, TITLE:     Analyzing Smart Contracts: From EVM to a sound Control-Flow Graph
http://arxiv.org/abs/2004.14437
AUTHORS:        Elvira Albert ; Jesús Correas ; Pablo Gordillo ; Guillermo Román-Díez ; Albert Rubio
HIGHLIGHT:      This report addresses the problem of obtaining a precise and complete stack-sensitive CFG by means of a static analysis, cloning the blocks that might be executed using different states of the execution stack.

149, TITLE:     AMPERSAND: Argument Mining for PERSuAsive oNline Discussions
http://arxiv.org/abs/2004.14677
AUTHORS:        Tuhin Chakrabarty ; Christopher Hidey ; Smaranda Muresan ; Kathy Mckeown ; Alyssa Hwang
COMMENTS:       EMNLP 2019
HIGHLIGHT:      We propose a computational model for argument mining in online persuasive discussion forums that brings together the micro-level (argument as product) and macro-level (argument as process) models of argumentation.

150, TITLE:     "The Boating Store Had Its Best Sail Ever": Pronunciation-attentive Contextualized Pun Recognition
http://arxiv.org/abs/2004.14457
AUTHORS:        Yichao Zhou ; Jyun-Yu Jiang ; Jieyu Zhao ; Kai-Wei Chang ; Wei Wang
COMMENTS:       10 pages, 4 figures, 7 tables, accepted by ACL 2020
HIGHLIGHT:      In this paper, we propose Pronunciation-attentive Contextualized Pun Recognition (PCPR) to perceive human humor, detect if a sentence contains puns and locate them in the sentence.

151, TITLE:     Rethinking Class-Discrimination Based CNN Channel Pruning
http://arxiv.org/abs/2004.14492
AUTHORS:        Yuchen Liu ; David Wentzlaff ; S. Y. Kung
HIGHLIGHT:      Prior works singly propose and evaluate their discriminant functions, while further study on the effectiveness of the adopted metrics is absent.

152, TITLE:     Detecting Deep-Fake Videos from Appearance and Behavior
http://arxiv.org/abs/2004.14491
AUTHORS:        Shruti Agarwal ; Tarek El-Gaaly ; Hany Farid ; Ser-Nam Lim
HIGHLIGHT:      We describe a biometric-based forensic technique for detecting face-swap deep fakes.

153, TITLE:     Interactive Video Stylization Using Few-Shot Patch-Based Training
http://arxiv.org/abs/2004.14489
AUTHORS:        Ondřej Texler ; David Futschik ; Michal Kučera ; Ondřej Jamriška ; Šárka Sochorová ; Menglei Chai ; Sergey Tulyakov ; Daniel Sýkora
HIGHLIGHT:      In this paper, we present a learning-based method to the keyframe-based video stylization that allows an artist to propagate the style from a few selected keyframes to the rest of the sequence.

154, TITLE:     Teaching Cameras to Feel: Estimating Tactile Physical Properties of Surfaces From Images
http://arxiv.org/abs/2004.14487
AUTHORS:        Matthew Purri ; Kristin Dana
COMMENTS:       19 pages, 5 figures, 6 tables
HIGHLIGHT:      In this work, we introduce the challenging task of estimating a set of tactile physical properties from visual information.



==========Updates to Previous Papers==========
1, TITLE:       Reducing Sentiment Bias in Language Models via Counterfactual Evaluation
http://arxiv.org/abs/1911.03064
AUTHORS:        Po-Sen Huang ; Huan Zhang ; Ray Jiang ; Robert Stanforth ; Johannes Welbl ; Jack Rae ; Vishal Maini ; Dani Yogatama ; Pushmeet Kohli
HIGHLIGHT:      This paper aims to quantify and reduce a particular type of bias exhibited by language models: bias with respect to sentiment.

2, TITLE:       Recipes for building an open-domain chatbot
http://arxiv.org/abs/2004.13637
AUTHORS:        Stephen Roller ; Emily Dinan ; Naman Goyal ; Da Ju ; Mary Williamson ; Yinhan Liu ; Jing Xu ; Myle Ott ; Kurt Shuster ; Eric M. Smith ; Y-Lan Boureau ; Jason Weston
HIGHLIGHT:      We build variants of these recipes with 90M, 2.7B and 9.4B parameter models, and make our models and code publicly available.

3, TITLE:       A Cascaded Learning Strategy for Robust COVID-19 Pneumonia Chest X-Ray Screening
http://arxiv.org/abs/2004.12786
AUTHORS:        Chun-Fu Yeh ; Hsien-Tzu Cheng ; Andy Wei ; Hsin-Ming Chen ; Po-Chen Kuo ; Keng-Chi Liu ; Mong-Chi Ko ; Ray-Jade Chen ; Po-Chang Lee ; Jen-Hsiang Chuang ; Chi-Mai Chen ; Yi-Chang Chen ; Wen-Jeng Lee ; Ning Chien ; Jo-Yu Chen ; Yu-Sen Huang ; Yu-Chien Chang ; Yu-Cheng Huang ; Nai-Kuan Chou ; Kuan-Hua Chao ; Yi-Chin Tu ; Yeun-Chung Chang ; Tyng-Luh Liu
COMMENTS:       14 pages, 6 figures
HIGHLIGHT:      We introduce a comprehensive screening platform for the COVID-19 (a.k.a., SARS-CoV-2) pneumonia.

4, TITLE:       CheXbert: Combining Automatic Labelers and Expert Annotations for Accurate Radiology Report Labeling Using BERT
http://arxiv.org/abs/2004.09167
AUTHORS:        Akshay Smit ; Saahil Jain ; Pranav Rajpurkar ; Anuj Pareek ; Andrew Y. Ng ; Matthew P. Lungren
HIGHLIGHT:      In this work, we introduce a BERT-based approach to medical image report labeling that exploits both the scale of available rule-based systems and the quality of expert annotations.

5, TITLE:       Endowing Empathetic Dialogue Systems with Personas
http://arxiv.org/abs/2004.12316
AUTHORS:        Peixiang Zhong ; Yao Sun ; Yong Liu ; Chen Zhang ; Hao Wang ; Zaiqing Nie ; Chunyan Miao
HIGHLIGHT:      To this end, we propose a new task to endow empathetic dialogue systems with personas and present the first empirical study on the impacts of persona on empathetic responding. Specifically, we first present a novel large-scale multi-domain dataset for empathetic dialogues with personas.

6, TITLE:       FD-FCN: 3D Fully Dense and Fully Convolutional Network for Semantic Segmentation of Brain Anatomy
http://arxiv.org/abs/1907.09194
AUTHORS:        Binbin Yang ; Weiwei Zhang
HIGHLIGHT:      In this paper, a 3D patch-based fully dense and fully convolutional network (FD-FCN) is proposed for fast and accurate segmentation of subcortical structures in T1-weighted magnetic resonance images.

7, TITLE:       Thermodynamics of computing with circuits
http://arxiv.org/abs/1806.04103
AUTHORS:        David Hilton Wolpert ; Artemy Kolchinsky
COMMENTS:       26 pages (6 of appendices), 5 figures
HIGHLIGHT:      We investigate how such restrictions on the physical coupling affects the thermodynamic costs of running the circuit.

8, TITLE:       Retrospective Reader for Machine Reading Comprehension
http://arxiv.org/abs/2001.09694
AUTHORS:        Zhuosheng Zhang ; Junjie Yang ; Hai Zhao
HIGHLIGHT:      Inspired by how humans solve reading comprehension questions, we proposed a retrospective reader (Retro-Reader) that integrates two stages of reading and verification strategies: 1) sketchy reading that briefly investigates the overall interactions of passage and question, and yield an initial judgment; 2) intensive reading that verifies the answer and gives the final prediction.

9, TITLE:       When Autonomous Systems Meet Accuracy and Transferability through AI: A Survey
http://arxiv.org/abs/2003.12948
AUTHORS:        Chongzhen Zhang ; Jianrui Wang ; Gary G. Yen ; Chaoqiang Zhao ; Qiyu Sun ; Yang Tang ; Feng Qian ; Jürgen Kurths
HIGHLIGHT:      Here, we review the learning-based approaches in autonomous systems from the perspectives of accuracy and transferability.

10, TITLE:      Structured Knowledge Distillation for Dense Prediction
http://arxiv.org/abs/1903.04197
AUTHORS:        Yifan Liu ; Changyong Shun ; Jingdong Wang ; Chunhua Shen
COMMENTS:       v1:10 pages cvpr2019 accepted; v2:15 pages for a journal version; Code is available at: https://github.com/irfanICMLL/structure_knowledge_distillation; fix typos
HIGHLIGHT:      In this paper, we consider transferring the structure information from large networks to small ones for dense prediction tasks.

11, TITLE:      Polymorphic Iterable Sequential Effect Systems
http://arxiv.org/abs/1808.02010
AUTHORS:        Colin S. Gordon
COMMENTS:       Extended journal version of ECOOP 2017 paper (preprint at arXiv:1705.02264) generalizing the iteration operator for behavioral effect systems, strengthening existence results, strengthening proof, and adding to examples and comparison to related work (more details in paper). This arXiv revision fixes incorrect proofs and technical claims in the earlier arXiv version
HIGHLIGHT:      We present an abstract polymorphic effect system parameterized by an effect quantale -- an algebraic structure with well-defined properties that can model the effects of a range of existing sequential effect systems.

12, TITLE:      Learning Gaussian Maps for Dense Object Detection
http://arxiv.org/abs/2004.11855
AUTHORS:        Sonaal Kant
HIGHLIGHT:      In this paper we review common and highly accurate object detection methods on the scenes where numerous similar looking objects are placed in close proximity with each other.

13, TITLE:      Topological Sweep for Multi-Target Detection of Geostationary Space Objects
http://arxiv.org/abs/2003.09583
AUTHORS:        Daqi Liu ; Bo Chen ; Tat-Jun Chin ; Mark Rutten
COMMENTS:       12 pages, 12 figures
HIGHLIGHT:      In this paper, we propose a novel multi-target detection technique based on topological sweep, to find GEO objects from a short sequence of optical images.

14, TITLE:      Multi-modal Egocentric Activity Recognition using Audio-Visual Features
http://arxiv.org/abs/1807.00612
AUTHORS:        Mehmet Ali Arabacı ; Fatih Özkan ; Elif Surer ; Peter Jančovič ; Alptekin Temizel
HIGHLIGHT:      In this work, we propose a new framework for egocentric activity recognition problem based on combining audio-visual features with multi-kernel learning (MKL) and multi-kernel boosting (MKBoost).

15, TITLE:      $P\neq NP$
http://arxiv.org/abs/2003.09791
AUTHORS:        Tianrong Lin
COMMENTS:       The statements of Theorem 1.4 and Theorem 1.6 changed to lower the difficulty of proofs, the lower bounds proofs further changed, questions posed, footnotes 2 and 6 added to clarify what means for a language $L\in NP-P$ (resp.~$coNP-coP$), and for a language $L\in NP-P$ (resp.~$L\in coNP-coP$) is in $P$ (resp.~$coP$); comments are welcome
HIGHLIGHT:      The main contribution of the paper is that a series of results are obtained.

16, TITLE:      PhoBERT: Pre-trained language models for Vietnamese
http://arxiv.org/abs/2003.00744
AUTHORS:        Dat Quoc Nguyen ; Anh Tuan Nguyen
HIGHLIGHT:      We present PhoBERT with two versions---PhoBERT-base and PhoBERT-large---the first public large-scale monolingual language models pre-trained for Vietnamese.

17, TITLE:      A Probabilistic Formulation of Unsupervised Text Style Transfer
http://arxiv.org/abs/2002.03912
AUTHORS:        Junxian He ; Xinyi Wang ; Graham Neubig ; Taylor Berg-Kirkpatrick
COMMENTS:       ICLR 2020 conference paper (spotlight). The first two authors contributed equally
HIGHLIGHT:      We present a deep generative model for unsupervised text style transfer that unifies previously proposed non-generative techniques.

18, TITLE:      Transformer-based Acoustic Modeling for Hybrid Speech Recognition
http://arxiv.org/abs/1910.09799
AUTHORS:        Yongqiang Wang ; Abdelrahman Mohamed ; Duc Le ; Chunxi Liu ; Alex Xiao ; Jay Mahadeokar ; Hongzhao Huang ; Andros Tjandra ; Xiaohui Zhang ; Frank Zhang ; Christian Fuegen ; Geoffrey Zweig ; Michael L. Seltzer
COMMENTS:       to appear in ICASSP 2020
HIGHLIGHT:      We propose and evaluate transformer-based acoustic models (AMs) for hybrid speech recognition.

19, TITLE:      Image Chat: Engaging Grounded Conversations
http://arxiv.org/abs/1811.00945
AUTHORS:        Kurt Shuster ; Samuel Humeau ; Antoine Bordes ; Jason Weston
COMMENTS:       ACL 2020
HIGHLIGHT:      In this work we study large-scale architectures and datasets for this goal. To test such models, we collect a dataset of grounded human-human conversations, where speakers are asked to play roles given a provided emotional mood or style, as the use of such traits is also a key factor in engagingness (Guo et al., 2019).

20, TITLE:      Spiking neural networks trained with backpropagation for low power neuromorphic implementation of voice activity detection
http://arxiv.org/abs/1910.09993
AUTHORS:        Flavio Martinelli ; Giorgia Dellaferrera ; Pablo Mainar ; Milos Cernak
COMMENTS:       5 pages, 2 figures, 2 tables
HIGHLIGHT:      We describe an SNN training procedure that achieves low spiking activity and pruning algorithms to remove 85% of the network connections with no performance loss.

21, TITLE:      MimicGAN: Robust Projection onto Image Manifolds with Corruption Mimicking
http://arxiv.org/abs/1912.07748
AUTHORS:        Rushil Anirudh ; Jayaraman J. Thiagarajan ; Bhavya Kailkhura ; Timo Bremer
COMMENTS:       International Journal on Computer Vision's (IJCV) Special Issue on GANs
HIGHLIGHT:      To address this, we propose corruption mimicking -- a new robust projection technique, that utilizes a surrogate network to approximate the unknown corruption directly at test time, without the need for additional supervision or data augmentation.

22, TITLE:      Maximum Likelihood Constraint Inference for Inverse Reinforcement Learning
http://arxiv.org/abs/1909.05477
AUTHORS:        Dexter R. R. Scobee ; S. Shankar Sastry
COMMENTS:       Published as a conference paper at the International Conference on Learning Representations (ICLR), 2020 (at https://openreview.net/forum?id=BJliakStvH )
HIGHLIGHT:      We present an algorithm which iteratively infers the Maximum Likelihood Constraint to best explain observed behavior, and we evaluate its efficacy using both simulated behavior and recorded data of humans navigating around an obstacle.

23, TITLE:      XNect: Real-time Multi-Person 3D Motion Capture with a Single RGB Camera
http://arxiv.org/abs/1907.00837
AUTHORS:        Dushyant Mehta ; Oleksandr Sotnychenko ; Franziska Mueller ; Weipeng Xu ; Mohamed Elgharib ; Pascal Fua ; Hans-Peter Seidel ; Helge Rhodin ; Gerard Pons-Moll ; Christian Theobalt
COMMENTS:       To appear in ACM Transactions on Graphics (SIGGRAPH) 2020
HIGHLIGHT:      We present a real-time approach for multi-person 3D motion capture at over 30 fps using a single RGB camera.

24, TITLE:      Adversarial Training for Large Neural Language Models
http://arxiv.org/abs/2004.08994
AUTHORS:        Xiaodong Liu ; Hao Cheng ; Pengcheng He ; Weizhu Chen ; Yu Wang ; Hoifung Poon ; Jianfeng Gao
COMMENTS:       13 pages, 9 tables, 2 figures
HIGHLIGHT:      In this paper, we show that adversarial pre-training can improve both generalization and robustness.

25, TITLE:      Forget Me Not: Reducing Catastrophic Forgetting for Domain Adaptation in Reading Comprehension
http://arxiv.org/abs/1911.00202
AUTHORS:        Y. Xu ; X. Zhong ; A. J. J. Yepes ; J. H. Lau
COMMENTS:       we have some dataset issues to deal with before resubmit to public
HIGHLIGHT:      In this paper, we explore methods that overcome catastrophic forgetting during fine-tuning without assuming access to data from the source domain.

26, TITLE:      On the Cross-lingual Transferability of Monolingual Representations
http://arxiv.org/abs/1910.11856
AUTHORS:        Mikel Artetxe ; Sebastian Ruder ; Dani Yogatama
COMMENTS:       ACL 2020
HIGHLIGHT:      State-of-the-art unsupervised multilingual models (e.g., multilingual BERT) have been shown to generalize in a zero-shot cross-lingual setting.

27, TITLE:      Facet-Aware Evaluation for Extractive Summarization
http://arxiv.org/abs/1908.10383
AUTHORS:        Yuning Mao ; Liyuan Liu ; Qi Zhu ; Xiang Ren ; Jiawei Han
COMMENTS:       ACL 2020, Long Paper
HIGHLIGHT:      In this paper, we present a facet-aware evaluation setup for better assessment of the information coverage in extracted summaries.

28, TITLE:      A Comprehensive Review of Shepherding as a Bio-inspired Swarm-Robotics Guidance Approach
http://arxiv.org/abs/1912.07796
AUTHORS:        Nathan K Long ; Karl Sammut ; Daniel Sgarioto ; Matthew Garratt ; Hussein Abbass
COMMENTS:       Copyright 2020 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works
HIGHLIGHT:      We present a comprehensive review of the literature on swarm shepherding to reveal the advantages and potential of the approach to be applied to a plethora of robotic systems in the future.

29, TITLE:      Generate, Delete and Rewrite: A Three-Stage Framework for Improving Persona Consistency of Dialogue Generation
http://arxiv.org/abs/2004.07672
AUTHORS:        Haoyu Song ; Yan Wang ; Wei-Nan Zhang ; Xiaojiang Liu ; Ting Liu
COMMENTS:       Accepted by ACL2020
HIGHLIGHT:      In this work, we introduce a three-stage framework that employs a generate-delete-rewrite mechanism to delete inconsistent words from a generated response prototype and further rewrite it to a personality-consistent one.

30, TITLE:      Neural Automated Essay Scoring and Coherence Modeling for Adversarially Crafted Input
http://arxiv.org/abs/1804.06898
AUTHORS:        Youmna Farag ; Helen Yannakoudakis ; Ted Briscoe
COMMENTS:       9, NAACL 2018
HIGHLIGHT:      We develop a neural model of local coherence that can effectively learn connectedness features between sentences, and propose a framework for integrating and jointly training the local coherence model with a state-of-the-art AES model.

31, TITLE:      Learning Spatiotemporal Features via Video and Text Pair Discrimination
http://arxiv.org/abs/2001.05691
AUTHORS:        Tianhao Li ; Limin Wang
COMMENTS:       Technical Report
HIGHLIGHT:      In this paper, we leverage this visual-textual connection to learn spatiotemporal features in an efficient weakly-supervised manner.

32, TITLE:      Graph-to-Graph Transformer for Transition-based Dependency Parsing
http://arxiv.org/abs/1911.03561
AUTHORS:        Alireza Mohammadshahi ; James Henderson
COMMENTS:       17 pages, 5 figures
HIGHLIGHT:      We propose the Graph2Graph Transformer architecture for conditioning on and predicting arbitrary graphs, and apply it to the challenging task of transition-based dependency parsing.

33, TITLE:      FSS-1000: A 1000-Class Dataset for Few-Shot Segmentation
http://arxiv.org/abs/1907.12347
AUTHORS:        Xiang Li ; Tianhan Wei ; Yau Pun Chen ; Yu-Wing Tai ; Chi-Keung Tang
HIGHLIGHT:      In this paper, we are interested in few-shot object segmentation where the number of annotated training examples are limited to 5 only. To evaluate and validate the performance of our approach, we have built a few-shot segmentation dataset, FSS-1000, which consists of 1000 object classes with pixelwise annotation of ground-truth segmentation.

34, TITLE:      Unsupervised Meta-Learning for Reinforcement Learning
http://arxiv.org/abs/1806.04640
AUTHORS:        Abhishek Gupta ; Benjamin Eysenbach ; Chelsea Finn ; Sergey Levine
COMMENTS:       First two authors contributed equally
HIGHLIGHT:      In this work, we take a step in this direction, proposing a family of unsupervised meta-learning algorithms for reinforcement learning.

35, TITLE:      Harnessing adversarial examples with a surprisingly simple defense
http://arxiv.org/abs/2004.13013
AUTHORS:        Ali Borji
HIGHLIGHT:      I introduce a very simple method to defend against adversarial examples.

36, TITLE:      Using Punkt for Sentence Segmentation in non-Latin Scripts: Experiments on Kurdish (Sorani) Texts
http://arxiv.org/abs/2004.14134
AUTHORS:        Roshna Omer Abdulrahman ; Hossein Hassani
COMMENTS:       Accepted for AfricaNLP Workshop at ICLR 2020
HIGHLIGHT:      We used Punkt, an unsupervised machine learning method, to segment a Kurdish corpus of Sorani dialect, written in Persian-Arabic script.

37, TITLE:      ToTTo: A Controlled Table-To-Text Generation Dataset
http://arxiv.org/abs/2004.14373
AUTHORS:        Ankur P. Parikh ; Xuezhi Wang ; Sebastian Gehrmann ; Manaal Faruqui ; Bhuwan Dhingra ; Diyi Yang ; Dipanjan Das
HIGHLIGHT:      We present ToTTo, an open-domain English table-to-text dataset with over 120,000 training examples that proposes a controlled generation task: given a Wikipedia table and a set of highlighted table cells, produce a one-sentence description.

38, TITLE:      PLATO: Pre-trained Dialogue Generation Model with Discrete Latent Variable
http://arxiv.org/abs/1910.07931
AUTHORS:        Siqi Bao ; Huang He ; Fan Wang ; Hua Wu ; Haifeng Wang
COMMENTS:       Accepted for publication at ACL2020. First two authors contributed equally
HIGHLIGHT:      Inspired by this, we propose a novel dialogue generation pre-training framework to support various kinds of conversations, including chit-chat, knowledge grounded dialogues, and conversational question answering.

39, TITLE:      VarGNet: Variable Group Convolutional Neural Network for Efficient Embedded Computing
http://arxiv.org/abs/1907.05653
AUTHORS:        Qian Zhang ; Jianjun Li ; Meng Yao ; Liangchen Song ; Helong Zhou ; Zhichao Li ; Wenming Meng ; Xuezhi Zhang ; Guoli Wang
COMMENTS:       Technical report
HIGHLIGHT:      In this paper, we propose a novel network design mechanism for efficient embedded computing.

40, TITLE:      DualSMC: Tunneling Differentiable Filtering and Planning under Continuous POMDPs
http://arxiv.org/abs/1909.13003
AUTHORS:        Yunbo Wang ; Bo Liu ; Jiajun Wu ; Yuke Zhu ; Simon S. Du ; Li Fei-Fei ; Joshua B. Tenenbaum
COMMENTS:       IJCAI 2020
HIGHLIGHT:      We cast POMDP filtering and planning problems as two closely related Sequential Monte Carlo (SMC) processes, one over the real states and the other over the future optimal trajectories, and combine the merits of these two parts in a new model named the DualSMC network.

41, TITLE:      Highway Transformer: Self-Gating Enhanced Self-Attentive Networks
http://arxiv.org/abs/2004.08178
AUTHORS:        Yekun Chai ; Jin Shuo ; Xinwen Hou
COMMENTS:       accepted at ACL 2020
HIGHLIGHT:      Through a pseudo information highway, we introduce a gated component self-dependency units (SDU) that incorporates LSTM-styled gating units to replenish internal semantic importance within the multi-dimensional latent space of individual representations.

42, TITLE:      FastDVDnet: Towards Real-Time Deep Video Denoising Without Flow Estimation
http://arxiv.org/abs/1907.01361
AUTHORS:        Matias Tassano ; Julie Delon ; Thomas Veit
COMMENTS:       Code for this algorithm and results can be found in https://github.com/m-tassano/fastdvdnet. arXiv admin note: text overlap with arXiv:1906.11890
HIGHLIGHT:      In this paper, we propose a state-of-the-art video denoising algorithm based on a convolutional neural network architecture.

43, TITLE:      Measuring Societal Biases in Text Corpora via First-Order Co-occurrence
http://arxiv.org/abs/1812.10424
AUTHORS:        Navid Rekabsaz ; James Henderson ; Robert West ; Allan Hanbury
HIGHLIGHT:      We propose instead to measure bias using the direct normalized co-occurrence associations between the word and the representative concept words, a first-order measure, by reconstructing the co-occurrence estimates inherent in the word embedding models.

44, TITLE:      Predictable Accelerator Design with Time-Sensitive Affine Types
http://arxiv.org/abs/2004.04852
AUTHORS:        Rachit Nigam ; Sachille Atapattu ; Samuel Thomas ; Zhijing Li ; Theodore Bauer ; Yuwei Ye ; Apurva Koti ; Adrian Sampson ; Zhiru Zhang
COMMENTS:       Full paper with soundness proof and MachSuite ports
HIGHLIGHT:      This paper proposes a type system that restricts HLS to programs that can predictably compile to hardware accelerators.

45, TITLE:      Multi-Task Learning for Coherence Modeling
http://arxiv.org/abs/1907.02427
AUTHORS:        Youmna Farag ; Helen Yannakoudakis
COMMENTS:       11 pages, 3 figures, Accepted at ACL 2019
HIGHLIGHT:      We propose a hierarchical neural network trained in a multi-task fashion that learns to predict a document-level coherence score (at the network's top layers) along with word-level grammatical roles (at the bottom layers), taking advantage of inductive transfer between the two tasks.

46, TITLE:      Why is the Mahalanobis Distance Effective for Anomaly Detection?
http://arxiv.org/abs/2003.00402
AUTHORS:        Ryo Kamoi ; Kei Kobayashi
HIGHLIGHT:      This work analyzes why this method exhibits such strong performance in practical settings while imposing an implausible assumption; namely, that class conditional distributions of pre-trained features have tied covariance.

47, TITLE:      The Ramanujan Machine: Automatically Generated Conjectures on Fundamental Constants
http://arxiv.org/abs/1907.00205
AUTHORS:        Gal Raayoni ; Shahar Gottlieb ; George Pisha ; Yoav Harris ; Yahel Manor ; Uri Mendlovic ; Doron Haviv ; Yaron Hadad ; Ido Kaminer
COMMENTS:       5 figures, 6 tables, 28 pages including the supplementary information
HIGHLIGHT:      Here we propose a novel and systematic approach that leverages algorithms for deriving mathematical formulas for fundamental constants and help reveal their underlying structure.

48, TITLE:      Molweni: A Challenge Multiparty Dialogues-based Machine Reading Comprehension Dataset with Discourse Structure
http://arxiv.org/abs/2004.05080
AUTHORS:        Jiaqi Li ; Ming Liu ; Min-Yen Kan ; Zihao Zheng ; Zekun Wang ; Wenqiang Lei ; Ting Liu ; Bing Qin
HIGHLIGHT:      We present the Molweni dataset, a machine reading comprehension (MRC) dataset built over multiparty dialogues.

49, TITLE:      Corruption robust exploration in episodic reinforcement learning
http://arxiv.org/abs/1911.08689
AUTHORS:        Thodoris Lykouris ; Max Simchowitz ; Aleksandrs Slivkins ; Wen Sun
HIGHLIGHT:      We provide a framework which modifies the aggressive exploration enjoyed by existing reinforcement learning approaches based on "optimism in the face of uncertainty", by complementing them with principles from "action elimination".

50, TITLE:      Good-Enough Compositional Data Augmentation
http://arxiv.org/abs/1904.09545
AUTHORS:        Jacob Andreas
HIGHLIGHT:      We propose a simple data augmentation protocol aimed at providing a compositional inductive bias in conditional and unconditional sequence models.

51, TITLE:      ResDepth: Learned Residual Stereo Reconstruction
http://arxiv.org/abs/2001.08026
AUTHORS:        Corinne Stucker ; Konrad Schindler
COMMENTS:       10 pages, 5 figures, 2 tables, extended version, accepted for the Earthvision 2020 Workshop in conjunction with CVPR2020
HIGHLIGHT:      We propose an embarrassingly simple but very effective scheme for high-quality dense stereo reconstruction: (i) generate an approximate reconstruction with your favourite stereo matcher; (ii) rewarp the input images with that approximate model; (iii) with the initial reconstruction and the warped images as input, train a deep network to enhance the reconstruction by regressing a residual correction; and (iv) if desired, iterate the refinement with the new, improved reconstruction.

52, TITLE:      What are We Depressed about When We Talk about COVID19: Mental Health Analysis on Tweets Using Natural Language Processing
http://arxiv.org/abs/2004.10899
AUTHORS:        Irene Li ; Yixin Li ; Tianxiao Li ; Sergio Alvarez-Napagao ; Dario Garcia
COMMENTS:       7 pages, 7 figures
HIGHLIGHT:      In this work, we focus on applying natural language processing (NLP) techniques to analyze tweets in terms of mental health. We build the EmoCT (Emotion-Covid19-Tweet) dataset for the training purpose by manually labeling 1,000 English tweets.

53, TITLE:      Diagnosis of Diabetic Retinopathy in Ethiopia: Before the Deep Learning based Automation
http://arxiv.org/abs/2003.09208
AUTHORS:        Misgina Tsighe Hagos
HIGHLIGHT:      Diagnosis of Diabetic Retinopathy in Ethiopia: Before the Deep Learning based Automation

54, TITLE:      Generating and Adapting to Diverse Ad-Hoc Cooperation Agents in Hanabi
http://arxiv.org/abs/2004.13710
AUTHORS:        Rodrigo Canaan ; Xianbo Gao ; Julian Togelius ; Andy Nealen ; Stefan Menzel
COMMENTS:       arXiv admin note: text overlap with arXiv:1907.03840
HIGHLIGHT:      This paper proposes Quality Diversity algorithms as a promising class of algorithms to generate diverse populations for this purpose, and generates a population of diverse Hanabi agents using MAP-Elites.

55, TITLE:      Once-for-All: Train One Network and Specialize it for Efficient Deployment
http://arxiv.org/abs/1908.09791
AUTHORS:        Han Cai ; Chuang Gan ; Tianzhe Wang ; Zhekai Zhang ; Song Han
COMMENTS:       ICLR 2020
HIGHLIGHT:      In this work, we propose to train a once-for-all (OFA) network that supports diverse architectural settings by decoupling training and search, to reduce the cost.

56, TITLE:      Continuous Adaptation for Interactive Object Segmentation by Learning from Corrections
http://arxiv.org/abs/1911.12709
AUTHORS:        Theodora Kontogianni ; Michael Gygli ; Jasper Uijlings ; Vittorio Ferrari
HIGHLIGHT:      Instead, we recognize that user corrections can serve as sparse training examples and we propose a method that capitalizes on that idea to update the model parameters on-the-fly to the data at hand.

57, TITLE:      Weighted Envy-Freeness in Indivisible Item Allocation
http://arxiv.org/abs/1909.10502
AUTHORS:        Mithun Chakraborty ; Ayumi Igarashi ; Warut Suksompong ; Yair Zick
COMMENTS:       A preliminary version appears in Proceedings of the 19th International Conference on Autonomous Agents and Multiagent Systems (AAMAS), 2020
HIGHLIGHT:      We introduce and analyze new envy-based fairness concepts for agents with weights that quantify their entitlements in the allocation of indivisible items.

58, TITLE:      Conditional Neural Generation using Sub-Aspect Functions for Extractive News Summarization
http://arxiv.org/abs/2004.13983
AUTHORS:        Zhengyuan Liu ; Ke Shi ; Nancy F. Chen
HIGHLIGHT:      We propose a neural framework that can flexibly control which sub-aspect functions (i.e. importance, diversity, position) to focus on during summary generation.

59, TITLE:      Dual Supervised Learning for Natural Language Understanding and Generation
http://arxiv.org/abs/1905.06196
AUTHORS:        Shang-Yu Su ; Chao-Wei Huang ; Yun-Nung Chen
COMMENTS:       Accepted by ACL 2019
HIGHLIGHT:      This paper proposes a new learning framework for language understanding and generation on top of dual supervised learning, providing a way to exploit the duality.

60, TITLE:      NLocalSAT: Boosting Local Search with Solution Prediction
http://arxiv.org/abs/2001.09398
AUTHORS:        Wenjie Zhang ; Zeyu Sun ; Qihao Zhu ; Ge Li ; Shaowei Cai ; Yingfei Xiong ; Lu Zhang
COMMENTS:       7 pages, 3 figures
HIGHLIGHT:      To address this problem, we propose NLocalSAT.

61, TITLE:      A Joint Model for Definition Extraction with Syntactic Connection and Semantic Consistency
http://arxiv.org/abs/1911.01678
AUTHORS:        Amir Pouran Ben Veyseh ; Franck Dernoncourt ; Dejing Dou ; Thien Huu Nguyen
HIGHLIGHT:      In this work, we propose a novel model for DE that simultaneously performs the two tasks in a single framework to benefit from their inter-dependencies.

62, TITLE:      ktrain: A Low-Code Library for Augmented Machine Learning
http://arxiv.org/abs/2004.10703
AUTHORS:        Arun S. Maiya
COMMENTS:       8 pages
HIGHLIGHT:      We present ktrain, a low-code Python library that makes machine learning more accessible and easier to apply.

63, TITLE:      Red-GAN: Attacking class imbalance via conditioned generation. Yet another medical imaging perspective
http://arxiv.org/abs/2004.10734
AUTHORS:        Ahmad B Qasim ; Ivan Ezhov ; Suprosanna Shit ; Oliver Schoppe ; Johannes C Paetzold ; Anjany Sekuboyina ; Florian Kofler ; Jana Lipkova ; Hongwei Li ; Bjoern Menze
HIGHLIGHT:      In an attempt to mitigate the problem, we propose a data augmentation protocol based on generative adversarial networks.

64, TITLE:      A Dual-hierarchy Semantic Graph for Robust Object Recognition
http://arxiv.org/abs/1909.06867
AUTHORS:        Isaac Weiss
HIGHLIGHT:      We present a system for object recognition based on a semantic graph representation, which the system can learn from image examples.

65, TITLE:      Improving the affordability of robustness training for DNNs
http://arxiv.org/abs/2002.04237
AUTHORS:        Sidharth Gupta ; Parijat Dube ; Ashish Verma
HIGHLIGHT:      In this paper we show that the initial phase of adversarial training is redundant and can be replaced with natural training which significantly improves the computational efficiency.

66, TITLE:      Normalizing Compositional Structures Across Graphbanks
http://arxiv.org/abs/2004.14236
AUTHORS:        Lucia Donatelli ; Jonas Groschwitz ; Alexander Koller ; Matthias Lindemann ; Pia Weißenhorn
COMMENTS:       16 pages, 6 figures
HIGHLIGHT:      We present a methodology for normalizing discrepancies between MRs at the compositional level (Lindemann et al., 2019), finding that we can normalize the majority of divergent phenomena using linguistically-grounded rules.

67, TITLE:      Consistent Dialogue Generation with Self-supervised Feature Learning
http://arxiv.org/abs/1903.05759
AUTHORS:        Yizhe Zhang ; Xiang Gao ; Sungjin Lee ; Chris Brockett ; Michel Galley ; Jianfeng Gao ; Bill Dolan
HIGHLIGHT:      In this paper, we propose a neural conversation model that generates consistent responses by maintaining certain features related to topics and personas throughout the conversation.

68, TITLE:      ToD-BERT: Pre-trained Natural Language Understanding for Task-Oriented Dialogues
http://arxiv.org/abs/2004.06871
AUTHORS:        Chien-Sheng Wu ; Steven Hoi ; Richard Socher ; Caiming Xiong
HIGHLIGHT:      In this work, we combine nine English-based, human-human, multi-turn and publicly available task-oriented dialogue datasets to conduct language model pre-training.

69, TITLE:      VIBE: Video Inference for Human Body Pose and Shape Estimation
http://arxiv.org/abs/1912.05656
AUTHORS:        Muhammed Kocabas ; Nikos Athanasiou ; Michael J. Black
COMMENTS:       CVPR-2020 camera ready. Code is available at https://github.com/mkocabas/VIBE
HIGHLIGHT:      To address this problem, we propose Video Inference for Body Pose and Shape Estimation (VIBE), which makes use of an existing large-scale motion capture dataset (AMASS) together with unpaired, in-the-wild, 2D keypoint annotations.

70, TITLE:      Multiscale Collaborative Deep Models for Neural Machine Translation
http://arxiv.org/abs/2004.14021
AUTHORS:        Xiangpeng Wei ; Heng Yu ; Yue Hu ; Yue Zhang ; Rongxiang Weng ; Weihua Luo
COMMENTS:       Accepted by ACL-2020
HIGHLIGHT:      In this paper, we present a MultiScale Collaborative (MSC) framework to ease the training of NMT models that are substantially deeper than those used previously.
