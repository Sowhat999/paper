1, TITLE: Detection of Non-uniformity in Parameters for Magnetic Domain Pattern Generation By Machine Learning
AUTHORS: Naoya Mamada ; Masaichiro Mizumaki ; Ichiro Akai ; Toru Aonishi
CATEGORY: cond-mat.mtrl-sci [cond-mat.mtrl-sci, cs.CV]
HIGHLIGHT: We attempt to estimate the spatial distribution of heterogeneous physical parameters involved in the formation of magnetic domain patterns of polycrystalline thin films by using convolutional neural networks. We propose a method to obtain a spatial map of physical parameters by estimating the parameters from patterns within a small subregion window of the full magnetic domain and subsequently shifting this window.

2, TITLE: Supermodular Rank: Set Function Decomposition and Optimization
AUTHORS: Rishi Sonthalia ; Anna Seigal ; Guido Montufar
CATEGORY: math.CO [math.CO, cs.CC, cs.DM, cs.LG, math.OC]
HIGHLIGHT: We characterize the maximum possible value of the supermodular rank and describe the functions with fixed supermodular rank.

3, TITLE: A Note on The Computational Complexity of The Moment-SOS Hierarchy for Polynomial Optimization
AUTHORS: Sander Gribling ; Sven Polak ; Lucas Slot
CATEGORY: math.OC [math.OC, cs.CC, 90C22, 90C23]
HIGHLIGHT: We study the computational complexity of the moment-SOS hierarchy, complementing and expanding upon earlier work of Raghavendra & Weitz (2017).

4, TITLE: Discounting in Strategy Logic
AUTHORS: Munyque Mittelmann ; Aniello Murano ; Laurent Perrussel
CATEGORY: cs.AI [cs.AI]
HIGHLIGHT: In this paper, we augment Strategy Logic with future discounting over a set of discounted functions D, denoted SLdisc[D].

5, TITLE: In-Context Impersonation Reveals Large Language Models' Strengths and Biases
AUTHORS: Leonard Salewski ; Stephan Alaniz ; Isabel Rio-Torto ; Eric Schulz ; Zeynep Akata
CATEGORY: cs.AI [cs.AI, cs.CL, cs.LG]
HIGHLIGHT: In everyday conversations, humans can take on different roles and adapt their vocabulary to their chosen roles. We explore whether LLMs can take on, that is impersonate, different roles when they generate text in-context.

6, TITLE: Measuring and Mitigating Constraint Violations of In-Context Learning for Utterance-to-API Semantic Parsing
AUTHORS: SHUFAN WANG et. al.
CATEGORY: cs.AI [cs.AI, cs.CL]
HIGHLIGHT: Thus, it remains uncertain if LLMs can effectively perform task-oriented utterance-to-API generation where respecting API's structural and task-specific constraints is crucial. In this work, we seek to measure, analyze and mitigate such constraints violations.

7, TITLE: Ethics and Deep Learning
AUTHORS: Travis LaCroix ; Simon J. D. Prince
CATEGORY: cs.AI [cs.AI, cs.CY, cs.LG]
HIGHLIGHT: This chapter considers potential harms arising from the design and use of AI systems.

8, TITLE: Leveraging Pre-trained Large Language Models to Construct and Utilize World Models for Model-based Task Planning
AUTHORS: Lin Guan ; Karthik Valmeekam ; Sarath Sreedharan ; Subbarao Kambhampati
CATEGORY: cs.AI [cs.AI]
HIGHLIGHT: In this work, we introduce a novel alternative paradigm that constructs an explicit world (domain) model in planning domain definition language (PDDL) and then uses it to plan with sound domain-independent planners.

9, TITLE: Model Evaluation for Extreme Risks
AUTHORS: TOBY SHEVLANE et. al.
CATEGORY: cs.AI [cs.AI, K.4.1]
HIGHLIGHT: We explain why model evaluation is critical for addressing extreme risks.

10, TITLE: A Mini Review on The Utilization of Reinforcement Learning with OPC UA
AUTHORS: Simon Schindler ; Martin Uray ; Stefan Huber
CATEGORY: cs.AI [cs.AI]
HIGHLIGHT: However, since RL and OPC UA are from different fields,there is a need for researchers to bridge the gap between the two technologies. This work serves to bridge this gap by providing a brief technical overview of both technologies and carrying out a semi-exhaustive literature review to gain insights on how RL and OPC UA are applied in combination.

11, TITLE: "What If?" in Probabilistic Logic Programming
AUTHORS: Rafael Kiesel ; Kilian Rückschloß ; Felix Weitkämper
CATEGORY: cs.AI [cs.AI]
HIGHLIGHT: A ProbLog program is a logic program with facts that only hold with a specified probability. In this contribution we extend this ProbLog language by the ability to answer "What if" queries.

12, TITLE: Guessing Winning Policies in LTL Synthesis By Semantic Learning
AUTHORS: Jan Kretinsky ; Tobias Meggendorfer ; Maximilian Prokop ; Sabine Rieder
CATEGORY: cs.AI [cs.AI, cs.SY, eess.SY]
HIGHLIGHT: We provide a learning-based technique for guessing a winning strategy in a parity game originating from an LTL synthesis problem.

13, TITLE: Graph Meets LLM: A Novel Approach to Collaborative Filtering for Robust Conversational Understanding
AUTHORS: Zheng Chen ; Ziyan Jiang ; Fan Yang
CATEGORY: cs.AI [cs.AI, cs.IR, cs.LG, F.2.2; I.2.7]
HIGHLIGHT: This paper presents our "Collaborative Query Rewriting" approach that focuses on rewriting novel user interactions unseen in the user history.

14, TITLE: ECHo: Event Causality Inference Via Human-centric Reasoning
AUTHORS: Yuxi Xie ; Guanzhen Li ; Min-Yen Kan
CATEGORY: cs.AI [cs.AI, cs.CL, cs.CV]
HIGHLIGHT: We introduce ECHo, a diagnostic dataset of event causality inference grounded in visual-and-linguistic social scenarios.

15, TITLE: GPT4Graph: Can Large Language Models Understand Graph Structured Data ? An Empirical Evaluation and Benchmarking
AUTHORS: Jiayan Guo ; Lun Du ; Hengyu Liu
CATEGORY: cs.AI [cs.AI, cs.CL]
HIGHLIGHT: In this study, we conduct an extensive investigation to assess the proficiency of LLMs in comprehending graph data, employing a diverse range of structural and semantic-related tasks.

16, TITLE: Optimal Control of Logically Constrained Partially Observable and Multi-Agent Markov Decision Processes
AUTHORS: KRISHNA C. KALAGARLA et. al.
CATEGORY: cs.AI [cs.AI, cs.FL, cs.SY, eess.SY]
HIGHLIGHT: We provide a structured methodology for synthesizing policies that maximize a cumulative reward while ensuring that the probability of satisfying a temporal logic constraint is sufficiently high.

17, TITLE: Anthropomorphization of AI: Opportunities and Risks
AUTHORS: Ameet Deshpande ; Tanmay Rajpurohit ; Karthik Narasimhan ; Ashwin Kalyan
CATEGORY: cs.AI [cs.AI, cs.CL, cs.CY, cs.LG]
HIGHLIGHT: We propose a conservative strategy for the cautious use of anthropomorphization to improve trustworthiness of AI systems.

18, TITLE: Towards Adaptive Prefix Tuning for Parameter-Efficient Language Model Fine-tuning
AUTHORS: ZHEN-RU ZHANG et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this work, we focus on prefix tuning, which only optimizes continuous prefix vectors (i.e. pseudo tokens) inserted into Transformer layers.

19, TITLE: Neural Summarization of Electronic Health Records
AUTHORS: Koyena Pal ; Seyed Ali Bahrainian ; Laura Mercurio ; Carsten Eickhoff
CATEGORY: cs.CL [cs.CL, cs.AI, cs.IR]
HIGHLIGHT: The objective of this study was to automatically generate hospital discharge summaries using neural network summarization models.

20, TITLE: Estimating Large Language Model Capabilities Without Labeled Test Data
AUTHORS: Harvey Yiyun Fu ; Qinyuan Ye ; Albert Xu ; Xiang Ren ; Robin Jia
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we propose the task of ICL accuracy estimation, in which we predict the accuracy of an LLM when doing in-context learning on a new task given only unlabeled data for that task.

21, TITLE: AWESOME: GPU Memory-constrained Long Document Summarization Using Memory Mechanism and Global Salient Content
AUTHORS: Shuyang Cao ; Lu Wang
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: This work aims to leverage the memory-efficient nature of divide-and-conquer methods while preserving global context.

22, TITLE: Dynamic Masking Rate Schedules for MLM Pretraining
AUTHORS: Zachary Ankner ; Naomi Saphra ; Davis Blalock ; Jonathan Frankle ; Matthew L. Leavitt
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: Most works on transformers trained with the Masked Language Modeling (MLM) objective use the original BERT model's fixed masking rate of 15%.

23, TITLE: Fourier Transformer: Fast Long Range Modeling By Removing Sequence Redundancy with FFT Operator
AUTHORS: ZIWEI HE et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We propose Fourier Transformer, a simple yet effective approach by progressively removing redundancies in hidden sequence using the ready-made Fast Fourier Transform (FFT) operator to perform Discrete Cosine Transformation (DCT).

24, TITLE: Referral Augmentation for Zero-Shot Information Retrieval
AUTHORS: Michael Tang ; Shunyu Yao ; John Yang ; Karthik Narasimhan
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We propose Referral-Augmented Retrieval (RAR), a simple technique that concatenates document indices with referrals, i.e. text from other documents that cite or link to the given document, to provide significant performance gains for zero-shot information retrieval.

25, TITLE: CSTS: Conditional Semantic Textual Similarity
AUTHORS: AMEET DESHPANDE et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: However, it is an inherently ambiguous task, with the sentence similarity depending on the specific aspect of interest. We resolve this ambiguity by proposing a novel task called conditional STS (C-STS) which measures similarity conditioned on an aspect elucidated in natural language (hereon, condition).

26, TITLE: STAR: Boosting Low-Resource Event Extraction By Structure-to-Text Data Generation with Large Language Models
AUTHORS: MINGYU DEREK MA et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: We propose STAR, a structure-to-text data generation method that first generates complicated event structures (Y) and then generates input passages (X), all with Large Language Models.

27, TITLE: Eliciting The Translation Ability of Large Language Models Via Multilingual Finetuning with Translation Instructions
AUTHORS: Jiahuan Li ; Hao Zhou ; Shujian Huang ; Shanbo Chen ; Jiajun Chen
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we present a detailed analysis by finetuning a multilingual pretrained language model, XGLM-7B, to perform multilingual translation following given instructions.

28, TITLE: Pento-DIARef: A Diagnostic Dataset for Learning The Incremental Algorithm for Referring Expression Generation from Examples
AUTHORS: Philipp Sadler ; David Schlangen
CATEGORY: cs.CL [cs.CL, cs.CV]
HIGHLIGHT: We present Pento-DIARef, a diagnostic dataset in a visual domain of puzzle pieces where referring expressions are generated by a well-known symbolic algorithm (the "Incremental Algorithm"), which itself is motivated by appeal to a hypothesised capability (eliminating distractors through application of Gricean maxims).

29, TITLE: Cream: Visually-Situated Natural Language Understanding with Contrastive Reading Model and Frozen Large Language Models
AUTHORS: GEEWOOK KIM et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this paper, we propose the Contrastive Reading Model (Cream), a novel neural architecture designed to enhance the language-image understanding capability of LLMs by capturing intricate details typically overlooked by existing methods.

30, TITLE: HuatuoGPT, Towards Taming Language Model to Be A Doctor
AUTHORS: HONGBO ZHANG et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this paper, we present HuatuoGPT, a large language model (LLM) for medical consultation.

31, TITLE: Have LLMs Advanced Enough? A Challenging Problem Solving Benchmark For Large Language Models
AUTHORS: Daman Arora ; Himanshu Gaurav Singh
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In response, we present JEEBench, a considerably more challenging benchmark dataset for evaluating the problem solving abilities of LLMs.

32, TITLE: Contrastive Learning of Sentence Embeddings from Scratch
AUTHORS: Junlei Zhang ; Zhenzhong Lan ; Junxian He
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: However, even in the case of unlabeled data, their acquisition presents challenges in certain domains due to various reasons. To address these issues, we present SynCSE, a contrastive learning framework that trains sentence embeddings with synthesized data.

33, TITLE: Meta-Learning Online Adaptation of Language Models
AUTHORS: Nathan Hu ; Eric Mitchell ; Christopher D. Manning ; Chelsea Finn
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We hypothesize that online fine-tuning does not sufficiently 'attend' to important information.

34, TITLE: Annotation Imputation to Individualize Predictions: Initial Studies on Distribution Dynamics and Model Predictions
AUTHORS: London Lowmanstone ; Ruyuan Wan ; Risako Owan ; Jaehyung Kim ; Dongyeop Kang
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Thus, we propose using imputation methods to restore the opinions of all annotators for all examples, creating a dataset that does not leave out any annotator's view.

35, TITLE: TACR: A Table-alignment-based Cell-selection and Reasoning Model for Hybrid Question-Answering
AUTHORS: JIAN WU et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Such a challenge made it difficult for previous studies to show their reasoning ability in retrieving answers. To bridge this gap, we propose a novel Table-alignment-based Cell-selection and Reasoning model (TACR) for hybrid text and table QA, evaluated on the HybridQA and WikiTableQuestions datasets.

36, TITLE: Interpretable By Design Visual Question Answering
AUTHORS: Xingyu Fu ; Ben Zhou ; Sihao Chen ; Mark Yatskar ; Dan Roth
CATEGORY: cs.CL [cs.CL, cs.AI, cs.CV]
HIGHLIGHT: In this paper, we specifically focus on the problem of Visual Question Answering (VQA).

37, TITLE: Exploring Contrast Consistency of Open-Domain Question Answering Systems on Minimally Edited Questions
AUTHORS: Zhihan Zhang ; Wenhao Yu ; Zheng Ning ; Mingxuan Ju ; Meng Jiang
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this work, we collect minimally edited questions as challenging contrast sets to evaluate OpenQA models.

38, TITLE: Emergent Inabilities? Inverse Scaling Over The Course of Pretraining
AUTHORS: James A. Michaelov ; Benjamin K. Bergen
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We find that for two tasks from the Inverse Scaling Challenge - quote-repetition and redefine-math - this is indeed the case. Specifically, we find that for Pythia (Biderman et al., 2023) models with a higher number of parameters, performance decreases over the course of training at these two tasks, despite these models showing standard (positive) scaling overall.

39, TITLE: Evaluating NLG Evaluation Metrics: A Measurement Theory Perspective
AUTHORS: Ziang Xiao ; Susu Zhang ; Vivian Lai ; Q. Vera Liao
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: Through this framework, we aim to promote the design, evaluation, and interpretation of valid and reliable metrics, ultimately contributing to the advancement of robust and effective NLG models in real-world settings.

40, TITLE: Privacy Implications of Retrieval-Based Language Models
AUTHORS: Yangsibo Huang ; Samyak Gupta ; Zexuan Zhong ; Kai Li ; Danqi Chen
CATEGORY: cs.CL [cs.CL, cs.CR, cs.LG]
HIGHLIGHT: In this work, we present the first study of privacy risks in retrieval-based LMs, particularly $k$NN-LMs.

41, TITLE: Meta-review Generation with Checklist-guided Iterative Introspection
AUTHORS: Qi Zeng ; Mankeerat Sidhu ; Hou Pong Chan ; Lu Wang ; Heng Ji
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: To address this gap, we propose the task of scientific opinion summarization, where research paper reviews are synthesized into meta-reviews. To facilitate this task, we introduce a new ORSUM dataset covering 10,989 paper meta-reviews and 40,903 paper reviews from 39 conferences.

42, TITLE: Iteratively Improving Biomedical Entity Linking and Event Extraction Via Hard Expectation-Maximization
AUTHORS: Xiaochu Li ; Minqian Liu ; Zhiyang Xu ; Lifu Huang
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: What's more, it's even more challenging to solve these two tasks together as there is no existing dataset that contains annotations for both tasks. To solve these challenges, we propose joint biomedical entity linking and event extraction by regarding the event structures and entity references in knowledge bases as latent variables and updating the two task-specific models in a hard Expectation-Maximization (EM) fashion: (1) predicting the missing variables for each partially annotated dataset based on the current two task-specific models, and (2) updating the parameters of each model on the corresponding pseudo completed dataset.

43, TITLE: Extracting Psychological Indicators Using Question Answering
AUTHORS: Luka Pavlovi?
CATEGORY: cs.CL [cs.CL, cs.CY]
HIGHLIGHT: In this work, we propose a method for extracting text spans that may indicate one of the BIG5 psychological traits using a question-answering task with examples that have no answer for the asked question.

44, TITLE: You Are What You Annotate: Towards Better Models Through Annotator Representations
AUTHORS: NAIHAO DENG et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: There are multiple reasons for such disagreements, including the subjectivity of the task, difficult cases, unclear guidelines, and so on. Rather than simply aggregating labels to obtain data annotations, we instead propose to explicitly account for the annotator idiosyncrasies and leverage them in the modeling process.

45, TITLE: ByteSized32: A Corpus and Challenge Task for Generating Task-Specific World Models Expressed As Text Games
AUTHORS: RUOYAO WANG et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this work we examine the ability of language models to generate explicit world models of scientific and common-sense reasoning tasks by framing this as a problem of generating text-based games.

46, TITLE: From Words to Wires: Generating Functioning Electronic Devices from Natural Language Descriptions
AUTHORS: Peter Jansen
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this work, we show that contemporary language models have a previously unknown skill -- the capacity for electronic circuit design from high-level textual descriptions, akin to code generation.

47, TITLE: Diffusion Models in NLP: A Survey
AUTHORS: Hao Zou ; Zae Myung Kim ; Dongyeop Kang
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: This survey paper provides a comprehensive review of the use of diffusion models in natural language processing (NLP).

48, TITLE: ClusterLLM: Large Language Models As A Guide for Text Clustering
AUTHORS: Yuwei Zhang ; Zihan Wang ; Jingbo Shang
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We introduce ClusterLLM, a novel text clustering framework that leverages feedback from an instruction-tuned large language model, such as ChatGPT.

49, TITLE: Testing Causal Models of Word Meaning in GPT-3 and -4
AUTHORS: Sam Musker ; Ellie Pavlick
CATEGORY: cs.CL [cs.CL, I.2.7]
HIGHLIGHT: Large Language Models (LLMs) have driven extraordinary improvements in NLP.

50, TITLE: Quantifying Character Similarity with Vision Transformers
AUTHORS: Xinmei Yang ; Abhishek Arora ; Shao-Yu Jheng ; Melissa Dell
CATEGORY: cs.CL [cs.CL, cs.CV, econ.GN, q-fin.EC]
HIGHLIGHT: This study develops an extensible way to measure character substitution costs for OCR'ed documents, by employing large-scale self-supervised training of vision transformers (ViT) with augmented digital fonts.

51, TITLE: Leveraging GPT-4 for Automatic Translation Post-Editing
AUTHORS: Vikas Raunak ; Amr Sharaf ; Hany Hassan Awadallah ; Arul Menezes
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this work, we formalize the task of translation post-editing with Large Language Models (LLMs) and explore the use of GPT-4 to automatically post-edit NMT outputs across several language pairs.

52, TITLE: CMOT: Cross-modal Mixup Via Optimal Transport for Speech Translation
AUTHORS: Yan Zhou ; Qingkai Fang ; Yang Feng
CATEGORY: cs.CL [cs.CL, cs.AI, cs.SD, eess.AS]
HIGHLIGHT: In this paper, we propose Cross-modal Mixup via Optimal Transport CMOT to overcome the modality gap.

53, TITLE: Improving Probability-based Prompt Selection Through Unified Evaluation and Analysis
AUTHORS: SOHEE YANG et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we propose a unified framework to interpret and evaluate the existing probability-based prompt selection methods by performing extensive experiments on 13 common NLP tasks.

54, TITLE: InteractiveIE: Towards Assessing The Strength of Human-AI Collaboration in Improving The Performance of Information Extraction
AUTHORS: ISHANI MONDAL et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Since the purpose of question answering intersect with the goal of information extraction, we use automatic question generation to induce template slots from the documents and investigate how a tiny amount of a proxy human-supervision on-the-fly (termed as InteractiveIE) can further boost the performance.

55, TITLE: Mixture of Prompt Experts for Generalizable and Interpretable Question Answering
AUTHORS: Chenglei Si ; Weijia Shi ; Chen Zhao ; Luke Zettlemoyer ; Jordan Boyd-Graber
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this paper, we first provide empirical evidence that state-of-the-art LLMs such as Codex suffer from poor generalizability on question types beyond those seen in the prompt. To address this, we propose a Mixture-of-Prompt-Experts (MOPE) system that ensembles multiple specialized LLMs.

56, TITLE: Advancements in Arabic Grammatical Error Detection and Correction: An Empirical Investigation
AUTHORS: Bashar Alhafni ; Go Inoue ; Christian Khairallah ; Nizar Habash
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we present the first results on Arabic GEC by using two newly developed Transformer-based pretrained sequence-to-sequence models.

57, TITLE: Revisit and Outstrip Entity Alignment: A Perspective of Generative Models
AUTHORS: Lingbing Guo ; Zhuo Chen ; Jiaoyan Chen ; Huajun Chen
CATEGORY: cs.CL [cs.CL, cs.IR, cs.LG]
HIGHLIGHT: In this paper, we study embedding-based entity alignment (EEA) from a perspective of generative models.

58, TITLE: CAR: Conceptualization-Augmented Reasoner for Zero-Shot Commonsense Question Answering
AUTHORS: WEIQI WANG et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: However, two bottlenecks limit these approaches: the inherent incompleteness of CSKBs limits the semantic coverage of synthetic QA pairs, and the lack of human annotations makes the sampled negative examples potentially uninformative and contradictory. To tackle these limitations above, we propose Conceptualization-Augmented Reasoner (CAR), a zero-shot commonsense question-answering framework that fully leverages the power of conceptualization.

59, TITLE: GPTAraEval: A Comprehensive Evaluation of ChatGPT on Arabic NLP
AUTHORS: Md Tawkat Islam Khondaker ; Abdul Waheed ; El Moatez Billah Nagoudi ; Muhammad Abdul-Mageed
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: To better understand ChatGPT's capabilities on Arabic, we present a large-scale evaluation of the model on a broad range of Arabic NLP tasks.

60, TITLE: Centering The Margins: Outlier-Based Identification of Harmed Populations in Toxicity Detection
AUTHORS: Vyoma Raman ; Eve Fleisig ; Dan Klein
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: A standard method for measuring the impacts of AI on marginalized communities is to determine performance discrepancies between specified demographic groups. These approaches aim to address harms toward vulnerable groups, but they obscure harm patterns faced by intersectional subgroups or shared across demographic groups.

61, TITLE: Denoising Bottleneck with Mutual Information Maximization for Video Multimodal Fusion
AUTHORS: SHAOXAING WU et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: They often suppress the redundant and noisy information at the risk of losing critical information. Therefore, we propose a denoising bottleneck fusion (DBF) model for fine-grained video multimodal fusion.

62, TITLE: Enabling Large Language Models to Generate Text with Citations
AUTHORS: Tianyu Gao ; Howard Yen ; Jiatong Yu ; Danqi Chen
CATEGORY: cs.CL [cs.CL, cs.IR, cs.LG]
HIGHLIGHT: In this work, we aim to enable LLMs to generate text with citations, improving their factual correctness and verifiability.

63, TITLE: Just Ask for Calibration: Strategies for Eliciting Calibrated Confidence Scores from Language Models Fine-Tuned with Human Feedback
AUTHORS: KATHERINE TIAN et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we conduct a broad evaluation of computationally feasible methods for extracting confidence scores from LLMs fine-tuned with RLHF.

64, TITLE: SenteCon: Leveraging Lexicons to Learn Human-Interpretable Language Representations
AUTHORS: Victoria Lin ; Louis-Philippe Morency
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We present SenteCon, a method for introducing human interpretability in deep language representations.

65, TITLE: Evaluate What You Can't Evaluate: Unassessable Generated Responses Quality
AUTHORS: Yongkang Liu ; Shi Feng ; Daling Wang ; Yifei Zhang ; Hinrich Schütze
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In order to comprehensively evaluate the reliability of evaluators based on LLMs, we construct two adversarial meta-evaluation dialogue generation datasets KdConv-ADV and DSTC7-ADV based on KdConv and DSTC7-AVSD, respectively.

66, TITLE: PIVOINE: Instruction Tuning for Open-world Information Extraction
AUTHORS: KEMING LU et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We consider the problem of Open-world Information Extraction (Open-world IE), which extracts comprehensive entity profiles from unstructured texts.

67, TITLE: AMELI: Enhancing Multimodal Entity Linking with Fine-Grained Attributes
AUTHORS: BARRY MENGLONG YAO et. al.
CATEGORY: cs.CL [cs.CL, I.2.7]
HIGHLIGHT: We propose attribute-aware multimodal entity linking, where the input is a mention described with a text and image, and the goal is to predict the corresponding target entity from a multimodal knowledge base (KB) where each entity is also described with a text description, a visual image and a set of attributes and values.

68, TITLE: Text Encoders Are Performance Bottlenecks in Contrastive Vision-language Models
AUTHORS: Amita Kamath ; Jack Hessel ; Kai-Wei Chang
CATEGORY: cs.CL [cs.CL, cs.CV, cs.LG]
HIGHLIGHT: Performant vision-language (VL) models like CLIP represent captions using a single vector.

69, TITLE: KNN-LM Does Not Improve Open-ended Text Generation
AUTHORS: SHUFAN WANG et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we study the generation quality of interpolation-based retrieval-augmented language models (LMs).

70, TITLE: In-Context Demonstration Selection with Cross Entropy Difference
AUTHORS: DAN ITER et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: We present a cross-entropy difference (CED) method for selecting in-context demonstrations.

71, TITLE: EXnet: Efficient In-context Learning for Data-less Text Classification
AUTHORS: Debaditya Shome ; Kuldeep Yadav
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: Our paper presents EXnet, a model specifically designed to perform in-context learning without any limitations on the number of examples.

72, TITLE: Complex Mathematical Symbol Definition Structures: A Dataset and Model for Coordination Resolution in Definition Extraction
AUTHORS: ANNA MARTIN-BOYLE et. al.
CATEGORY: cs.CL [cs.CL, I.2.7]
HIGHLIGHT: We present SymDef, an English language dataset of 5,927 sentences from full-text scientific papers where each sentence is annotated with all mathematical symbols linked with their corresponding definitions.

73, TITLE: Are Pre-trained Language Models Useful for Model Ensemble in Chinese Grammatical Error Correction?
AUTHORS: Chenming Tang ; Xiuyu Wu ; Yunfang Wu
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We hypothesize that model ensemble based on the perplexity (PPL) computed by pre-trained language models (PLMs) should benefit the GEC system.

74, TITLE: HiTIN: Hierarchy-aware Tree Isomorphism Network for Hierarchical Text Classification
AUTHORS: He Zhu ; Chong Zhang ; Junjie Huang ; Junran Wu ; Ke Xu
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we propose Hierarchy-aware Tree Isomorphism Network (HiTIN) to enhance the text representations with only syntactic information of the label hierarchy.

75, TITLE: Tricking LLMs Into Disobedience: Understanding, Analyzing, and Preventing Jailbreaks
AUTHORS: Abhinav Rao ; Sachin Vashistha ; Atharva Naik ; Somak Aditya ; Monojit Choudhury
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Limited formal studies have been carried out to formalize and analyze these attacks and their mitigations. We bridge this gap by proposing a formalism and a taxonomy of known (and possible) jailbreaks.

76, TITLE: I Spy A Metaphor: Large Language Models and Diffusion Models Co-Create Visual Metaphors
AUTHORS: TUHIN CHAKRABARTY et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.CV, cs.HC]
HIGHLIGHT: We propose to solve the task through the collaboration between Large Language Models (LLMs) and Diffusion Models: Instruct GPT-3 (davinci-002) with Chain-of-Thought prompting generates text that represents a visual elaboration of the linguistic metaphor containing the implicit meaning and relevant objects, which is then used as input to the diffusion-based text-to-image models.Using a human-AI collaboration framework, where humans interact both with the LLM and the top-performing diffusion model, we create a high-quality dataset containing 6,476 visual metaphors for 1,540 linguistic metaphors and their associated visual elaborations.

77, TITLE: Detecting and Characterizing Political Incivility on Social Media
AUTHORS: Sagi Penzel ; Nir Lotan ; Alon Zoizner ; Einat Minkov
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In our work, we study political incivility in Twitter, presenting several research contributions. First, we present state-of-the-art incivility detection results using a large dataset, which we collected and labeled via crowd sourcing.

78, TITLE: SciReviewGen: A Large-scale Dataset for Automatic Literature Review Generation
AUTHORS: Tetsu Kasanishi ; Masaru Isonuma ; Junichiro Mori ; Ichiro Sakata
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: We release SciReviewGen, consisting of over 10,000 literature reviews and 690,000 papers cited in the reviews.

79, TITLE: PESCO: Prompt-enhanced Self Contrastive Learning for Zero-shot Text Classification
AUTHORS: Yau-Shian Wang ; Ta-Chung Chi ; Ruohong Zhang ; Yiming Yang
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We present PESCO, a novel contrastive learning framework that substantially improves the performance of zero-shot text classification.

80, TITLE: GlobalBench: A Benchmark for Global Progress in Natural Language Processing
AUTHORS: YUEQI SONG et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: To track and further incentivize the global development of equitable language technology, we introduce GlobalBench.

81, TITLE: Exploiting Correlations Between Contexts and Definitions with Multiple Definition Modeling
AUTHORS: LINHAN ZHANG et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this paper, we carefully design a new task called Multiple Definition Modeling (MDM) that pool together all contexts and definition of target words.

82, TITLE: Editing Commonsense Knowledge in GPT
AUTHORS: ANSHITA GUPTA et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We propose $MEMIT_{CSK}$, an adaptation of MEMIT to edit commonsense mistakes in GPT-2 Large and XL.

83, TITLE: Improving Language Models with Advantage-based Offline Policy Gradients
AUTHORS: ASHUTOSH BAHETI et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: To this end, we present Left-over Lunch RL (LoL-RL), a simple training algorithm that uses offline policy gradients for learning language generation tasks as a 1-step RL game.

84, TITLE: Pre-training Multi-party Dialogue Models with Latent Discourse Inference
AUTHORS: Yiyang Li ; Xinting Huang ; Wei Bi ; Hai Zhao
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: However, due to the lack of explicitly annotated discourse labels in multi-party dialogue corpora, previous works fail to scale up the pre-training process by putting aside the unlabeled multi-party conversational data for nothing. To fully utilize the unlabeled data, we propose to treat the discourse structures as latent variables, then jointly infer them and pre-train the discourse-aware model by unsupervised latent variable inference methods.

85, TITLE: CuRIAM: Corpus Re Interpretation and Metalanguage in U.S. Supreme Court Opinions
AUTHORS: Michael Kranzlein ; Nathan Schneider ; Kevin Tobia
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We develop an annotation schema for categorizing types of legal metalanguage and apply our schema to a set of U.S. Supreme Court opinions, yielding a corpus totaling 59k tokens.

86, TITLE: Adversarial Demonstration Attacks on Large Language Models
AUTHORS: Jiongxiao Wang ; Zichen Liu ; Keun Hee Park ; Muhao Chen ; Chaowei Xiao
CATEGORY: cs.CL [cs.CL, cs.AI, cs.CR, cs.LG]
HIGHLIGHT: In this paper, we investigate the security concern of ICL from an adversarial perspective, focusing on the impact of demonstrations.

87, TITLE: How to Distill Your BERT: An Empirical Study on The Impact of Weight Initialisation and Distillation Objectives
AUTHORS: Xinpeng Wang ; Leonie Weissweiler ; Hinrich Schütze ; Barbara Plank
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: Recently, various intermediate layer distillation (ILD) objectives have been shown to improve compression of BERT models via Knowledge Distillation (KD).

88, TITLE: Instructions As Backdoors: Backdoor Vulnerabilities of Instruction Tuning for Large Language Models
AUTHORS: Jiashu Xu ; Mingyu Derek Ma ; Fei Wang ; Chaowei Xiao ; Muhao Chen
CATEGORY: cs.CL [cs.CL, cs.AI, cs.CR, cs.LG]
HIGHLIGHT: Instruction-tuned models are trained on crowdsourcing datasets with task instructions to achieve superior performance.

89, TITLE: Gender Biases in Automatic Evaluation Metrics: A Case Study on Image Captioning
AUTHORS: Haoyi Qiu ; Zi-Yi Dou ; Tianlu Wang ; Asli Celikyilmaz ; Nanyun Peng
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we conduct a systematic study in gender biases of model-based evaluation metrics with a focus on image captioning tasks.

90, TITLE: Flan-MoE: Scaling Instruction-Finetuned Language Models with Sparse Mixture of Experts
AUTHORS: SHENG SHEN et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we introduce Flan-MoE, a set of Instruction-Finetuned Sparse Mixture-of-Expert (MoE) models.

91, TITLE: Unlocking Temporal Question Answering for Large Language Models Using Code Execution
AUTHORS: XINGXUAN LI et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Our preliminary experiments show that generating intermediate reasoning steps does not always boost the performance of complex temporal question-answering tasks. Therefore, we propose a novel framework that combines the extraction capability of LLMs and the logical reasoning capability of a Python solver to tackle this issue.

92, TITLE: How Predictable Are Large Language Model Capabilities? A Case Study on BIG-bench
AUTHORS: Qinyuan Ye ; Harvey Yiyun Fu ; Xiang Ren ; Robin Jia
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: We study the performance prediction problem on experiment records from BIG-bench.

93, TITLE: Comparing Humans and Models on A Similar Scale: Towards Cognitive Gender Bias Evaluation in Coreference Resolution
AUTHORS: Gili Lior ; Gabriel Stanovsky
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this work we address the question: can we quantify the extent to which model biases reflect human behaviour?

94, TITLE: Revisiting Parallel Context Windows: A Frustratingly Simple Alternative and Chain-of-Thought Deterioration
AUTHORS: KEJUAN YANG et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We identify two crucial limitations in the evaluation of recent parallel-integrated method Parallel Context Windows (PCW), which extends the maximum context lengths of language models, e.g., 2048 for LLaMA, by harnessing window-wise attention and positional embedding techniques.

95, TITLE: An Efficient Multilingual Language Model Compression Through Vocabulary Trimming
AUTHORS: Asahi Ushio ; Yi Zhou ; Jose Camacho-Collados
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: On the contrary, monolingual LMs can be trained in a target language with the language-specific vocabulary only, but this requires a large budget and availability of reliable corpora to achieve a high-quality LM from scratch. In this paper, we propose vocabulary-trimming (VT), a method to reduce a multilingual LM vocabulary to a target language by deleting irrelevant tokens from its vocabulary.

96, TITLE: The Student Becomes The Master: Matching GPT3 on Scientific Factual Error Correction
AUTHORS: Dhananjay Ashok ; Atharva Kulkarni ; Hai Pham ; Barnabás Póczos
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: In this work, we introduce a claim correction system that makes no domain assumptions and does not require a verifier but is able to outperform existing methods by an order of magnitude -- achieving 94% correction accuracy on the SciFact dataset, and 62.5% on the SciFact-Open dataset, compared to the next best methods 0.5% and 1.50% respectively.

97, TITLE: ChatAgri: Exploring Potentials of ChatGPT on Cross-linguistic Agricultural Text Classification
AUTHORS: Biao Zhao ; Weiqiang Jin ; Javier Del Ser ; Guang Yang
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: Complex and expensive large models deployment.Inspired by the extraordinary success brought by the recent ChatGPT (e.g. GPT-3.5, GPT-4), in this work, we systematically investigate and explore the capability and utilization of ChatGPT applying to the agricultural informatization field.

98, TITLE: Cross-lingual Data Augmentation for Document-grounded Dialog Systems in Low Resource Languages
AUTHORS: Qi Gou ; Zehua Xia ; Wenzhe Du
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: This paper proposes a framework to address the issue of data scarcity in Document-Grounded Dialogue Systems(DGDS).

99, TITLE: Modeling Rapid Language Learning By Distilling Bayesian Priors Into Artificial Neural Networks
AUTHORS: R. Thomas McCoy ; Thomas L. Griffiths
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: We show that learning from limited naturalistic data is possible with an approach that combines the strong inductive biases of a Bayesian model with the flexible representations of a neural network.

100, TITLE: Analyzing Influential Factors in Human Preference Judgments Via GPT-4
AUTHORS: YEBOWEN HU et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we conduct an in-depth examination of a dataset of pairwise human judgments released by OpenAI.

101, TITLE: A Fair and In-Depth Evaluation of Existing End-to-End Entity Linking Systems
AUTHORS: Hannah Bast ; Matthias Hertel ; Natalie Prange
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We provide a more meaningful and fair in-depth evaluation of a variety of existing end-to-end entity linkers.

102, TITLE: Sentiment Analysis in The Era of Large Language Models: A Reality Check
AUTHORS: Wenxuan Zhang ; Yue Deng ; Bing Liu ; Sinno Jialin Pan ; Lidong Bing
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: This paper aims to provide a comprehensive investigation into the capabilities of LLMs in performing various sentiment analysis tasks, from conventional sentiment classification to aspect-based sentiment analysis and multifaceted analysis of subjective texts.

103, TITLE: Trade-Offs Between Fairness and Privacy in Language Modeling
AUTHORS: Cleo Matzken ; Steffen Eger ; Ivan Habernal
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Existing research suggests that privacy preservation comes at the price of worsening biases in classification tasks. In this paper, we explore the extent to which this tradeoff really holds when we incorporate both privacy preservation and de-biasing techniques into training text generation models.

104, TITLE: LLMDet: A Large Language Models Detection Tool
AUTHORS: Kangxi Wu ; Liang Pang ; Huawei Shen ; Xueqi Cheng ; Tat-Seng Chua
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: However, existing detection tools typically require access to language models and can only differentiate between machine-generated and human-authored text, failing to meet the requirements of rapid detection and text tracing. Therefore, in this paper, we propose an efficient, secure, and scalable detection tool called LLMDet, which calculates the proxy perplexity of text by utilizing the prior information of the model's next-token probabilities, obtained through pre-training.

105, TITLE: Modeling Appropriate Language in Argumentation
AUTHORS: Timon Ziegenbein ; Shahbaz Syed ; Felix Lange ; Martin Potthast ; Henning Wachsmuth
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we operationalize appropriate language in argumentation for the first time.

106, TITLE: Discriminator-Guided Multi-step Reasoning with Language Models
AUTHORS: Muhammad Khalifa ; Lajanugen Logeswaran ; Moontae Lee ; Honglak Lee ; Lu Wang
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In addition, methods such as self-consistency and verifiers rely on sampling from the LM distribution and do not tackle the underlying issue. To address this, we introduce Guiding Multi-step ReAsoning with a CorrectnEss Discriminator (GRACE), a stepwise decoding approach that nudges the model towards producing correct reasoning steps.

107, TITLE: Do LLMs Understand Social Knowledge? Evaluating The Sociability of Large Language Models with SocKET Benchmark
AUTHORS: Minje Choi ; Jiaxin Pei ; Sagar Kumar ; Chang Shu ; David Jurgens
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: Here, we introduce a new theory-driven benchmark, SocKET, that contains 58 NLP tasks testing social knowledge which we group into five categories: humor & sarcasm, offensiveness, sentiment & emotion, and trustworthiness.

108, TITLE: Are Chatbots Ready for Privacy-Sensitive Applications? An Investigation Into Input Regurgitation and Prompt-Induced Sanitization
AUTHORS: Aman Priyanshu ; Supriti Vijay ; Ayush Kumar ; Rakshit Naidu ; Fatemehsadat Mireshghallah
CATEGORY: cs.CL [cs.CL, cs.AI, cs.CY]
HIGHLIGHT: The information provided in the prompt could directly appear in the output, which might have privacy ramifications if there is sensitive information there. As such, in this paper, we aim to understand the input copying and regurgitation capabilities of these models during inference and how they can be directly instructed to limit this copying by complying with regulations such as HIPAA and GDPR, based on their internal knowledge of them.

109, TITLE: LMs with A Voice: Spoken Language Modeling Beyond Speech Tokens
AUTHORS: ELIYA NACHMANI et. al.
CATEGORY: cs.CL [cs.CL, cs.LG, cs.SD, eess.AS]
HIGHLIGHT: We present SPECTRON, a novel approach to adapting pre-trained language models (LMs) to perform speech continuation.

110, TITLE: Are Large Language Models Robust Zero-shot Coreference Resolvers?
AUTHORS: Nghia T. Le ; Alan Ritter
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this work, we assess the feasibility of zero-shot learning for coreference resolution by evaluating instruction-tuned language models on more difficult, linguistically-complex coreference benchmarks (e.g., CoNLL-2012).

111, TITLE: Gorilla: Large Language Model Connected with Massive APIs
AUTHORS: Shishir G. Patil ; Tianjun Zhang ; Xin Wang ; Joseph E. Gonzalez
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: To evaluate the model's ability, we introduce APIBench, a comprehensive dataset consisting of HuggingFace, TorchHub, and TensorHub APIs.

112, TITLE: Bactrian-X : A Multilingual Replicable Instruction-Following Model with Low-Rank Adaptation
AUTHORS: Haonan Li ; Fajri Koto ; Minghao Wu ; Alham Fikri Aji ; Timothy Baldwin
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: However, the research on multilingual instruction tuning has been limited due to the scarcity of high-quality instruction-response datasets. To address this gap, we present Bactrian-X, a comprehensive multilingual parallel dataset of 3.4 million instruction-response pairs across 52 languages.

113, TITLE: Injecting Knowledge Into Biomedical Pre-trained Models Via Polymorphism and Synonymous Substitution
AUTHORS: Hongbo Zhang ; Xiang Wan ; Benyou Wang
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: To additionally inject relational knowledge into PLMs, we propose a simple-yet-effective approach to inject relational knowledge into PLMs, which is inspired by three observations (namely, polymorphism, synonymous substitution, and association).

114, TITLE: Sociocultural Norm Similarities and Differences Via Situational Alignment and Explainable Textual Entailment
AUTHORS: Sky CH-Wang ; Arkadiy Saakyan ; Oliver Li ; Zhou Yu ; Smaranda Muresan
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Here, we propose a novel approach to discover and compare descriptive social norms across Chinese and American cultures.

115, TITLE: A RelEntLess Benchmark for Modelling Graded Relations Between Named Entities
AUTHORS: Asahi Ushio ; Jose Camacho Collados ; Steven Schockaert
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: Such graded relations play a central role in many applications, yet they are typically not covered by existing Knowledge Graphs. In this paper, we consider the possibility of using Large Language Models (LLMs) to fill this gap.

116, TITLE: Prompt Position Really Matters in Few-shot and Zero-shot NLU Tasks
AUTHORS: Junyu Mao ; Stuart E. Middleton ; Mahesan Niranjan
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: However, prior studies have mainly focused on prompt vocabulary selection or embedding initialization with the reserved prompt position fixed. In this empirical study, we conduct the most comprehensive analysis to date of prompt position option for natural language understanding tasks.

117, TITLE: SAIL: Search-Augmented Instruction Learning
AUTHORS: HONGYIN LUO et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this work, we propose search-augmented instruction learning (SAIL), which grounds the language generation and instruction following abilities on complex search results generated by in-house and external search engines.

118, TITLE: Boosting Cross-lingual Transferability in Multilingual Models Via In-Context Learning
AUTHORS: Sunkyoung Kim ; Dayeon Ki ; Yireun Kim ; Jinsik Lee
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this paper, we propose In-CLT, a novel cross-lingual transfer prompting method that leverages both source and target languages to construct the demonstration examples.

119, TITLE: Universal Self-adaptive Prompting
AUTHORS: XINGCHEN WAN et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: However, while highly coveted and being the most general, zero-shot performances in LLMs are still typically weaker due to the lack of guidance and the difficulty of applying existing automatic prompt design methods in general tasks when ground-truth labels are unavailable. In this study, we address this by presenting Universal Self-adaptive Prompting (USP), an automatic prompt design approach specifically tailored for zero-shot learning (while compatible with few-shot).

120, TITLE: Aligning Language Models to User Opinions
AUTHORS: EunJeong Hwang ; Bodhisattwa Prasad Majumder ; Niket Tandon
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Mining public opinion surveys (by Pew Research), we find that the opinions of a user and their demographics and ideologies are not mutual predictors. We use this insight to align LLMs by modeling both user opinions as well as user demographics and ideology, achieving up to 7 points accuracy gains in predicting public opinions from survey questions across a broad set of topics.

121, TITLE: Towards Reliable Misinformation Mitigation: Generalization, Uncertainty, and GPT-4
AUTHORS: Kellin Pelrine ; Meilina Reksoprodjo ; Caleb Gupta ; Joel Christoph ; Reihaneh Rabbany
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: We propose focusing on generalization, soft classification, and leveraging recent large language models to create more practical tools in contexts where perfect predictions remain unattainable.

122, TITLE: CoLaDa: A Collaborative Label Denoising Framework for Cross-lingual Named Entity Recognition
AUTHORS: TINGTING MA et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: However, these methods may suffer from label noise due to the automatic labeling process. In this paper, we propose CoLaDa, a Collaborative Label Denoising Framework, to address this problem.

123, TITLE: Frugal Prompting for Dialog Models
AUTHORS: Bishal Santra ; Sakya Basak ; Abhinandan De ; Manish Gupta ; Pawan Goyal
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: This study examines different approaches for building dialog systems using LLMs by considering various aspects of the prompt.

124, TITLE: Structural Ambiguity and Its Disambiguation in Language Model Based Parsers: The Case of Dutch Clause Relativization
AUTHORS: Gijs Wijnholds ; Michael Moortgat
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: We apply this method to two parsing architectures in an attempt to demystify the parsing and language model components of two present-day neural parsers.

125, TITLE: From Shortcuts to Triggers: Backdoor Defense with Denoised PoE
AUTHORS: Qin Liu ; Fei Wang ; Chaowei Xiao ; Muhao Chen
CATEGORY: cs.CL [cs.CL, cs.AI, cs.CR, cs.LG]
HIGHLIGHT: In this paper, we propose an end-to-end ensemble-based backdoor defense framework, DPoE (Denoised Product-of-Experts), which is inspired by the shortcut nature of backdoor attacks, to defend various backdoor attacks.

126, TITLE: Identifying Informational Sources in News Articles
AUTHORS: Alexander Spangher ; Nanyun Peng ; Jonathan May ; Emilio Ferrara
CATEGORY: cs.CL [cs.CL, cs.AI, cs.CY]
HIGHLIGHT: Modeling when, how and why sources get used together in stories can help us better understand the information we consume and even help journalists with the task of producing it. In this work, we take steps toward this goal by constructing the largest and widest-ranging annotated dataset, to date, of informational sources used in news writing.

127, TITLE: M4: Multi-generator, Multi-domain, and Multi-lingual Black-Box Machine-Generated Text Detection
AUTHORS: YUXIA WANG et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this work, we aim to develop automatic systems to identify machine-generated text and to detect potential misuse.

128, TITLE: Chain-of-Questions Training with Latent Answers for Robust Multistep Question Answering
AUTHORS: Wang Zhu ; Jesse Thomason ; Robin Jia
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: We propose Chain-of-Questions, a framework that trains a model to generate sub-questions and sub-answers one at a time by leveraging human annotated question decomposition meaning representation (QDMR).

129, TITLE: PURR: Efficiently Editing Language Model Hallucinations By Denoising Language Model Corruptions
AUTHORS: Anthony Chen ; Panupong Pasupat ; Sameer Singh ; Hongrae Lee ; Kelvin Guu
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: The remarkable capabilities of large language models have been accompanied by a persistent drawback: the generation of false and unsubstantiated claims commonly known as "hallucinations". To combat this issue, recent research has introduced approaches that involve editing and attributing the outputs of language models, particularly through prompt-based editing.

130, TITLE: Coverage-based Example Selection for In-Context Learning
AUTHORS: Shivanshu Gupta ; Sameer Singh ; Matt Gardner
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: This work proposes a framework for assessing the informativeness of demonstrations based on their coverage of salient aspects (e.g., reasoning patterns) of the test input.

131, TITLE: Large Language Model Distillation Doesn't Need A Teacher
AUTHORS: Ananya Harsh Jha ; Dirk Groeneveld ; Emma Strubell ; Iz Beltagy
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We propose a teacher-free task-agnostic distillation method, which uses a truncated version of the larger model for initialization, and continues pretraining this model using a language modeling objective.

132, TITLE: Self-Checker: Plug-and-Play Modules for Fact-Checking with Large Language Models
AUTHORS: Miaoran Li ; Baolin Peng ; Zhu Zhang
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we aim to assess the capacity of LLMs for fact-checking by introducing Self-Checker, a framework comprising a set of plug-and-play modules that facilitate fact-checking by purely prompting LLMs in an almost zero-shot setting.

133, TITLE: COMET-M: Reasoning About Multiple Events in Complex Sentences
AUTHORS: Sahithya Ravi ; Raymond Ng ; Vered Shwartz
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: We propose COMET-M (Multi-Event), an event-centric commonsense model capable of generating commonsense inferences for a target event within a complex sentence.

134, TITLE: Abductive Commonsense Reasoning Exploiting Mutually Exclusive Explanations
AUTHORS: Wenting Zhao ; Justin T. Chiu ; Claire Cardie ; Alexander M. Rush
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: Instead of using direct supervision, this work proposes an approach for abductive commonsense reasoning that exploits the fact that only a subset of explanations is correct for a given context.

135, TITLE: BUFFET: Benchmarking Large Language Models for Few-shot Cross-lingual Transfer
AUTHORS: AKARI ASAI et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: To facilitate research on few-shot cross-lingual transfer, we introduce a new benchmark, called BUFFET, which unifies 15 diverse tasks across 54 languages in a sequence-to-sequence format and provides a fixed set of few-shot examples and instructions.

136, TITLE: Exploring The Grounding Issues in Image Caption
AUTHORS: Pin-Er Chen ; Hsin-Yu Chou ; Po-Ya Angela Wang ; Yu-Hsiang Tseng ; Shu-Kai Hsieh
CATEGORY: cs.CL [cs.CL, cs.CV]
HIGHLIGHT: This paper explores the grounding issue concerning multimodal semantic representation from a computational cognitive-linguistic view.

137, TITLE: This Land Is {Your, My} Land: Evaluating Geopolitical Biases in Language Models
AUTHORS: Bryan Li ; Chris Callison-Burch
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We introduce the notion of geopolitical bias -- a tendency to report different geopolitical knowledge depending on the linguistic context.

138, TITLE: Selectively Answering Ambiguous Questions
AUTHORS: JEREMY R. COLE et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: We investigate question answering from this perspective, focusing on answering a subset of questions with a high degree of accuracy, from a set of questions in which many are inherently ambiguous.

139, TITLE: Drafting Event Schemas Using Language Models
AUTHORS: Anisha Gunjal ; Greg Durrett
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Such schemas can lead to explainable predictions and forecasting of unseen events given incomplete information. In this work, we look at the process of creating such schemas to describe complex events.

140, TITLE: OpenPI2.0: An Improved Dataset for Entity Tracking in Texts
AUTHORS: Li Zhang ; Hainiu Xu ; Abhinav Kommula ; Niket Tandon ; Chris Callison-Burch
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We propose OpenPI2.0, an improved dataset for tracking entity states in procedural texts.

141, TITLE: Meta-Learning For Vision-and-Language Cross-lingual Transfer
AUTHORS: Hanxu Hu ; Frank Keller
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Current PVLMs typically perform poorly on these datasets when used for multi-modal zero-shot or few-shot cross-lingual transfer, especially for low-resource languages. To alleviate this problem, we propose a novel meta-learning fine-tuning framework.

142, TITLE: Learning Semantic Role Labeling from Compatible Label Sequences
AUTHORS: Tao Li ; Ghazaleh Kazeminejad ; Susan W. Brown ; Martha Palmer ; Vivek Srikumar
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: This paper addresses the question of how to efficiently learn from disjoint, compatible label sequences.

143, TITLE: Exploring Sentiment Analysis Techniques in Natural Language Processing: A Comprehensive Review
AUTHORS: Karthick Prasad Gunasekaran
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: Additionally, researchers rely on SA to analyze public sentiment on various topics. In this particular research study, a comprehensive survey was conducted to explore the latest trends and techniques in SA.

144, TITLE: ComSL: A Composite Speech-Language Model for End-to-End Speech-to-Text Translation
AUTHORS: CHENYANG LE et. al.
CATEGORY: cs.CL [cs.CL, cs.SD, eess.AS]
HIGHLIGHT: We present ComSL, a speech-language model built atop a composite architecture of public pretrained speech-only and language-only models and optimized data-efficiently for spoken language tasks.

145, TITLE: SummIt: Iterative Text Summarization Via ChatGPT
AUTHORS: Haopeng Zhang ; Xiao Liu ; Jiawei Zhang
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: The one-shot summarization setting is sometimes inadequate, however, as the generated summary may contain hallucinations or overlook important details related to the reader's interests. In this paper, we address this limitation by proposing SummIt, an iterative text summarization framework based on large language models like ChatGPT.

146, TITLE: PaCE: Unified Multi-modal Dialogue Pre-training with Progressive and Compositional Experts
AUTHORS: YUNSHUI LI et. al.
CATEGORY: cs.CL [cs.CL, cs.CV]
HIGHLIGHT: This paper proposes \textbf{PaCE}, a unified, structured, compositional multi-modal dialogue pre-training framework.

147, TITLE: Pre-training Intent-Aware Encoders for Zero- and Few-Shot Intent Classification
AUTHORS: MUJEEN SUNG et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We propose a novel pre-training method for text encoders that uses contrastive learning with intent psuedo-labels to produce embeddings that are well-suited for IC tasks.

148, TITLE: Topic-Guided Self-Introduction Generation for Social Media Users
AUTHORS: Chunpu Xu ; Jing Li ; Piji Li ; Min Yang
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: The task is non-trivial because the history content may be lengthy, noisy, and exhibit various personal interests. To address this challenge, we propose a novel unified topic-guided encoder-decoder (UTGED) framework; it models latent topics to reflect salient user interest, whose topic mixture then guides encoding a user's history and topic words control decoding their self-introduction.

149, TITLE: Large Language Models Are In-Context Semantic Reasoners Rather Than Symbolic Reasoners
AUTHORS: XIAOJUAN TANG et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this work, we hypothesize that the learned \textit{semantics} of language tokens do the most heavy lifting during the reasoning process.

150, TITLE: Mitigating Temporal Misalignment By Discarding Outdated Facts
AUTHORS: Michael J. Q. Zhang ; Eunsol Choi
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: To mitigate the effects of temporal misalignment, we propose fact duration prediction: the task of predicting how long a given fact will remain true.

151, TITLE: Towards Few-shot Entity Recognition in Document Images: A Graph Neural Network Approach Robust to Image Manipulation
AUTHORS: Prashant Krishnan ; Zilong Wang ; Yangkun Wang ; Jingbo Shang
CATEGORY: cs.CL [cs.CL, cs.CV]
HIGHLIGHT: In this paper, we propose to further introduce the topological adjacency relationship among the tokens, emphasizing their relative position information.

152, TITLE: Uncovering and Quantifying Social Biases in Code Generation
AUTHORS: YAN LIU et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this work, we explore the social bias problem in pre-trained code generation models.

153, TITLE: Machine Reading Comprehension Using Case-based Reasoning
AUTHORS: DUNG THAI et. al.
CATEGORY: cs.CL [cs.CL, cs.IR]
HIGHLIGHT: We present an accurate and interpretable method for answer extraction in machine reading comprehension that is reminiscent of case-based reasoning (CBR) from classical AI.

154, TITLE: Sentiment Analysis Using Aligned Word Embeddings for Uralic Languages
AUTHORS: Khalid Alnajjar ; Mika Hämäläinen ; Jack Rueter
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we present an approach for translating word embeddings from a majority language into 4 minority languages: Erzya, Moksha, Udmurt and Komi-Zyrian.

155, TITLE: Peek Across: Improving Multi-Document Modeling Via Cross-Document Question-Answering
AUTHORS: Avi Caciularu ; Matthew E. Peters ; Jacob Goldberger ; Ido Dagan ; Arman Cohan
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: The integration of multi-document pre-training objectives into language models has resulted in remarkable improvements in multi-document downstream tasks. In this work, we propose extending this idea by pre-training a generic multi-document model from a novel cross-document question answering pre-training objective.

156, TITLE: Vistaar: Diverse Benchmarks and Training Sets for Indian Language ASR
AUTHORS: KAUSHAL SANTOSH BHOGALE et. al.
CATEGORY: cs.CL [cs.CL, cs.SD, eess.AS]
HIGHLIGHT: In this paper, we focus on Indian languages, and make the case that diverse benchmarks are required to evaluate and improve ASR systems for Indian languages.

157, TITLE: On Degrees of Freedom in Defining and Testing Natural Language Understanding
AUTHORS: Saku Sugawara ; Shun Tsugita
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: These erroneous evaluations can be attributed to the difficulty of defining and testing NLU adequately. In this position paper, we reconsider this challenge by identifying two types of researcher degrees of freedom.

158, TITLE: ASPER: Answer Set Programming Enhanced Neural Network Models for Joint Entity-Relation Extraction
AUTHORS: Trung Hoang Le ; Huiping Cao ; Tran Cao Son
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: This paper proposes a new approach, ASP-enhanced Entity-Relation extraction (ASPER), to jointly recognize entities and relations by learning from both data and domain knowledge.

159, TITLE: Context-Aware Transformer Pre-Training for Answer Sentence Selection
AUTHORS: Luca Di Liello ; Siddhant Garg ; Alessandro Moschitti
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: In this paper, we propose three pre-training objectives designed to mimic the downstream fine-tuning task of contextual AS2.

160, TITLE: BAND: Biomedical Alert News Dataset
AUTHORS: ZIHAO FU et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: However, existing systems lack thorough epidemiological analysis in relation to corresponding alerts or news, largely due to the scarcity of well-annotated reports data. To address this gap, we introduce the Biomedical Alert News Dataset (BAND), which includes 1,508 samples from existing reported news articles, open emails, and alerts, as well as 30 epidemiology-related questions.

161, TITLE: FOCUS: Effective Embedding Initialization for Specializing Pretrained Multilingual Models on A Single Language
AUTHORS: Konstantin Dobler ; Gerard de Melo
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we investigate the multilingual source model setting and propose FOCUS - Fast Overlapping Token Combinations Using Sparsemax, a novel embedding initialization method that outperforms previous work when adapting XLM-R.

162, TITLE: Is A Prestigious Job The Same As A Prestigious Country? A Case Study on Multilingual Sentence Embeddings and European Countries
AUTHORS: Jind?ich Libovický
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We study how multilingual sentence representations capture European countries and how this differs across European languages.

163, TITLE: Another Dead End for Morphological Tags? Perturbed Inputs and Parsing
AUTHORS: Alberto Muńoz-Ortiz ; David Vilares
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Yet, most studies are limited to coarse-grained tags and high quality written content; while we know little about their influence when it comes to models in production that face lexical errors. We expand these setups and design an adversarial attack to verify if the use of morphological information by parsers: (i) contributes to error propagation or (ii) if on the other hand it can play a role to correct mistakes that word-only neural parsers make.

164, TITLE: Language Model Self-improvement By Reinforcement Learning Contemplation
AUTHORS: JING-CHENG PANG et. al.
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: This paper introduces a novel unsupervised method called LanguageModel Self-Improvement by Reinforcement Learning Contemplation (SIRLC) that improves LLMs without reliance on external labels.

165, TITLE: NAIL: Lexical Retrieval Indices with Efficient Non-Autoregressive Decoders
AUTHORS: Livio Baldini Soares ; Daniel Gillick ; Jeremy R. Cole ; Tom Kwiatkowski
CATEGORY: cs.CL [cs.CL, cs.IR]
HIGHLIGHT: However, the best models require dedicated hardware for serving, which is costly and often not feasible. To avoid this serving-time requirement, we present a method of capturing up to 86% of the gains of a Transformer cross-attention model with a lexicalized scoring function that only requires 10-6% of the Transformer's FLOPs per document and can be served using commodity CPUs.

166, TITLE: CGCE: A Chinese Generative Chat Evaluation Benchmark for General and Financial Domains
AUTHORS: Xuanyu Zhang ; Bingbing Li ; Qing Yang
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: However, the lack of standardized evaluation benchmarks for chat models, particularly for Chinese and domain-specific models, hinders their assessment and progress. To address this gap, we introduce the Chinese Generative Chat Evaluation (CGCE) benchmark, focusing on general and financial domains.

167, TITLE: Self-Polish: Enhance Reasoning in Large Language Models Via Problem Refinement
AUTHORS: ZHIHENG XI et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: However, they have overlooked the potential challenges posed by the poor quality of reasoning problems, which may influence the reasoning performance significantly. In this work, we propose Self-Polish (SP), a novel method that facilitates the model's problem-solving process by prompting them to progressively refine the given problems to be more comprehensible and solvable.

168, TITLE: Learning Answer Generation Using Supervision from Automatic Question Answering Evaluators
AUTHORS: Matteo Gabburo ; Siddhant Garg ; Rik Koncel-Kedziorski ; Alessandro Moschitti
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: In this paper, we propose a novel training paradigm for GenQA using supervision from automatic QA evaluation models (GAVA).

169, TITLE: The Role of Output Vocabulary in T2T LMs for SPARQL Semantic Parsing
AUTHORS: Debayan Banerjee ; Pranav Ajit Nair ; Ricardo Usbeck ; Chris Biemann
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this work, we analyse the role of output vocabulary for text-to-text (T2T) models on the task of SPARQL semantic parsing.

170, TITLE: Having Beer After Prayer? Measuring Cultural Bias in Large Language Models
AUTHORS: Tarek Naous ; Michael J. Ryan ; Wei Xu
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: However, we show in this paper that language models suffer from a significant bias towards Western culture when handling and generating text in Arabic, often preferring, and producing Western-fitting content as opposed to the relevant Arab content. We quantify this bias through a likelihood scoring-based metric using naturally occurring contexts that we collect from online social media.

171, TITLE: A Causal View of Entity Bias in (Large) Language Models
AUTHORS: Fei Wang ; Wenjie Mo ; Yiwei Wang ; Wenxuan Zhou ; Muhao Chen
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: The rise of black-box LLMs also makes the situation even worse, because of their inaccessible parameters and uncalibrated logits. To address these problems, we propose a specific structured causal model (SCM) whose parameters are comparatively easier to estimate.

172, TITLE: On Robustness of Finetuned Transformer-based NLP Models
AUTHORS: Pavan Kalyan Reddy Neerudu ; Subba Reddy Oota ; Mounika Marreddy ; Venkateswara Rao Kagita ; Manish Gupta
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we study the robustness of three language models (BERT, GPT-2 and T5) with eight different text perturbations on the General Language Understanding Evaluation (GLUE) benchmark.

173, TITLE: SELFOOD: Self-Supervised Out-Of-Distribution Detection Via Learning to Rank
AUTHORS: Dheeraj Mekala ; Adithya Samavedhi ; Chengyu Dong ; Jingbo Shang
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: To address the annotation bottleneck, we introduce SELFOOD, a self-supervised OOD detection method that requires only in-distribution samples as supervision.

174, TITLE: Clever Hans or Neural Theory of Mind? Stress Testing Social Reasoning in Large Language Models
AUTHORS: NATALIE SHAPIRA et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Recently, many anecdotal examples were used to suggest that newer large language models (LLMs) like ChatGPT and GPT-4 exhibit Neural Theory-of-Mind (N-ToM); however, prior work reached conflicting conclusions regarding those abilities. We investigate the extent of LLMs' N-ToM through an extensive evaluation on 6 tasks and find that while LLMs exhibit certain N-ToM abilities, this behavior is far from being robust.

175, TITLE: Enhancing Generation Through Summarization Duality and Explicit Outline Control
AUTHORS: YUNZHE LI et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: Furthermore, we identify an underutilization issue in outline-based generation with both standard pretrained language models (e.g., GPT-2, BART) and large language models (e.g., Vicuna, ChatGPT). To address this, we propose a novel explicit outline control method for more effective utilization of generated outlines.

176, TITLE: UniChart: A Universal Vision-language Pretrained Model for Chart Comprehension and Reasoning
AUTHORS: Ahmed Masry ; Parsa Kavehzadeh ; Xuan Long Do ; Enamul Hoque ; Shafiq Joty
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We propose several chart-specific pretraining tasks that include: (i) low-level tasks to extract the visual elements (e.g., bars, lines) and data from charts, and (ii) high-level tasks to acquire chart understanding and reasoning skills.

177, TITLE: Pre-training Language Models for Comparative Reasoning
AUTHORS: Mengxia Yu ; Zhihan Zhang ; Wenhao Yu ; Meng Jiang
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we propose a novel framework to pre-train language models for enhancing their abilities of comparative reasoning over texts.

178, TITLE: Dancing Between Success and Failure: Edit-level Simplification Evaluation Using SALSA
AUTHORS: David Heineman ; Yao Dou ; Mounica Maddela ; Wei Xu
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Large language models (e.g., GPT-3.5) are uniquely capable of producing highly rated text simplification, yet current human evaluation methods fail to provide a clear understanding of systems' specific strengths and weaknesses. To address this limitation, we introduce SALSA, an edit-based human annotation framework that enables holistic and fine-grained text simplification evaluation.

179, TITLE: Towards Massively Multi-domain Multilingual Readability Assessment
AUTHORS: Tarek Naous ; Michael J. Ryan ; Mohit Chandra ; Wei Xu
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: We present ReadMe++, a massively multi-domain multilingual dataset for automatic readability assessment.

180, TITLE: BeamSearchQA: Large Language Models Are Strong Zero-Shot QA Solver
AUTHORS: Hao Sun ; Xiao Liu ; Yeyun Gong ; Yan Zhang ; Nan Duan
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this work, we propose a novel question-answering pipeline called eamSearchQA.

181, TITLE: Using Natural Language Explanations to Rescale Human Judgments
AUTHORS: Manya Wadhwa ; Jifan Chen ; Junyi Jessy Li ; Greg Durrett
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: However, different annotators may have different interpretations of labeling schemes unless given extensive training, and for subjective NLP tasks, even trained expert annotators can diverge heavily. We show that these nuances can be captured by high quality natural language explanations, and propose a method to rescale ordinal annotation in the presence of disagreement using LLMs.

182, TITLE: SSD-2: Scaling and Inference-time Fusion of Diffusion Language Models
AUTHORS: Xiaochuang Han ; Sachin Kumar ; Yulia Tsvetkov ; Marjan Ghazvininejad
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: While autoregressive LMs have benefited immensely from scaling and instruction-based learning, existing studies on diffusion LMs have been conducted on a relatively smaller scale. Starting with a recently proposed diffusion model SSD-LM, in this work we explore methods to scale it from 0.4B to 13B parameters, proposing several techniques to improve its training and inference efficiency.

183, TITLE: ExpertPrompting: Instructing Large Language Models to Be Distinguished Experts
AUTHORS: BENFENG XU et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this paper, we propose ExpertPrompting to elicit the potential of LLMs to answer as distinguished experts.

184, TITLE: RefGPT: Reference -> Truthful & Customized Dialogues Generation By GPTs and for GPTs
AUTHORS: DONGJIE YANG et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Though previous studies have used powerful LLMs to generate the dialogues automatically, but they all suffer from generating untruthful dialogues because of the LLMs hallucination. Therefore, we propose a method called RefGPT to generate enormous truthful and customized dialogues without worrying about factual errors caused by the model hallucination.

185, TITLE: Have Large Language Models Developed A Personality?: Applicability of Self-Assessment Tests in Measuring Personality in LLMs
AUTHORS: Xiaoyang Song ; Akshat Gupta ; Kiyan Mohebbizadeh ; Shujie Hu ; Anant Singh
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: In this paper, we investigate the emergence of personality in five LLMs of different sizes ranging from 1.5B to 30B.

186, TITLE: How To Control Text Simplification? An Empirical Study of Control Tokens for Meaning Preserving Controlled Simplification
AUTHORS: Sweta Agrawal ; Marine Carpuat
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this work, we conduct an empirical study to understand how different control mechanisms impact the adequacy and simplicity of model outputs.

187, TITLE: Mastering The ABCDs of Complex Questions: Answer-Based Claim Decomposition for Fine-grained Self-Evaluation
AUTHORS: Nishant Balepur ; Jie Huang ; Samraj Moorjani ; Hari Sundaram ; Kevin Chen-Chuan Chang
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: While existing self-evaluation techniques aim to detect if such answers are correct, these techniques are unable to determine which criteria of the question are satisfied by the generated answers. To address this issue, we propose answer-based claim decomposition (ABCD), a prompting strategy that decomposes questions into a series of true/false claims that can be used to verify which criteria of the input question an answer satisfies.

188, TITLE: Advancing Topic Segmentation and Outline Generation in Chinese Texts: The Paragraph-level Topic Representation, Corpus, and Benchmark
AUTHORS: FENG JIANG et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: However, research and applications in this field have been restrained due to the lack of proper paragraph-level topic representations and large-scale, high-quality corpora in Chinese compared to the success achieved in English. Addressing these issues, we introduce a hierarchical paragraph-level topic structure representation with title, subheading, and paragraph that comprehensively models the document discourse topic structure.

189, TITLE: Reasoning with Language Model Is Planning with World Model
AUTHORS: SHIBO HAO et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: To overcome the limitations, we propose a new LLM reasoning framework, $\underline{R}\textit{easoning vi}\underline{a} \underline{P}\textit{lanning}$ $\textbf{(RAP)}$.

190, TITLE: Large Language Models As Counterfactual Generator: Strengths and Weaknesses
AUTHORS: Yongqi Li ; Mayi Xu ; Xin Miao ; Shen Zhou ; Tieyun Qian
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Yet, their ability to generate counterfactuals, which can be used for areas like data augmentation, remains under-explored. This study aims to investigate the counterfactual generation capabilities of LLMs and analysis factors that influence this ability.

191, TITLE: DialogVCS: Robust Natural Language Understanding in Dialogue System Upgrade
AUTHORS: ZEFAN CAI et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: We formulate the intent detection with imperfect data in the system update as a multi-label classification task with positive but unlabeled intents, which asks the models to recognize all the proper intents, including the ones with semantic entanglement, in the inference.

192, TITLE: Is Information Extraction Solved By ChatGPT? An Analysis of Performance, Evaluation Criteria, Robustness and Errors
AUTHORS: RIDONG HAN et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we assess the capabilities of ChatGPT from four perspectives including Performance, Evaluation Criteria, Robustness and Error Types.

193, TITLE: Cascaded Beam Search: Plug-and-Play Terminology-Forcing For Neural Machine Translation
AUTHORS: Frédéric Odermatt ; Béni Egressy ; Roger Wattenhofer
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: This paper presents a plug-and-play approach for translation with terminology constraints.

194, TITLE: The Art of SOCRATIC QUESTIONING: Zero-shot Multimodal Reasoning with Recursive Thinking and Self-Questioning
AUTHORS: JINGYUAN QI et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this work, we propose Socratic Questioning, a divide-and-conquer fashion algorithm that simulates the self-questioning and recursive thinking process.

195, TITLE: Measuring The Knowledge Acquisition-Utilization Gap in Pretrained Language Models
AUTHORS: Amirhossein Kazemnejad ; Mehdi Rezagholizadeh ; Prasanna Parthasarathi ; Sarath Chandar
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: We propose a systematic framework to measure parametric knowledge utilization in PLMs.

196, TITLE: An Examination of The Robustness of Reference-Free Image Captioning Evaluation Metrics
AUTHORS: Saba Ahmadi ; Aishwarya Agrawal
CATEGORY: cs.CL [cs.CL, cs.AI, cs.CV, cs.LG]
HIGHLIGHT: Recently, reference-free metrics such as CLIPScore (Hessel et al., 2021) and UMIC (Lee et al., 2021) have been proposed for automatic evaluation of image captions, demonstrating a high correlation with human judgment. In this work, our focus lies in evaluating the robustness of these metrics in scenarios that require distinguishing between two captions with high lexical overlap but very different meanings.

197, TITLE: How to Choose How to Choose Your Chatbot: A Massively Multi-System MultiReference Data Set for Dialog Metric Evaluation
AUTHORS: Huda Khayrallah ; Zuhaib Akhtar ; Edward Cohen ; Joăo Sedoc
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We release MMSMR, a Massively Multi-System MultiReference dataset to enable future work on metrics and evaluation for dialog.

198, TITLE: GRILL: Grounded Vision-language Pre-training Via Aligning Text and Image Regions
AUTHORS: WOOJEONG JIN et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we introduce GRILL, GRounded vIsion Language aLigning, a novel VL model that can be generalized to diverse tasks including visual question answering, captioning, and grounding tasks with no or very few training instances.

199, TITLE: Human-Centered Metrics for Dialog System Evaluation
AUTHORS: SALVATORE GIORGI et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We present metrics for evaluating dialog systems through a psychologically-grounded "human" lens: conversational agents express a diversity of both states (short-term factors like emotions) and traits (longer-term factors like personality) just as people do.

200, TITLE: Domain-Expanded ASTE: Rethinking Generalization in Aspect Sentiment Triplet Extraction
AUTHORS: YEW KEN CHIA et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Hence, we propose a domain-expanded benchmark to address the in-domain, out-of-domain and cross-domain settings.

201, TITLE: A Controllable QA-based Framework for Decontextualization
AUTHORS: Benjamin Newman ; Luca Soldaini ; Raymond Fok ; Arman Cohan ; Kyle Lo
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this work, we explore the limits of LLMs to perform decontextualization of document snippets in user-facing scenarios, focusing on two real-world settings - question answering and citation context previews for scientific documents.

202, TITLE: The ACL OCL Corpus: Advancing Open Science in Computational Linguistics
AUTHORS: Shaurya Rohatgi ; Yanxia Qin ; Benjamin Aw ; Niranjana Unnithan ; Min-Yen Kan
CATEGORY: cs.CL [cs.CL, cs.DL]
HIGHLIGHT: We present a scholarly corpus from the ACL Anthology to assist Open scientific research in the Computational Linguistics domain, named as ACL OCL.

203, TITLE: MathDial: A Dialogue Tutoring Dataset with Rich Pedagogical Properties Grounded in Math Reasoning Problems
AUTHORS: JAKUB MACINA et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: However, collecting such datasets remains challenging, as recording tutoring sessions raises privacy concerns and crowdsourcing leads to insufficient data quality. To address this problem, we propose a framework to semi-synthetically generate such dialogues by pairing real teachers with a large language model (LLM) scaffolded to represent common student errors.

204, TITLE: Don't Take This Out of Context! On The Need for Contextual Models and Evaluations for Stylistic Rewriting
AUTHORS: Akhila Yerukola ; Xuhui Zhou ; Maarten Sap
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this paper, we propose the integration of preceding textual context into both the rewriting and evaluation stages of stylistic text rewriting, focusing on formality, toxicity, and sentiment transfer tasks.

205, TITLE: Bi-Drop: Generalizable Fine-tuning for Pre-trained Language Models Via Adaptive Subnetwork Optimization
AUTHORS: SHOUJIE TONG et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this work, we propose a dynamic fine-tuning strategy for pretrained language models called Bi-Drop.

206, TITLE: Deduction Under Perturbed Evidence: Probing Student Simulation Capabilities of Large Language Models
AUTHORS: Shashank Sonkar ; Richard G. Baraniuk
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: However, in DUPE, LLMs must reason over manipulated or falsified evidence present in their prompts, which can result in false conclusions that are valid only under the manipulated evidence. Our goal with DUPE is to determine whether LLMs can arrive at these false conclusions and identify whether the dominant factor influencing the deduction process is the encoded data in the parameters or the manipulated evidence in the prompts.

207, TITLE: Detecting Propaganda Techniques in Code-Switched Social Media Text
AUTHORS: Muhammad Umar Salman ; Asif Hanif ; Shady Shehata ; Preslav Nakov
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: Code-switching combines different languages within the same text, which poses a challenge for automatic systems. With this in mind, here we propose the novel task of detecting propaganda techniques in code-switched text.

208, TITLE: Bridging Continuous and Discrete Spaces: Interpretable Sentence Representation Learning Via Compositional Operations
AUTHORS: JAMES Y. HUANG et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We propose InterSent, an end-to-end framework for learning interpretable sentence embeddings that supports compositional sentence operations in the embedding space.

209, TITLE: Attentiveness to Answer Choices Doesn't Always Entail High QA Accuracy
AUTHORS: Sarah Wiegreffe ; Matthew Finlayson ; Oyvind Tafjord ; Peter Clark ; Ashish Sabharwal
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: Does increasing attentiveness always improve task accuracy? We propose a mathematical formalism for studying this phenomenon, provide a metric for quantifying attentiveness, and identify a simple method for increasing it -- namely, in-context learning with even just one example containing answer choices.

210, TITLE: Voices of Her: Analyzing Gender Differences in The AI Publication World
AUTHORS: YIWEN DING et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: While several previous studies have analyzed gender bias in research, we are still missing a comprehensive analysis of gender differences in the AI community, covering diverse topics and different development trends. Using the AI Scholar dataset of 78K researchers in the field of AI, we identify several gender differences: (1) Although female researchers tend to have fewer overall citations than males, this citation difference does not hold for all academic-age groups; (2) There exist large gender homophily in co-authorship on AI papers; (3) Female first-authored papers show distinct linguistic styles, such as longer text, more positive emotion words, and more catchy titles than male first-authored papers.

211, TITLE: Dolphin: A Challenging and Diverse Benchmark for Arabic NLG
AUTHORS: El Moatez Billah Nagoudi ; Ahmed El-Shangiti ; AbdelRahim Elmadany ; Muhammad Abdul-Mageed
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We present Dolphin, a novel benchmark that addresses the need for an evaluation framework for the wide collection of Arabic languages and varieties.

212, TITLE: LLMs As Factual Reasoners: Insights from Existing Benchmarks and Beyond
AUTHORS: PHILIPPE LABAN et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: However, a closer analysis reveals that most LLMs fail on more complex formulations of the task and exposes issues with existing evaluation benchmarks, affecting evaluation precision. To address this, we propose a new protocol for inconsistency detection benchmark creation and implement it in a 10-domain benchmark called SummEdits.

213, TITLE: Prompt Optimization of Large Language Model for Interactive Tasks Without Gradient and Demonstrations
AUTHORS: Siqi Ouyang ; Lei Li
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Existing methods either rely on gradient access, which is often inaccessible in state-of-the-art LLMs like GPT-4, or necessitate diverse and high-quality in-context demonstrations. In this study, we propose LLM-PO, a novel approach that enables LLMs to address these tasks without gradient access or extensive demonstrations.

214, TITLE: Lawyer LLaMA Technical Report
AUTHORS: QUZHE HUANG et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this paper, we focus on the legal domain and explore how to inject domain knowledge during the continual training stage and how to design proper supervised finetune tasks to help the model tackle practical issues.

215, TITLE: Contextualized Topic Coherence Metrics
AUTHORS: HAMED RAHIMI et. al.
CATEGORY: cs.CL [cs.CL, cs.IR]
HIGHLIGHT: We propose LLM-based methods inspired by standard human topic evaluations, in a family of metrics called Contextualized Topic Coherence (CTC).

216, TITLE: Evaluating End-to-end Entity Linking on Domain-specific Knowledge Bases: Learning About Ancient Technologies from Museum Collections
AUTHORS: SEBASTIAN CADAVID-SANCHEZ et. al.
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: While recent advances in NLP provide many tools to efficiently process such data, most existing approaches rely on generic solutions whose performance and suitability for domain-specific tasks is not well understood. This work presents an attempt to bridge this domain gap by exploring the use of modern Entity Linking approaches for the enrichment of museum collection data.

217, TITLE: Benchmarking Arabic AI with Large Language Models
AUTHORS: AHMED ABDELALI et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, 68T50, F.2.2; I.2.7]
HIGHLIGHT: Given the importance of prompt for the FMs performance, we discuss our prompt strategies in detail and elaborate on our findings.

218, TITLE: ToMChallenges: A Principle-Guided Dataset and Diverse Evaluation Tasks for Exploring Theory of Mind
AUTHORS: Xiaomeng Ma ; Lingyu Gao ; Qihui Xu
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this study, We present ToMChallenges, a dataset for comprehensively evaluating Theory of Mind based on Sally-Anne and Smarties tests.

219, TITLE: Not All Metrics Are Guilty: Improving NLG Evaluation with LLM Paraphrasing
AUTHORS: TIANYI TANG et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: The underlying reason is that one semantic meaning can actually be expressed in different forms, and the evaluation with a single or few references may not accurately reflect the quality of the model's hypotheses. To address this issue, this paper presents a novel method, named Para-Ref, to enhance existing evaluation benchmarks by enriching the number of references.

220, TITLE: Improving Factuality of Abstractive Summarization Without Sacrificing Summary Quality
AUTHORS: Tanay Dixit ; Fei Wang ; Muhao Chen
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: We propose EFACTSUM (i.e., Effective Factual Summarization), a candidate summary generation and ranking technique to improve summary factuality without sacrificing summary quality.

221, TITLE: Inference-Time Policy Adapters (IPA): Tailoring Extreme-Scale LMs Without Fine-tuning
AUTHORS: XIMING LU et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We propose Inference-time Policy Adapters (IPA), which efficiently tailors a language model such as GPT-3 without fine-tuning it.

222, TITLE: Who Wrote This Code? Watermarking for Code Generation
AUTHORS: TAEHYUN LEE et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Hence, in this work, we propose a new watermarking method, SWEET, that significantly improves upon previous approaches when watermarking machine-generated code.

223, TITLE: Large Language Models Are Effective Table-to-Text Generators, Evaluators, and Feedback Providers
AUTHORS: YILUN ZHAO et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we study the capabilities of LLMs for table-to-text generation tasks, particularly aiming to investigate their performance in generating natural language statements that can be logically entailed by a provided table.

224, TITLE: Ranger: A Toolkit for Effect-Size Based Multi-Task Evaluation
AUTHORS: Mete Sertkan ; Sophia Althammer ; Sebastian Hofstätter
CATEGORY: cs.CL [cs.CL, cs.IR]
HIGHLIGHT: In this paper, we introduce Ranger - a toolkit to facilitate the easy use of effect-size-based meta-analysis for multi-task evaluation in NLP and IR.

225, TITLE: Ghostbuster: Detecting Text Ghostwritten By Large Language Models
AUTHORS: Vivek Verma ; Eve Fleisig ; Nicholas Tomlin ; Dan Klein
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: We introduce Ghostbuster, a state-of-the-art system for detecting AI-generated text.

226, TITLE: RE$^2$: Region-Aware Relation Extraction from Visually Rich Documents
AUTHORS: Pritika Ramu ; Sijia Wang ; Lalla Mouatadid ; Joy Rimchala ; Lifu Huang
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this paper, we propose REgion-Aware Relation Extraction (RE$^2$) that leverages region-level spatial structure among the entity blocks to improve their relation prediction.

227, TITLE: ALGO: Synthesizing Algorithmic Programs with Generated Oracle Verifiers
AUTHORS: Kexun Zhang ; Danqing Wang ; Jingtao Xia ; William Yang Wang ; Lei Li
CATEGORY: cs.CL [cs.CL, cs.SE]
HIGHLIGHT: Moreover, LLM-generated programs lack guaranteed correctness and require human verification. To address these challenges, we propose ALGO, a framework that synthesizes Algorithmic programs with LLM-Generated Oracles to guide the creation and verify their correctness.

228, TITLE: Instruction Tuning with Lexicons for Zero-Shot Style Classification
AUTHORS: Ruohao Guo ; Wei Xu ; Alan Ritter
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: In this study, we investigate the effectiveness of style lexicons as a means for instructing language models how to identify new styles that are unseen during training.

229, TITLE: Parameter-Efficient Language Model Tuning with Active Learning in Low-Resource Settings
AUTHORS: Josip Juki? ; Jan ?najder
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In our study, we empirically investigate PEFT behavior with AL in low-resource settings for text classification tasks.

230, TITLE: Detecting and Mitigating Indirect Stereotypes in Word Embeddings
AUTHORS: Erin George ; Joyce Chew ; Deanna Needell
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: In this paper, we propose a novel method called Biased Indirect Relationship Modification (BIRM) to mitigate indirect bias in distributional word embeddings by modifying biased relationships between words before embeddings are learned.

231, TITLE: Decomposing Complex Queries for Tip-of-the-tongue Retrieval
AUTHORS: Kevin Lin ; Kyle Lo ; Joseph E. Gonzalez ; Dan Klein
CATEGORY: cs.CL [cs.CL, cs.IR]
HIGHLIGHT: This retrieval setting, called tip of the tongue (TOT), is especially challenging for models heavily reliant on lexical and semantic overlap between query and document text. In this work, we introduce a simple yet effective framework for handling such complex queries by decomposing the query into individual clues, routing those as sub-queries to specialized retrievers, and ensembling the results.

232, TITLE: RetICL: Sequential Retrieval of In-Context Examples with Reinforcement Learning
AUTHORS: Alexander Scarlatos ; Andrew Lan
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: In this work, we propose Retrieval for In-Context Learning (RetICL), a learnable method for modeling and optimally selecting examples sequentially for in-context learning.

233, TITLE: Enhancing Retrieval-Augmented Large Language Models with Iterative Retrieval-Generation Synergy
AUTHORS: ZHIHONG SHAO et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we show that strong performance can be achieved by a method we call Iter-RetGen, which synergizes retrieval and generation in an iterative manner.

234, TITLE: MuLER: Detailed and Scalable Reference-based Evaluation
AUTHORS: Taelin Karidi ; Leshem Choshen ; Gal Patel ; Omri Abend
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: We propose a novel methodology (namely, MuLER) that transforms any reference-based evaluation metric for text generation, such as machine translation (MT) into a fine-grained analysis tool.

235, TITLE: A Monte Carlo Language Model Pipeline for Zero-Shot Sociopolitical Event Extraction
AUTHORS: Erica Cai ; Brendan O'Connor
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Straightforward application of large language model prompting typically performs even worse. We address these challenges with a new fine-grained, multi-stage generative question-answer method, using a Monte Carlo approach to exploit and overcome the randomness of generative outputs.

236, TITLE: Trusting Your Evidence: Hallucinate Less with Context-aware Decoding
AUTHORS: WEIJIA SHI et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Language models (LMs) often struggle to pay enough attention to the input context, and generate texts that are unfaithful or contain hallucinations. To mitigate this issue, we present context-aware decoding (CAD), which follows a contrastive output distribution that amplifies the difference between the output probabilities when a model is used with and without context.

237, TITLE: Learning The String Partial Order
AUTHORS: Tianyu Liu ; Afra Amini ; Mrinmaya Sachan ; Ryan Cotterell
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We show that most structured prediction problems can be solved in linear time and space by considering them as partial orderings of the tokens in the input string.

238, TITLE: Connecting The Dots: What Graph-Based Text Representations Work Best for Text Classification Using Graph Neural Networks?
AUTHORS: Margarita Bugueńo ; Gerard de Melo
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: This work presents an extensive empirical investigation of graph-based text representation methods proposed for text classification, identifying practical implications and open challenges in the field.

239, TITLE: Evaluating OpenAI's Whisper ASR for Punctuation Prediction and Topic Modeling of Life Histories of The Museum of The Person
AUTHORS: LUCAS RAFAEL STEFANEL GRIS et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: This chapter presents the first study on the performance of Whisper for punctuation prediction in the Portuguese language.

240, TITLE: Making The Implicit Explicit: Implicit Content As A First Class Citizen in NLP
AUTHORS: Alexander Hoyle ; Rupak Sarkar ; Pranav Goel ; Philip Resnik
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this work, we represent language with language, and direct an LLM to decompose utterances into logical and plausible inferences.

241, TITLE: Reasoning Over Hierarchical Question Decomposition Tree for Explainable Question Answering
AUTHORS: JIAJIE ZHANG et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we propose to leverage question decomposing for heterogeneous knowledge integration, by breaking down a complex question into simpler ones, and selecting the appropriate knowledge source for each sub-question.

242, TITLE: OverPrompt: Enhancing ChatGPT Capabilities Through An Efficient In-Context Learning Approach
AUTHORS: Jiazheng Li ; Runcong Zhao ; Yulan He ; Lin Gui
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: This paper proposes OverPrompt, an in-context learning method aimed at improving LLM efficiency and performance by processing multiple inputs in parallel.

243, TITLE: Understanding Arithmetic Reasoning in Language Models Using Causal Mediation Analysis
AUTHORS: Alessandro Stolfo ; Yonatan Belinkov ; Mrinmaya Sachan
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: In this paper, we present a mechanistic interpretation of LLMs for arithmetic-based questions using a causal mediation analysis framework.

244, TITLE: Getting Sick After Seeing A Doctor? Diagnosing and Mitigating Knowledge Conflicts in Event Temporal Reasoning
AUTHORS: TIANQING FANG et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: We first systematically define distinct kinds of bias in event temporal reasoning, which include event relation prior bias, tense bias, narrative bias, and dependency bias, as indicators to study knowledge conflicts. To mitigate such event-related knowledge conflict, we introduce a Counterfactual Data Augmentation based method that can be applied to both Pre-trained Language Models (PLMs) and Large Language Models (LLMs) either as additional training data or demonstrations for In-Context Learning.

245, TITLE: Is GPT-4 A Good Data Analyst?
AUTHORS: Liying Cheng ; Xingxuan Li ; Lidong Bing
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: in this work and aim to answer it by conducting head-to-head comparative studies.

246, TITLE: PEARL: Prompting Large Language Models to Plan and Execute Actions Over Long Documents
AUTHORS: Simeng Sun ; Yang Liu ; Shuohang Wang ; Chenguang Zhu ; Mohit Iyyer
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this work, we propose PEARL, a prompting framework to improve reasoning over long documents, which consists of three stages: action mining, plan formulation, and plan execution.

247, TITLE: Few-shot Unified Question Answering: Tuning Models or Prompts?
AUTHORS: Srijan Bansal ; Semih Yavuz ; Bo Pang ; Meghana Bhat ; Yingbo Zhou
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: The paper provides an exhaustive analysis of their applicability using 16 QA datasets, revealing that prompt tuning can perform as well as model tuning in a few-shot setting with a good initialization.

248, TITLE: From Characters to Words: Hierarchical Pre-trained Language Model for Open-vocabulary Language Understanding
AUTHORS: Li Sun ; Florian Luisier ; Kayhan Batmanghelich ; Dinei Florencio ; Cha Zhang
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this work, we introduce a novel open-vocabulary language model that adopts a hierarchical two-level approach: one at the word level and another at the sequence level.

249, TITLE: Generating Faithful Synthetic Data with Large Language Models: A Case Study in Computational Social Science
AUTHORS: VENIAMIN VESELOVSKY et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Large Language Models (LLMs) have democratized synthetic data generation, which in turn has the potential to simplify and broaden a wide gamut of NLP tasks. Here, we tackle a pervasive problem in synthetic data generation: its generative distribution often differs from the distribution of real-world data researchers care about (in other words, it is unfaithful).

250, TITLE: A Simple and Effective Framework for Strict Zero-Shot Hierarchical Classification
AUTHORS: Rohan Bhambhoria ; Lei Chen ; Xiaodan Zhu
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: However, these benchmarks often do not adequately address the challenges posed in the real-world, such as that of hierarchical classification. In order to address this challenge, we propose refactoring conventional tasks on hierarchical datasets into a more indicative long-tail prediction task.

251, TITLE: Active Learning for Natural Language Generation
AUTHORS: YOTAM PERLITZ et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we present a first systematic study of active learning for text generation, considering a diverse set of tasks and multiple leading AL strategies.

252, TITLE: All Roads Lead to Rome? Exploring The Invariance of Transformers' Representations
AUTHORS: YUXIN REN et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: In this work, we formulate the Bijection Hypothesis, which suggests the use of bijective methods to align different models' representation spaces.

253, TITLE: Debiasing Made State-of-the-art: Revisiting The Simple Seed-based Weak Supervision for Text Classification
AUTHORS: Chengyu Dong ; Zihan Wang ; Jingbo Shang
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: Recent advances in weakly supervised text classification mostly focus on designing sophisticated methods to turn high-level human heuristics into quality pseudo-labels. In this paper, we revisit the seed matching-based method, which is arguably the simplest way to generate pseudo-labels, and show that its power was greatly underestimated.

254, TITLE: Sources of Hallucination By Large Language Models on Inference Tasks
AUTHORS: NICK MCKENNA et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: We present a series of behavioral studies on several LLM families (LLaMA, GPT-3.5, and PaLM) which probe their behavior using controlled experiments. We establish two factors which predict much of their performance, and propose that these are major sources of hallucination in generative LLM.

255, TITLE: MQuAKE: Assessing Knowledge Editing in Language Models Via Multi-Hop Questions
AUTHORS: Zexuan Zhong ; Zhengxuan Wu ; Christopher D. Manning ; Christopher Potts ; Danqi Chen
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this work, we present a benchmark MQuAKE (Multi-hop Question Answering for Knowledge Editing) comprising multi-hop questions that assess whether edited models correctly answer questions where the answer should change as an entailed consequence of edited facts.

256, TITLE: SETI: Systematicity Evaluation of Textual Inference
AUTHORS: Xiyan Fu ; Anette Frank
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We propose SETI (Systematicity Evaluation of Textual Inference), a novel and comprehensive benchmark designed for evaluating pre-trained language models (PLMs) for their systematicity capabilities in the domain of textual inference.

257, TITLE: Is Summary Useful or Not? An Extrinsic Human Evaluation of Text Summaries on Downstream Tasks
AUTHORS: Xiao Pu ; Mingqi Gao ; Xiaojun Wan
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We carefully design three different downstream tasks for extrinsic human evaluation of summaries, i.e., question answering, text classification and text similarity assessment.

258, TITLE: Unit-based Speech-to-Speech Translation Without Parallel Data
AUTHORS: Anuj Diwan ; Anirudh Srinivasan ; David Harwath ; Eunsol Choi
CATEGORY: cs.CL [cs.CL, eess.AS]
HIGHLIGHT: We propose an unsupervised speech-to-speech translation (S2ST) system that does not rely on parallel data between the source and target languages.

259, TITLE: Unraveling ChatGPT: A Critical Analysis of AI-Generated Goal-Oriented Dialogues and Annotations
AUTHORS: Tiziano Labruna ; Sofia Brenna ; Andrea Zaninello ; Bernardo Magnini
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: This fact introduces new possibilities for data collection and annotation, particularly in situations where such data is scarce, complex to gather, expensive, or even sensitive. In this paper, we explore the potential of these models to generate and annotate goal-oriented dialogues, and conduct an in-depth analysis to evaluate their quality.

260, TITLE: AV-TranSpeech: Audio-Visual Robust Speech-to-Speech Translation
AUTHORS: RONGJIE HUANG et. al.
CATEGORY: cs.CL [cs.CL, cs.SD, eess.AS]
HIGHLIGHT: In this work, we present AV-TranSpeech, the first audio-visual speech-to-speech (AV-S2ST) translation model without relying on intermediate text.

261, TITLE: ImageNetVC: Zero-Shot Visual Commonsense Evaluation on 1000 ImageNet Categories
AUTHORS: HEMING XIA et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.CV]
HIGHLIGHT: However, it remains unclear how well current PLMs and their visually augmented counterparts (VaLMs) can master visual commonsense knowledge. To investigate this, we propose ImageNetVC, a fine-grained, human-annotated dataset specifically designed for zero-shot visual commonsense evaluation across 1,000 ImageNet categories.

262, TITLE: Testing The General Deductive Reasoning Capacity of Large Language Models Using OOD Examples
AUTHORS: ABULHAIR SAPAROV et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: Given the intractably large size of the space of proofs, any model that is capable of general deductive reasoning must generalize to proofs of greater complexity.

263, TITLE: EvEval: A Comprehensive Evaluation of Event Semantics for Large Language Models
AUTHORS: ZHENGWEI TAO et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this paper, we propose an overarching framework for event semantic processing, encompassing understanding, reasoning, and prediction, along with their fine-grained aspects.

264, TITLE: Dior-CVAE: Diffusion Priors in Variational Dialog Generation
AUTHORS: Tianyu Yang ; Thy Thy Tran ; Iryna Gurevych
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We propose, Dior-CVAE, a hierarchical CVAE model with an informative prior produced by a diffusion model.

265, TITLE: Revisiting Token Dropping Strategy in Efficient BERT Pretraining
AUTHORS: QIHUANG ZHONG et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: However, we empirically find that token dropping is prone to a semantic loss problem and falls short in handling semantic-intense tasks. Motivated by this, we propose a simple yet effective semantic-consistent learning method (ScTD) to improve the token dropping.

266, TITLE: ChatGPT and Simple Linguistic Inferences: Blind Spots and Blinds
AUTHORS: Victoria Basmov ; Yoav Goldberg ; Reut Tsarfaty
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: Specifically, we target (i) grammatically-specified entailments, (ii) premises with evidential adverbs of uncertainty, and (iii) monotonicity entailments. We present expert-designed evaluation sets for these inference types and conduct experiments in a zero-shot setup.

267, TITLE: Disentangled Phonetic Representation for Chinese Spelling Correction
AUTHORS: Zihong Liang ; Xiaojun Quan ; Qifan Wang
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this work, we propose to disentangle the two types of features to allow for direct interaction between textual and phonetic information.

268, TITLE: Self-ICL: Zero-Shot In-Context Learning with Self-Generated Demonstrations
AUTHORS: Wei-Lin Chen ; Cheng-Kuang Wu ; Hsin-Hsi Chen
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Inspired by evidence suggesting LMs' zero-shot capabilities are underrated, and the role of demonstrations are primarily for exposing models' intrinsic functionalities, we introduce Self-ICL, a simple framework for zero-shot ICL.

269, TITLE: Self-Evolution Learning for Discriminative Language Model Pretraining
AUTHORS: Qihuang Zhong ; Liang Ding ; Juhua Liu ; Bo Du ; Dacheng Tao
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we present Self-Evolution learning (SE), a simple and effective token masking and learning method to fully and wisely exploit the knowledge from data.

270, TITLE: SmartTrim: Adaptive Tokens and Parameters Pruning for Efficient Vision-Language Models
AUTHORS: Zekun Wang ; Jingchang Chen ; Wangchunshu Zhou ; Ming Liu ; Bing Qin
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this work, we propose an adaptive acceleration method SmartTrim for VLMs, which adjusts the inference overhead based on the complexity of instances.

271, TITLE: Interpretable Automatic Fine-grained Inconsistency Detection in Text Summarization
AUTHORS: Hou Pong Chan ; Qi Zeng ; Heng Ji
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Motivated by how humans inspect factual inconsistency in summaries, we propose an interpretable fine-grained inconsistency detection model, FineGrainFact, which explicitly represents the facts in the documents and summaries with semantic frames extracted by semantic role labeling, and highlights the related semantic frames to predict inconsistency.

272, TITLE: Adapting Language Models to Compress Contexts
AUTHORS: Alexis Chevalier ; Alexander Wettig ; Anirudh Ajith ; Danqi Chen
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We propose to adapt pre-trained LMs into AutoCompressors.

273, TITLE: Faithful Low-Resource Data-to-Text Generation Through Cycle Training
AUTHORS: ZHUOER WANG et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Since the problem is fundamentally one of consistency between the representations of the structured data and text, we evaluate the effectiveness of cycle training in this work.

274, TITLE: Unprovability of Strong Complexity Lower Bounds in Bounded Arithmetic
AUTHORS: Jiatu Li ; Igor Carboni Oliveira
CATEGORY: cs.CC [cs.CC, cs.LO, F.0]
HIGHLIGHT: In this work, we establish unprovability results for stronger theories and for sentences of higher quantifier complexity.

275, TITLE: Polynomial-Time Pseudodeterministic Construction of Primes
AUTHORS: Lijie Chen ; Zhenjian Lu ; Igor C. Oliveira ; Hanlin Ren ; Rahul Santhanam
CATEGORY: cs.CC [cs.CC, cs.DM, cs.DS]
HIGHLIGHT: In their seminal work on the topic, Gat and Goldwasser posed as their main open problem whether prime numbers can be pseudodeterministically constructed in polynomial time. We provide a positive solution to this question in the infinitely-often regime.

276, TITLE: GTNet: Graph Transformer Network for 3D Point Cloud Classification and Semantic Segmentation
AUTHORS: WEI ZHOU et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Most Transformer-based methods extract point cloud features based on global attention and lack the feature learning on local neighbors. To solve the problems of these two types of models, we propose a new feature extraction block named Graph Transformer and construct a 3D point point cloud learning network called GTNet to learn features of point clouds on local and global patterns.

277, TITLE: DynStatF: An Efficient Feature Fusion Strategy for LiDAR 3D Object Detection
AUTHORS: Yao Rong ; Xiangyu Wei ; Tianwei Lin ; Yueyu Wang ; Enkelejda Kasneci
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this work, we propose a novel feature fusion strategy, DynStaF (Dynamic-Static Fusion), which enhances the rich semantic information provided by the multi-frame (dynamic branch) with the accurate location information from the current single-frame (static branch).

278, TITLE: L-CAD: Language-based Colorization with Any-level Descriptions
AUTHORS: ZHENG CHANG et. al.
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: In this paper, we propose a unified model to perform language-based colorization with any-level descriptions.

279, TITLE: Exploring Diverse In-Context Configurations for Image Captioning
AUTHORS: Xu Yang ; Yongliang Wu ; Mingzhuo Yang ; Haokun Chen
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In order to explore the effects of varying configurations on VL in-context learning, we devised four strategies for image selection and four for caption assignment to configure in-context image-text pairs for image captioning.

280, TITLE: Computer Vision for Construction Progress Monitoring: A Real-Time Object Detection Approach
AUTHORS: Jiesheng Yang ; Andreas Wilde ; Karsten Menzel ; Md Zubair Sheikh ; Boris Kuznetsov
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: This paper proposes a novel approach for automated CPM using state-of-the-art object detection algorithms.

281, TITLE: InpaintNeRF360: Text-Guided 3D Inpainting on Unbounded Neural Radiance Fields
AUTHORS: Dongqing Wang ; Tong Zhang ; Alaa Abboud ; Sabine Süsstrunk
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we propose InpaintNeRF360, a unified framework that utilizes natural language instructions as guidance for inpainting NeRF-based 3D scenes.Our approach employs a promptable segmentation model by generating multi-modal prompts from the encoded text for multiview segmentation.

282, TITLE: Modeling Complex Object Changes in Satellite Image Time-Series: Approach Based on CSP and Spatiotemporal Graph
AUTHORS: Zouhayra Ayadi ; Wadii Boulila ; Imed Riadh Farah
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: This paper proposes a method for automatically monitoring and analyzing the evolution of complex geographic objects.

283, TITLE: Unpaired Image-to-Image Translation Via Neural Schrödinger Bridge
AUTHORS: Beomsu Kim ; Gihyun Kwon ; Kwanyoung Kim ; Jong Chul Ye
CATEGORY: cs.CV [cs.CV, cs.AI, cs.LG, stat.ML]
HIGHLIGHT: In this work, we propose the Unpaired Neural Schr\"odinger Bridge (UNSB), which combines SB with adversarial training and regularization to learn a SB between unpaired data.

284, TITLE: Audio-Visual Dataset and Method for Anomaly Detection in Traffic Videos
AUTHORS: B?A?EJ LEPOROWSKI et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We introduce the first audio-visual dataset for traffic anomaly detection taken from real-world scenes, called MAVAD, with a diverse range of weather and illumination conditions.

285, TITLE: PathAsst: Redefining Pathology Through Generative Foundation AI Assistant for Pathology
AUTHORS: YUXUAN SUN et. al.
CATEGORY: cs.CV [cs.CV, cs.MM]
HIGHLIGHT: To bridge the gap in pathology MLLMs, we present the PathAsst in this study, which is a generative foundation AI assistant to revolutionize diagnostic and predictive analytics in pathology.

286, TITLE: Learning INR for Event-guided Rolling Shutter Frame Correction, Deblur, and Interpolation
AUTHORS: Yunfan Lu ; Guoqiang Liang ; Lin Wang
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Our key idea is to learn an implicit neural representation (INR) to directly map the position and time coordinates to RGB values to address the interlocking degradations in the image restoration process.

287, TITLE: Towards View-invariant and Accurate Loop Detection Based on Scene Graph
AUTHORS: Chuhao Liu ; Shaojie Shen
CATEGORY: cs.CV [cs.CV, cs.RO]
HIGHLIGHT: This paper introduces a novel loop detection method based on an incrementally created scene graph, targeting the visual SLAM at indoor scenes.

288, TITLE: Optimal Linear Subspace Search: Learning to Construct Fast and High-Quality Schedulers for Diffusion Models
AUTHORS: Zhongjie Duan ; Chengyu Wang ; Cen Chen ; Jun Huang ; Weining Qian
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We transform the designing problem of schedulers into the determination of several parameters, and further transform the accelerated generation process into an expansion process of the linear subspace. Based on these analyses, we consequently propose a novel method called Optimal Linear Subspace Search (OLSS), which accelerates the generation process by searching for the optimal approximation process of the complete generation process in the linear subspaces spanned by latent variables.

289, TITLE: Prompting Language-Informed Distribution for Compositional Zero-Shot Learning
AUTHORS: Wentao Bao ; Lichang Chen ; Heng Huang ; Yu Kong
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we propose a model by prompting the language-informed distribution, aka., PLID, for the CZSL task.

290, TITLE: HARD: Hard Augmentations for Robust Distillation
AUTHORS: Arne F. Nix ; Max F. Burg ; Fabian H. Sinz
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: However, current KD has a few shortcomings: it has recently been shown that this method is unsuitable to transfer simple inductive biases like shift equivariance, struggles to transfer out of domain generalization, and optimization time is magnitudes longer compared to default non-KD model training. To improve these aspects of KD, we propose Hard Augmentations for Robust Distillation (HARD), a generally applicable data augmentation framework, that generates synthetic data points for which the teacher and the student disagree.

291, TITLE: Reinforcement Learning Finetuned Vision-Code Transformer for UI-to-Code Generation
AUTHORS: Davit Soselia ; Khalid Saifullah ; Tianyi Zhou
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: In this paper, we present a novel vision-code transformer approach that leverages an Encoder-Decoder architecture as well as explore actor-critic fine-tuning as a method for improving upon the baseline.

292, TITLE: Robust 3D-aware Object Classification Via Discriminative Render-and-Compare
AUTHORS: Artur Jesslen ; Guofeng Zhang ; Angtian Wang ; Alan Yuille ; Adam Kortylewski
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Our main contribution is a novel architecture for 3D-aware classification, which builds upon a recent work and performs comparably to single-task models while being highly robust.

293, TITLE: NegVSR: Augmenting Negatives for Generalized Noise Modeling in Real-World Video Super-Resolution
AUTHORS: YEXING SONG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: To address the aforementioned problems, we propose a Negatives augmentation strategy for generalized noise modeling in Video Super-Resolution (NegVSR) task.

294, TITLE: Multiresolution Feature Guidance Based Transformer for Anomaly Detection
AUTHORS: SHUTING YAN et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we propose a multiresolution feature guidance method based on Transformer named GTrans for unsupervised anomaly detection and localization.

295, TITLE: Sampling-based Uncertainty Estimation for An Instance Segmentation Network
AUTHORS: Florian Heidecker ; Ahmad El-Khateeb ; Bernhard Sick
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Therefore, clustering is required to describe the resulting uncertainty, but only through efficient clustering is it possible to describe the uncertainty from the model attached to each object. This article uses Bayesian Gaussian Mixture (BGM) to solve this problem.

296, TITLE: Realistically Distributing Object Placements in Synthetic Training Data Improves The Performance of Vision-based Object Detection Models
AUTHORS: SETAREH DABIRI et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We investigate specifically the impact of object placement distribution, keeping all other aspects of synthetic data fixed.

297, TITLE: MMNet: Multi-Mask Network for Referring Image Segmentation
AUTHORS: Yichen Yan ; Xingjian He ; Wenxuan Wan ; Jing Liu
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Most of previous work focus on improving cross-modal feature fusion while not fully addressing the inherent uncertainty caused by diverse objects and unrestricted language. To tackle these problems, we propose an end-to-end Multi-Mask Network for referring image segmentation(MMNet).

298, TITLE: ICDAR 2023 Competition on Robust Layout Segmentation in Corporate Documents
AUTHORS: CHRISTOPH AUER et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this report, we present the results of our \textit{ICDAR 2023 Competition on Robust Layout Segmentation in Corporate Documents}, which posed the challenge to accurately segment the page layout in a broad range of document styles and domains, including corporate reports, technical literature and patents.

299, TITLE: BLIP-Diffusion: Pre-trained Subject Representation for Controllable Text-to-Image Generation and Editing
AUTHORS: Dongxu Li ; Junnan Li ; Steven C. H. Hoi
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: Existing models suffer from lengthy fine-tuning and difficulties preserving the subject fidelity. To overcome these limitations, we introduce BLIP-Diffusion, a new subject-driven image generation model that supports multimodal control which consumes inputs of subject images and text prompts.

300, TITLE: Remote Sensing Image Change Detection Towards Continuous Bitemporal Resolution Differences
AUTHORS: HAO CHEN et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Concretely, we synthesize blurred versions of the HR image by random downsampled reconstructions to reduce the gap between HR and LR images. We introduce coordinate-based representations to decode per-pixel predictions by feeding the coordinate query and corresponding multi-level embedding features into an MLP that implicitly learns the shape of land cover changes, therefore benefiting recognizing blurred objects in the LR image.

301, TITLE: Deceptive-NeRF: Enhancing NeRF Reconstruction Using Pseudo-Observations from Diffusion Models
AUTHORS: Xinhang Liu ; Shiu-hong Kao ; Jiaben Chen ; Yu-Wing Tai ; Chi-Keung Tang
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: This paper introduces Deceptive-NeRF, a new method for enhancing the quality of reconstructed NeRF models using synthetically generated pseudo-observations, capable of handling sparse input and removing floater artifacts.

302, TITLE: Leveraging Future Relationship Reasoning for Vehicle Trajectory Prediction
AUTHORS: DAEHEE PARK et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we propose a novel approach that uses lane information to predict a stochastic future relationship among agents.

303, TITLE: Dual-Side Feature Fusion 3D Pose Transfer
AUTHORS: Jue Liu ; Feipeng Da
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this work, we propose a Dual-Side Feature Fusion Pose Transfer Network to improve the pose transfer accuracy of the lightweight method.

304, TITLE: DC-Net: Divide-and-Conquer for Salient Object Detection
AUTHORS: Jiayi Zhu ; Xuebin Qin ; Abdulmotaleb Elsaddik
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we introduce Divide-and-Conquer into the salient object detection (SOD) task to enable the model to learn prior knowledge that is for predicting the saliency map.

305, TITLE: Sin3DM: Learning A Diffusion Model from A Single 3D Textured Shape
AUTHORS: Rundi Wu ; Ruoshi Liu ; Carl Vondrick ; Changxi Zheng
CATEGORY: cs.CV [cs.CV, cs.AI, cs.GR]
HIGHLIGHT: In this paper, we present Sin3DM, a diffusion model that learns the internal patch distribution from a single 3D textured shape and generates high-quality variations with fine geometry and texture details.

306, TITLE: Streaming Object Detection on Fisheye Cameras for Automatic Parking
AUTHORS: Yixiong Yan ; Liangzhu Cheng ; Yongxu Li ; Xinjuan Tuo
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: In this paper, we propose a real-time detection framework equipped with a dual-flow perception module (dynamic and static flows) that can predict the future and alleviate the time-lag problem.

307, TITLE: Measuring Faithful and Plausible Visual Grounding in VQA
AUTHORS: Daniel Reich ; Felix Putze ; Tanja Schultz
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: To this end, we propose a new VG metric that captures if a model a) identifies question-relevant objects in the scene, and b) actually relies on the information contained in the relevant objects when producing its answer, i.e., if its visual grounding is both "faithful" and "plausible".

308, TITLE: Reliability Scores from Saliency Map Clusters for Improved Image-based Harvest-Readiness Prediction in Cauliflower
AUTHORS: Jana Kierdorf ; Ribana Roscher
CATEGORY: cs.CV [cs.CV, cs.AI, cs.LG]
HIGHLIGHT: In this paper, we analyze the reliability of a harvest-readiness classifier with interpretable machine learning.

309, TITLE: EgoVSR: Towards High-Quality Egocentric Video Super-Resolution
AUTHORS: Yichen Chi ; Junhao Gu ; Jiamiao Zhang ; Wenming Yang ; Yapeng Tian
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: To this end, we propose EgoVSR, a VSR framework specifically designed for egocentric videos.

310, TITLE: Cheap and Quick: Efficient Vision-Language Instruction Tuning for Large Language Models
AUTHORS: GEN LUO et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we propose a novel and affordable solution for the effective VL adaption of LLMs, called Mixture-of-Modality Adaptation (MMA).

311, TITLE: Delving Deeper Into Data Scaling in Masked Image Modeling
AUTHORS: CHENG-ZE LU et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this work, we conduct an empirical study on the scaling capability of masked image modeling (MIM) methods (e.g., MAE) for visual recognition.

312, TITLE: Point2SSM: Learning Morphological Variations of Anatomies from Point Cloud
AUTHORS: Jadie Adams ; Shireen Elhabian
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: We introduce Point2SSM, a novel unsupervised learning approach that can accurately construct correspondence-based statistical shape models (SSMs) of anatomy directly from point clouds.

313, TITLE: Robust Classification Via A Single Diffusion Model
AUTHORS: HUANRAN CHEN et. al.
CATEGORY: cs.CV [cs.CV, cs.CR, cs.LG]
HIGHLIGHT: To better harness the expressive power of diffusion models, in this paper we propose Robust Diffusion Classifier (RDC), a generative classifier that is constructed from a pre-trained diffusion model to be adversarially robust.

314, TITLE: Real Time Dense Anomaly Detection By Learning on Synthetic Negative Data
AUTHORS: Anja Deli? ; Matej Grci? ; Sini?a ?egvi?
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: We extend that work with a jointly trained generative flow that samples synthetic negatives at the border of the inlier distribution.

315, TITLE: GAMUS: A Geometry-aware Multi-modal Semantic Segmentation Benchmark for Remote Sensing Data
AUTHORS: Zhitong Xiong ; Sining Chen ; Yi Wang ; Lichao Mou ; Xiao Xiang Zhu
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Last, sophisticated multi-modal semantic segmentation methods have not been deeply explored for remote sensing data. To cope with these challenges, in this paper, we introduce a new remote-sensing benchmark dataset for multi-modal semantic segmentation based on RGB-Height (RGB-H) data.

316, TITLE: Incremental Dense Reconstruction from Monocular Video with Guided Sparse Feature Volume Fusion
AUTHORS: Xingxing Zuo ; Nan Yang ; Nathaniel Merrill ; Binbin Xu ; Stefan Leutenegger
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: This letter proposes a real-time feature volume-based dense reconstruction method that predicts TSDF (Truncated Signed Distance Function) values from a novel sparsified deep feature volume, which is able to achieve higher resolutions than previous feature volume-based methods, and is favorable in large-scale outdoor scenarios where the majority of voxels are empty.

317, TITLE: Optimization-Based Improvement of Face Image Quality Assessment Techniques
AUTHORS: ?iga Babnik ; Naser Damer ; Vitomir ?truc
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: While existing FIQA techniques are able to efficiently capture the differences between high and low quality images, they typically cannot fully distinguish between images of similar quality, leading to lower performance in many scenarios. To address this issue, we present in this paper a supervised quality-label optimization approach, aimed at improving the performance of existing FIQA techniques.

318, TITLE: Assessment of Anterior Cruciate Ligament Injury Risk Based on Human Key Points Detection Algorithm
AUTHORS: Ziyu Gong ; Xiong Zhao ; Chen Yang
CATEGORY: cs.CV [cs.CV, stat.AP]
HIGHLIGHT: This paper aims to detect the potential injury risk of the anterior cruciate ligament (ACL) by proposing an ACL potential injury risk assessment algorithm based on key points of the human body detected using computer vision technology.

319, TITLE: DuDGAN: Improving Class-Conditional GANs Via Dual-Diffusion
AUTHORS: Taesun Yeom ; Minhyeok Lee
CATEGORY: cs.CV [cs.CV, eess.IV]
HIGHLIGHT: While Diffusion-GAN has shown potential in generating realistic samples, it has a critical limitation in generating class-conditional samples. To overcome these limitations, we propose a novel approach for class-conditional image generation using GANs called DuDGAN, which incorporates a dual diffusion-based noise injection process.

320, TITLE: Introducing Competition to Boost The Transferability of Targeted Adversarial Examples Through Clean Feature Mixup
AUTHORS: Junyoung Byun ; Myung-Joon Kwon ; Seungju Cho ; Yoonji Kim ; Changick Kim
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: To enhance the transferability of targeted adversarial examples, we propose introducing competition into the optimization process.

321, TITLE: Predicting Token Impact Towards Efficient Vision Transformer
AUTHORS: Hong Wang ; Su Yang ; Xiaoke Huang ; Weishan Zhang
CATEGORY: cs.CV [cs.CV, I.5.1]
HIGHLIGHT: The token filter can be realized using a very simple network, where we utilize multi-layer perceptron.

322, TITLE: FaceFusion: Exploiting Full Spectrum of Multiple Datasets
AUTHORS: Chiyoung Song ; Dongjae Lee
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We present a novel training method, named FaceFusion.

323, TITLE: LayoutGPT: Compositional Visual Planning and Generation with Large Language Models
AUTHORS: WEIXI FENG et. al.
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: We propose LayoutGPT, a method to compose in-context visual demonstrations in style sheet language to enhance the visual planning skills of LLMs.

324, TITLE: NuScenes-QA: A Multi-modal Visual Question Answering Benchmark for Autonomous Driving Scenario
AUTHORS: Tianwen Qian ; Jingjing Chen ; Linhai Zhuo ; Yang Jiao ; Yu-Gang Jiang
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We introduce a novel visual question answering (VQA) task in the context of autonomous driving, aiming to answer natural language questions based on street-view clues.

325, TITLE: A Neural Space-Time Representation for Text-to-Image Personalization
AUTHORS: Yuval Alaluf ; Elad Richardson ; Gal Metzer ; Daniel Cohen-Or
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: This choice greatly affects the visual fidelity, downstream editability, and disk space needed to store the learned concept. In this paper, we explore a new text-conditioning space that is dependent on both the denoising process timestep (time) and the denoising U-Net layers (space) and showcase its compelling properties.

326, TITLE: Clinically Labeled Contrastive Learning for OCT Biomarker Classification
AUTHORS: Kiran Kokilepersaud ; Stephanie Trejo Corona ; Mohit Prabhushankar ; Ghassan AlRegib ; Charles Wykoff
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: This paper presents a novel positive and negative set selection strategy for contrastive learning of medical images based on labels that can be extracted from clinical data.

327, TITLE: OD-NeRF: Efficient Training of On-the-Fly Dynamic Neural Radiance Fields
AUTHORS: Zhiwen Yan ; Chen Li ; Gim Hee Lee
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In contrast, we propose OD-NeRF to efficiently train and render dynamic NeRFs on-the-fly which instead is capable of streaming the dynamic scene.

328, TITLE: On Correlated Knowledge Distillation for Monitoring Human Pose with Radios
AUTHORS: SHIVA RAJ POKHREL et. al.
CATEGORY: cs.CV [cs.CV, eess.SP]
HIGHLIGHT: In this work, we propose and develop a simple experimental testbed to study the feasibility of a novel idea by coupling radio frequency (RF) sensing technology with Correlated Knowledge Distillation (CKD) theory towards designing lightweight, near real-time and precise human pose monitoring systems.

329, TITLE: Semi-Supervised and Long-Tailed Object Detection with CascadeMatch
AUTHORS: Yuhang Zang ; Kaiyang Zhou ; Chen Huang ; Chen Change Loy
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We propose a novel pseudo-labeling-based detector called CascadeMatch.

330, TITLE: SAMScore: A Semantic Structural Similarity Metric for Image Translation Evaluation
AUTHORS: YUNXIANG LI et. al.
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: Traditional image-level similarity metrics are of limited use, since the semantics of an image are high-level, and not strongly governed by pixel-wise faithfulness to an original image. Towards filling this gap, we introduce SAMScore, a generic semantic structural similarity metric for evaluating the faithfulness of image translation models.

331, TITLE: What Can Generic Neural Networks Learn from A Child's Visual Experience?
AUTHORS: A. Emin Orhan ; Brenden M. Lake
CATEGORY: cs.CV [cs.CV, cs.LG, cs.NE, q-bio.NC]
HIGHLIGHT: Specifically, we train both embedding models and generative models on 200 hours of headcam video from a single child collected over two years.

332, TITLE: Networks Are Slacking Off: Understanding Generalization Problem in Image Deraining
AUTHORS: Jinjin Gu ; Xianzheng Ma ; Xiangtao Kong ; Yu Qiao ; Chao Dong
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Our research not only offers a valuable perspective and methodology for better understanding the generalization problem in low-level vision tasks, but also displays promising practical potential.

333, TITLE: Visual Programming for Text-to-Image Generation and Evaluation
AUTHORS: Jaemin Cho ; Abhay Zala ; Mohit Bansal
CATEGORY: cs.CV [cs.CV, cs.AI, cs.CL, cs.LG]
HIGHLIGHT: As large language models have demonstrated impressive performance in many domains, recent works have adopted language models (LMs) as controllers of visual modules for vision-and-language tasks.

334, TITLE: Thinking Twice: Clinical-Inspired Thyroid Ultrasound Lesion Detection Based on Feature Feedback
AUTHORS: Lingtao Wang ; Jianrui Ding ; Fenghe Tang ; Chunping Ning
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this study, we propose a novel detection network based on a feature feedback mechanism inspired by clinical diagnosis.

335, TITLE: FLAIR #2: Textural and Temporal Information for Semantic Segmentation from Multi-source Optical Imagery
AUTHORS: ANATOL GARIOUD et. al.
CATEGORY: cs.CV [cs.CV, cs.LG, eess.IV]
HIGHLIGHT: FLAIR #2: Textural and Temporal Information for Semantic Segmentation from Multi-source Optical Imagery

336, TITLE: Boundary Attention Mapping (BAM): Fine-grained Saliency Maps for Segmentation of Burn Injuries
AUTHORS: MAHLA ABDOLAHNEJAD et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we introduce a machine learning pipeline for assessing burn severities and segmenting the regions of skin that are affected by burn.

337, TITLE: Training on Thin Air: Improve Image Classification with Generated Data
AUTHORS: Yongchao Zhou ; Hshmat Sahak ; Jimmy Ba
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: In this paper, we present Diffusion Inversion, a simple yet effective method that leverages the pre-trained generative model, Stable Diffusion, to generate diverse, high-quality training data for image classification.

338, TITLE: Run Like A Girl! Sports-Related Gender Bias in Language and Vision
AUTHORS: Sophia Harrison ; Eleonora Gualdoni ; Gemma Boleda
CATEGORY: cs.CV [cs.CV, cs.CL]
HIGHLIGHT: We analyze gender bias in two Language and Vision datasets.

339, TITLE: A Tale of Two Features: Stable Diffusion Complements DINO for Zero-Shot Semantic Correspondence
AUTHORS: JUNYI ZHANG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this work, we exploit Stable Diffusion (SD) features for semantic and dense correspondence and discover that with simple post-processing, SD features can perform quantitatively similar to SOTA representations.

340, TITLE: DiffBlender: Scalable and Composable Multimodal Text-to-Image Diffusion Models
AUTHORS: Sungnyun Kim ; Junsoo Lee ; Kibeom Hong ; Daesik Kim ; Namhyuk Ahn
CATEGORY: cs.CV [cs.CV, cs.AI, cs.LG]
HIGHLIGHT: We thus design a multimodal text-to-image diffusion model, coined as DiffBlender, that achieves the aforementioned goal in a single model by training only a few small hypernetworks.

341, TITLE: Promoting Generalization in Cross-Dataset Remote Photoplethysmography
AUTHORS: Nathan Vance ; Jeremy Speth ; Benjamin Sporrer ; Patrick Flynn
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Through a 3-way cross dataset analysis we demonstrate a reduction in mean absolute error from over 13 beats per minute to below 3 beats per minute.

342, TITLE: Multi-Modal Mutual Attention and Iterative Interaction for Referring Image Segmentation
AUTHORS: Chang Liu ; Henghui Ding ; Yulun Zhang ; Xudong Jiang
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Thus, its output feature is dominated by vision information, which limits the model to comprehensively understand the multi-modal information, and brings uncertainty for the subsequent mask decoder to extract the output mask. To address this issue, we propose Multi-Modal Mutual Attention ($\mathrm{M^3Att}$) and Multi-Modal Mutual Decoder ($\mathrm{M^3Dec}$) that better fuse information from the two input modalities.

343, TITLE: Mitigating Biased Activation in Weakly-supervised Object Localization Via Counterfactual Learning
AUTHORS: FEIFEI SHAO et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we focus on an under-explored issue of biased activation in prior weakly-supervised object localization methods based on Class Activation Mapping (CAM).

344, TITLE: Slovo: Russian Sign Language Dataset
AUTHORS: Alexander Kapitanov ; Karina Kvanchiani ; Alexander Nagaev ; Elizaveta Petrova
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: This paper presents the Russian Sign Language (RSL) video dataset Slovo, produced using crowdsourcing platforms.

345, TITLE: Sorted Convolutional Network for Achieving Continuous Rotational Invariance
AUTHORS: Hanlin Mo ; Guoying Zhao
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this letter, we propose a Sorting Convolution (SC) inspired by some hand-crafted features of texture images, which achieves continuous rotational invariance without requiring additional learnable parameters or data augmentation.

346, TITLE: Dual Path Transformer with Partition Attention
AUTHORS: ZHENGKAI JIANG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: This paper introduces a novel attention mechanism, called dual attention, which is both efficient and effective.

347, TITLE: Collaborative Auto-encoding for Blind Image Quality Assessment
AUTHORS: Zehong Zhou ; Fei Zhou ; Guoping Qiu
CATEGORY: cs.CV [cs.CV, eess.IV]
HIGHLIGHT: Recent efforts attempting to exploit powerful representations by deep neural networks (DNN) are hindered by the lack of subjectively annotated data. This paper presents a novel BIQA method which overcomes this fundamental obstacle.

348, TITLE: MRN: Multiplexed Routing Network for Incremental Multilingual Text Recognition
AUTHORS: Tianlun Zheng ; Zhineng Chen ; BingChen Huang ; Wei Zhang ; Yu-Gang Jiang
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we introduce the Incremental Multilingual Text Recognition (IMLTR) task in the incremental learning setting, where new language data comes in batches.

349, TITLE: Exploring Semantic Variations in GAN Latent Spaces Via Matrix Factorization
AUTHORS: Andrey Palaev ; Rustam A. Lukmanov ; Adil Khan
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: In this work, we explore image manipulations learned by GANSpace, a state-of-the-art method based on PCA.

350, TITLE: Label-Efficient Learning in Agriculture: A Comprehensive Review
AUTHORS: JIAJIA LI et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In fact, there are more than 50 papers on developing and applying deep-learning-based label-efficient techniques to address various agricultural problems since 2016, which motivates the authors to provide a timely and comprehensive review of recent label-efficient ML/DL methods in agricultural applications.

351, TITLE: SUVR: A Search-based Approach to Unsupervised Visual Representation Learning
AUTHORS: Yi-Zhan Xu ; Chih-Yao Chen ; Cheng-Te Li
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: In this work, we propose Search-based Unsupervised Visual Representation Learning (SUVR) to learn better image representations in an unsupervised manner.

352, TITLE: T1: Scaling Diffusion Probabilistic Fields to High-Resolution on Unified Visual Modalities
AUTHORS: Kangfu Mei ; Mo Zhou ; Vishal M. Patel
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: To this end, we propose a new model comprising of a view-wise sampling algorithm to focus on local structure learning, and incorporating additional guidance, e.g., text description, to complement the global geometry.

353, TITLE: Windscreen Optical Quality for AI Algorithms: Refractive Power and MTF Not Sufficient
AUTHORS: Dominik Werner Wolf ; Markus Ulrich ; Alexander Braun
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this article we demonstrate that the main metric established in the industry - refractive power - is fundamentally not capable of capturing relevant optical properties of windscreens.

354, TITLE: Text Conditional Alt-Text Generation for Twitter Images
AUTHORS: Nikita Srivatsan ; Sofia Samaniego ; Omar Florez ; Taylor Berg-Kirkpatrick
CATEGORY: cs.CV [cs.CV, cs.CL, cs.LG]
HIGHLIGHT: In this work we present an approach for generating alternative text (or alt-text) descriptions for images shared on social media, specifically Twitter.

355, TITLE: Generative Modeling Through The Semi-dual Formulation of Unbalanced Optimal Transport
AUTHORS: Jaemoo Choi ; Jaewoong Choi ; Myungjoo Kang
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: In this paper, we propose a novel generative model based on the semi-dual formulation of Unbalanced Optimal Transport (UOT).

356, TITLE: Vision + Language Applications: A Survey
AUTHORS: Yutong Zhou ; Nobutaka Shimada
CATEGORY: cs.CV [cs.CV, cs.MM]
HIGHLIGHT: This paper explores a relevant research track within multimodal applications, including text, vision, audio, and others.

357, TITLE: ChatFace: Chat-Guided Real Face Editing Via Diffusion Latent Space Manipulation
AUTHORS: DONGXU YUE et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: While GAN-based methods have showed potential in manipulating images especially when combined with CLIP, these methods are limited in their ability to reconstruct real images due to challenging GAN inversion capability. Despite the successful image reconstruction achieved by diffusion-based methods, there are still challenges in effectively manipulating fine-gained facial attributes with textual instructions.To address these issues and facilitate convenient manipulation of real facial images, we propose a novel approach that conduct text-driven image editing in the semantic latent space of diffusion model.

358, TITLE: IdealGPT: Iteratively Decomposing Vision and Language Reasoning Via Large Language Models
AUTHORS: HAOXUAN YOU et. al.
CATEGORY: cs.CV [cs.CV, cs.CL]
HIGHLIGHT: To achieve this goal, previous works resort to a divide-and-conquer pipeline. In this paper, we argue that previous efforts have several inherent shortcomings: 1) They rely on domain-specific sub-question decomposing models.

359, TITLE: Towards Early Prediction of Human IPSC Reprogramming Success
AUTHORS: ABHINEET SINGH et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: This paper presents advancements in automated early-stage prediction of the success of reprogramming human induced pluripotent stem cells (iPSCs) as a potential source for regenerative cell therapies.The minuscule success rate of iPSC-reprogramming of around $ 0.01% $ to $ 0.1% $ makes it labor-intensive, time-consuming, and exorbitantly expensive to generate a stable iPSC line.

360, TITLE: Real-Time Idling Vehicles Detection Using Combined Audio-Visual Deep Learning
AUTHORS: XIWEN LI et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper we present a real-time, dynamic vehicle idling detection algorithm.

361, TITLE: Scale Matters: Attribution Meets The Wavelet Domain to Explain Model Sensitivity to Image Corruptions
AUTHORS: Gabriel Kasmi ; Laurent Dubus ; Yves-Marie Saint Drenan ; Philippe Blanc
CATEGORY: cs.CV [cs.CV, cs.AI, stat.ML]
HIGHLIGHT: However, the ability to scrutinize models' behavior under image corruptions is crucial to increase the user's trust. Towards this end, we introduce the Wavelet sCale Attribution Method (WCAM), a generalization of attribution from the pixel domain to the space-scale domain.

362, TITLE: BinaryViT: Towards Efficient and Accurate Binary Vision Transformers
AUTHORS: Junrui Xiao ; Zhikai Li ; Lianwei Yang ; Qingyi Gu
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we first argue empirically that the severe performance degradation is mainly caused by the weight oscillation in the binarization training and the information distortion in the activation of ViTs. Based on these analyses, we propose $\textbf{BinaryViT}$, an accurate full binarization scheme for ViTs, which pushes the quantization of ViTs to the limit.

363, TITLE: AutoDepthNet: High Frame Rate Depth Map Reconstruction Using Commodity Depth and RGB Cameras
AUTHORS: Peyman Gholami ; Robert Xiao
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: We propose a fast and accurate depth map reconstruction technique to reduce latency and increase the frame rate in depth cameras.

364, TITLE: MultiFusion: Fusing Pre-Trained Models for Multi-Lingual, Multi-Modal Image Generation
AUTHORS: MARCO BELLAGENTE et. al.
CATEGORY: cs.CV [cs.CV, cs.AI, cs.LG]
HIGHLIGHT: To ease image generation, we propose MultiFusion that allows one to express complex and nuanced concepts with arbitrarily interleaved inputs of multiple modalities and languages.

365, TITLE: GO-LDA: Generalised Optimal Linear Discriminant Analysis
AUTHORS: Jiahui Liu ; Xiaohao Cai ; Mahesan Niranjan
CATEGORY: cs.CV [cs.CV, cs.NA, math.NA]
HIGHLIGHT: It is well known that the multiclass LDA is solved by an extension to the binary LDA, a generalised eigenvalue problem, from which the largest subspace that can be extracted is of dimension one lower than the number of classes in the given problem. In this paper, we show that, apart from the first of the discriminant directions, the generalised eigenanalysis solution to multiclass LDA does neither yield orthogonal discriminant directions nor maximise discrimination of projected data along them.

366, TITLE: High Speed Human Action Recognition Using A Photonic Reservoir Computer
AUTHORS: Enrico Picco ; Piotr Antonik ; Serge Massar
CATEGORY: cs.CV [cs.CV, cs.ET, physics.optics]
HIGHLIGHT: We introduce a new training method for the reservoir computer, based on "Timesteps Of Interest", which combines in a simple way short and long time scales.

367, TITLE: Balancing The Picture: Debiasing Vision-Language Datasets with Synthetic Contrast Sets
AUTHORS: BRANDON SMITH et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: This is problematic because commonly-used bias metrics (such as Bias@K) rely on per-gender base rates. To address this issue, we propose a novel dataset debiasing pipeline to augment the COCO dataset with synthetic, gender-balanced contrast sets, where only the gender of the subject is edited and the background is fixed.

368, TITLE: RoMa: Revisiting Robust Losses for Dense Feature Matching
AUTHORS: Johan Edstedt ; Qiyu Sun ; Georg Bökman ; Mĺrten Wadenbäck ; Michael Felsberg
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we revisit robust losses for matching from a Markov chain perspective, yielding theoretical insights and large gains in performance.

369, TITLE: Transferring Visual Attributes from Natural Language to Verified Image Generation
AUTHORS: RODRIGO VALERIO et. al.
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: In this paper, we propose to strengthen the consistency property of T2I methods in the presence of natural complex language, which often breaks the limits of T2I methods by including non-visual information, and textual elements that require knowledge for accurate generation.

370, TITLE: ViTMatte: Boosting Image Matting with Pretrained Plain Vision Transformers
AUTHORS: Jingfeng Yao ; Xinggang Wang ; Shusheng Yang ; Baoyuan Wang
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Our method utilizes (i) a hybrid attention mechanism combined with a convolution neck to help ViTs achieve an excellent performance-computation trade-off in matting tasks.

371, TITLE: Jointly Optimizing Image Compression with Low-light Image Enhancement
AUTHORS: Shilv Cai ; Xu Zou ; Liqun Chen ; Luxin Yan ; Sheng Zhong
CATEGORY: cs.CV [cs.CV, eess.IV]
HIGHLIGHT: To simultaneously achieve a higher compression rate and better enhancement performance for low-light images, we propose a novel image compression framework with joint optimization of low-light image enhancement.

372, TITLE: Reversible Graph Neural Network-based Reaction Distribution Learning for Multiple Appropriate Facial Reactions Generation
AUTHORS: TONG XU et. al.
CATEGORY: cs.CV [cs.CV, 68T40]
HIGHLIGHT: This paper proposes the first multiple appropriate facial reaction generation framework that re-formulates the one-to-many mapping facial reaction generation problem as a one-to-one mapping problem.

373, TITLE: Polarimetric Imaging for Perception
AUTHORS: Michael Baltaxe ; Tomer Pe'er ; Dan Levi
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this work we analyze the potential for improvement in perception tasks when using an RGB-polarimetric camera, as compared to an RGB camera.

374, TITLE: A Human-in-the-Loop Approach for Information Extraction from Privacy Policies Under Data Scarcity
AUTHORS: Michael Gebauer ; Faraz Mashhur ; Nicola Leschke ; Elias Grünewald ; Frank Pallas
CATEGORY: cs.CY [cs.CY, cs.AI]
HIGHLIGHT: In this work, we present a prototype system for a `Human-in-the-Loop' approach to privacy policy annotation that integrates ML-generated suggestions and ultimately human annotation decisions.

375, TITLE: Disincentivizing Polarization in Social Networks
AUTHORS: Christian Borgs ; Jennifer Chayes ; Christian Ikeokwu ; Ellen Vitercik
CATEGORY: cs.CY [cs.CY, cs.AI, cs.LG]
HIGHLIGHT: We present a model for content curation and personalization that avoids filter bubbles, along with algorithmic guarantees and nearly matching lower bounds.

376, TITLE: Science in The Era of ChatGPT, Large Language Models and AI: Challenges for Research Ethics Review and How to Respond
AUTHORS: Evangelos Pournaras
CATEGORY: cs.CY [cs.CY, cs.AI, cs.CL]
HIGHLIGHT: This paper reviews epistemological challenges, ethical and integrity risks in science conduct.

377, TITLE: Adversarial Machine Learning and Cybersecurity: Risks, Challenges, and Legal Implications
AUTHORS: MICAH MUSSER et. al.
CATEGORY: cs.CR [cs.CR, cs.AI, cs.CY]
HIGHLIGHT: Adversarial Machine Learning and Cybersecurity: Risks, Challenges, and Legal Implications

378, TITLE: Towards Foundation Models for Relational Databases [Vision Paper]
AUTHORS: Liane Vogel ; Benjamin Hilprecht ; Carsten Binnig
CATEGORY: cs.DB [cs.DB, cs.CL]
HIGHLIGHT: In this paper, we thus introduce our vision of relational representation learning, that can not only learn from the full relational structure, but also can scale to larger database sizes that are commonly found in real-world.

379, TITLE: Invited Paper: Initial Steps Toward A Compiler for Distributed Programs
AUTHORS: Joseph M. Hellerstein ; Shadaj Laddad ; Mae Milano ; Conor Power ; Mingwei Samuel
CATEGORY: cs.DC [cs.DC, cs.DB, cs.PL]
HIGHLIGHT: In the Hydro project we are designing a compiler toolkit that can optimize for the concerns of distributed systems, including scale-up and scale-down, availability, and consistency of outcomes across replicas.

380, TITLE: Multi-modal Machine Learning for Vehicle Rating Predictions Using Image, Text, and Parametric Data
AUTHORS: Hanqi Su ; Binyang Song ; Faez Ahmed
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CV]
HIGHLIGHT: These methods lack comprehensive analyses and exploration of data from multiple modes, which probably leads to inaccurate conclusions and hinders progress in this field. To overcome this limitation, we propose a multi-modal learning model for more comprehensive and accurate vehicle rating predictions.

381, TITLE: A Joint Time-frequency Domain Transformer for Multivariate Time Series Forecasting
AUTHORS: YUSHU CHEN et. al.
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: To enhance predicting performance while minimizing computational demands, this paper introduces a joint time-frequency domain Transformer (JTFT) for multivariate forecasting.

382, TITLE: Dealing with Cross-Task Class Discrimination in Online Continual Learning
AUTHORS: Yiduo Guo ; Bing Liu ; Dongyan Zhao
CATEGORY: cs.LG [cs.LG, cs.CV]
HIGHLIGHT: A novel optimization objective with a gradient-based adaptive method is proposed to dynamically deal with the problem in the online CL process.

383, TITLE: RSRM: Reinforcement Symbolic Regression Machine
AUTHORS: Yilong Xu ; Yang Liu ; Hao Sun
CATEGORY: cs.LG [cs.LG, cs.AI, cs.SC]
HIGHLIGHT: To this end, we propose a novel Reinforcement Symbolic Regression Machine (RSRM) that masters the capability of uncovering complex math equations from only scarce data.

384, TITLE: Using Models Based on Cognitive Theory to Predict Human Behavior in Traffic: A Case Study
AUTHORS: Julian F. Schumann ; Aravinda Ramakrishnan Srinivasan ; Jens Kober ; Gustav Markkula ; Arkady Zgonnikov
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: In this article, we investigate the usefulness of the \emph{Commotions} model -- a novel cognitively plausible model incorporating the latest theories of human perception, decision-making, and motor control -- for predicting human behavior in gap acceptance scenarios, which entail many important traffic interactions such as lane changes and intersections.

385, TITLE: Calc-X: Enriching Arithmetical Chain-of-Thoughts Datasets By Interaction with Symbolic Systems
AUTHORS: Marek Kadl?ík ; Michal ?tefánik
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CL]
HIGHLIGHT: We conduct an analysis of prominent relevant datasets such as GSM8K, Ape210K, AQuA-RAT, and MathQA and propose a machine-processable HTML-like format specifically tailored for working with semi-structured chains.

386, TITLE: Personalized DP-SGD Using Sampling Mechanisms
AUTHORS: Geon Heo ; Junseok Seo ; Steven Euijong Whang
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CR]
HIGHLIGHT: In practice, different users may require different privacy levels, and the model can be improved by using more information about the users with lower privacy requirements.

387, TITLE: PruMUX: Augmenting Data Multiplexing with Model Compression
AUTHORS: Yushan Su ; Vishvak Murahari ; Karthik Narasimhan ; Kai Li
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: Prior work has investigated techniques like model pruning, knowledge distillation, and data multiplexing to increase model throughput without sacrificing accuracy. In this paper, we combine two such methods -- structured pruning and data multiplexing -- to compound the speedup gains obtained by either method.

388, TITLE: Theoretically Principled Federated Learning for Balancing Privacy and Utility
AUTHORS: Xiaojin Zhang ; Wenjie Li ; Kai Chen ; Shutao Xia ; Qiang Yang
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CR]
HIGHLIGHT: We propose a general learning framework for the protection mechanisms that protects privacy via distorting model parameters, which facilitates the trade-off between privacy and utility.

389, TITLE: Winner-Take-All Column Row Sampling for Memory Efficient Adaptation of Language Model
AUTHORS: ZIRUI LIU et. al.
CATEGORY: cs.LG [cs.LG, cs.CL]
HIGHLIGHT: We argue that in stochastic optimization, models can handle noisy gradients as long as the gradient estimator is unbiased with reasonable variance. Following this motivation, we propose a new family of unbiased estimators called WTA-CRS, for matrix production with reduced variance, which only requires storing the sub-sampled activations for calculating the gradient.

390, TITLE: AdvFunMatch: When Consistent Teaching Meets Adversarial Robustness
AUTHORS: Ziuhi Wu ; Haichang Gao ; Bingqian Zhou ; Ping Wang
CATEGORY: cs.LG [cs.LG, cs.CV]
HIGHLIGHT: However, one limitation of FunMatch is that it does not account for the transfer of adversarial robustness, a model's resistance to adversarial attacks. To tackle this problem, we propose a simple but effective strategy called Adversarial Function Matching (AdvFunMatch), which aims to match distributions for all data points within the $\ell_p$-norm ball of the training data, in accordance with consistent teaching.

391, TITLE: Decision-Aware Actor-Critic with Function Approximation and Theoretical Guarantees
AUTHORS: Sharan Vaswani ; Amirreza Kazemi ; Reza Babanezhad ; Nicolas Le Roux
CATEGORY: cs.LG [cs.LG, cs.AI, math.OC]
HIGHLIGHT: We use the proposed objective to design a generic, AC algorithm that can easily handle any function approximation.

392, TITLE: Rethinking The Evaluation Protocol of Domain Generalization
AUTHORS: HAN YU et. al.
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CV]
HIGHLIGHT: We propose that training from scratch and using multiple test domains would result in a more precise evaluation of OOD generalization ability.

393, TITLE: Contrastive Training of Complex-Valued Autoencoders for Object Discovery
AUTHORS: Aleksandar Stani? ; Anand Gopalakrishnan ; Kazuki Irie ; Jürgen Schmidhuber
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CV]
HIGHLIGHT: Here we introduce architectural modifications and a novel contrastive learning method that greatly improve the state-of-the-art synchrony-based model.

394, TITLE: Utility-Probability Duality of Neural Networks
AUTHORS: Huang Bojun ; Fei Yuan
CATEGORY: cs.LG [cs.LG, cs.CL, cs.NE]
HIGHLIGHT: In this perspective, training of the neural network corresponds to a utility learning process.

395, TITLE: Pre-RMSNorm and Pre-CRMSNorm Transformers: Equivalent and Efficient Pre-LN Transformers
AUTHORS: Zixuan Jiang ; Jiaqi Gu ; Hanqing Zhu ; David Z. Pan
CATEGORY: cs.LG [cs.LG, cs.AI, cs.NE]
HIGHLIGHT: By removing the inherent redundant mean information in the main branch of Pre-LN Transformers, we can reduce LayerNorm to RMSNorm, achieving higher efficiency.

396, TITLE: SWAMP: Sparse Weight Averaging with Multiple Particles for Iterative Magnitude Pruning
AUTHORS: Moonseok Choi ; Hyungi Lee ; Giung Nam ; Juho Lee
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: In light of the recent finding that the two successive matching IMP solutions are linearly connected without a loss barrier, we propose Sparse Weight Averaging with Multiple Particles (SWAMP), a straightforward modification of IMP that achieves performance comparable to an ensemble of two IMP solutions.

397, TITLE: Inverse Reinforcement Learning with The Average Reward Criterion
AUTHORS: Feiyang Wu ; Jingyang Ke ; Anqi Wu
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: Equipped with SPMD, we propose the Inverse Policy Mirror Descent (IPMD) method for solving the IRL problem with a $\mathcal{O}(1/\varepsilon^2)$ complexity.

398, TITLE: Building Transportation Foundation Model Via Generative Graph Transformer
AUTHORS: Xuhong Wang ; Ding Wang ; Liang Chen ; Yilun Lin
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: In this paper, we propose a novel approach, Transportation Foundation Model (TFM), which integrates the principles of traffic simulation into traffic prediction.

399, TITLE: From Tempered to Benign Overfitting in ReLU Neural Networks
AUTHORS: Guy Kornowski ; Gilad Yehudai ; Ohad Shamir
CATEGORY: cs.LG [cs.LG, cs.NE, stat.ML]
HIGHLIGHT: However, a theoretical justification of this claim for non-linear NNs has been lacking so far. In this work, we provide several results that aim at bridging these complementing views.

400, TITLE: Personalized Dictionary Learning for Heterogeneous Datasets
AUTHORS: Geyu Liang ; Naichen Shi ; Raed Al Kontar ; Salar Fattahi
CATEGORY: cs.LG [cs.LG, cs.CV]
HIGHLIGHT: Challenges for PerDL not only are inherited from classical dictionary learning (DL), but also arise due to the unknown nature of the shared and unique features. In this paper, we rigorously formulate this problem and provide conditions under which the global and local dictionaries can be provably disentangled.

401, TITLE: Feature-aligned N-BEATS with Sinkhorn Divergence
AUTHORS: Myeongho Jeon ; Myungjoo Kang ; Joonhun Lee ; Kyunghyun Park
CATEGORY: cs.LG [cs.LG, cs.AI, math.OC, math.PR]
HIGHLIGHT: In this study, we propose Feature-aligned N-BEATS as a domain generalization model for univariate time series forecasting problems.

402, TITLE: READ: Recurrent Adaptation of Large Transformers
AUTHORS: Sid Wang ; John Nguyen ; Ke Li ; Carole-Jean Wu
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: In this paper, we introduce \textbf{RE}current \textbf{AD}aption (READ) -- a lightweight and memory-efficient fine-tuning method -- to overcome the limitations of the current PETL approaches.

403, TITLE: Eliminating Spurious Correlations from Pre-trained Models Via Data Mixing
AUTHORS: Yihao Xue ; Ali Payani ; Yu Yang ; Baharan Mirzasoleiman
CATEGORY: cs.LG [cs.LG, cs.CL, cs.CV]
HIGHLIGHT: In this work, we propose a simple and highly effective method to eliminate spurious correlations from pre-trained models.

404, TITLE: Can Transformers Learn to Solve Problems Recursively?
AUTHORS: Shizhuo Dylan Zhang ; Curt Tigges ; Stella Biderman ; Maxim Raginsky ; Talia Ringer
CATEGORY: cs.LG [cs.LG, cs.AI, cs.LO, cs.PL]
HIGHLIGHT: This paper examines the behavior of neural networks learning algorithms relevant to programs and formal verification proofs through the lens of mechanistic interpretability, focusing in particular on structural recursion.

405, TITLE: CongFu: Conditional Graph Fusion for Drug Synergy Prediction
AUTHORS: Oleksii Tsepa ; Bohdan Naida ; Bo Wang
CATEGORY: cs.LG [cs.LG, cs.AI, q-bio.QM]
HIGHLIGHT: In this work, we introduce CongFu, a novel Conditional Graph Fusion Layer, designed to predict drug synergy.

406, TITLE: Kernel Interpolation with Sparse Grids
AUTHORS: Mohit Yadav ; Daniel Sheldon ; Cameron Musco
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: Unfortunately, SKI scales poorly in the dimension of the input points, since the dense grid size grows exponentially with the dimension. To mitigate this issue, we propose the use of sparse grids within the SKI framework.

407, TITLE: Relating Implicit Bias and Adversarial Attacks Through Intrinsic Dimension
AUTHORS: LORENZO BASILE et. al.
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CR, stat.ML]
HIGHLIGHT: Naturally, a question arises regarding the potential connection between the architecture, settings, or properties of the model and the nature of the attack. In this work, we aim to shed light on this problem by focusing on the implicit bias of the neural network, which refers to its inherent inclination to favor specific patterns or outcomes.

408, TITLE: Difference-Masking: Choosing What to Mask in Continued Pretraining
AUTHORS: ALEX WILF et. al.
CATEGORY: cs.LG [cs.LG, cs.CL]
HIGHLIGHT: We introduce Difference-Masking, an approach that automatically chooses what to mask during continued pretraining by considering what makes an unlabelled target domain different from the pretraining domain.

409, TITLE: Non-adversarial Robustness of Deep Learning Methods for Computer Vision
AUTHORS: Gorana Goji? ; Vladimir Vincan ; Ognjen Kunda?ina ; Dragi?a Mi?kovi? ; Dinu Dragan
CATEGORY: cs.LG [cs.LG, cs.CV]
HIGHLIGHT: In this paper, we present a brief overview of the most recent techniques for improving the robustness of computer vision methods, as well as a summary of commonly used robustness benchmark datasets for evaluating the model's performance under data distribution shifts.

410, TITLE: Interpretation of Time-Series Deep Models: A Survey
AUTHORS: ZIQI ZHAO et. al.
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: In this paper, we present a wide range of post-hoc interpretation methods for time-series models based on backpropagation, perturbation, and approximation.

411, TITLE: Constant Memory Attentive Neural Processes
AUTHORS: Leo Feng ; Frederick Tung ; Hossein Hajimirsadeghi ; Yoshua Bengio ; Mohamed Osama Ahmed
CATEGORY: cs.LG [cs.LG, cs.CV]
HIGHLIGHT: In this work, we propose Constant Memory Attentive Neural Processes (CMANPs), an NP variant which only requires constant memory for the conditioning, querying, and updating phases.

412, TITLE: Towards Revealing The Mystery Behind Chain of Thought: A Theoretical Perspective
AUTHORS: GUHAO FENG et. al.
CATEGORY: cs.LG [cs.LG, cs.CC, cs.CL, stat.ML]
HIGHLIGHT: Despite the enormous empirical success, the underlying mechanisms behind CoT and how it unlocks the potential of LLMs remain elusive. In this paper, we take a first step towards theoretically answering these questions.

413, TITLE: The Crucial Role of Normalization in Sharpness-Aware Minimization
AUTHORS: Yan Dai ; Kwangjun Ahn ; Suvrit Sra
CATEGORY: cs.LG [cs.LG, cs.AI, stat.ML]
HIGHLIGHT: We focus, in particular, on understanding the role played by normalization, a key component of the SAM updates.

414, TITLE: Negative Feedback Training: A Novel Concept to Improve Robustness of NVCiM DNN Accelerators
AUTHORS: Yifan Qin ; Zheyu Yan ; Wujie Wen ; Xiaobo Sharon Hu ; Yiyu Shi
CATEGORY: cs.LG [cs.LG, cs.AI, cs.AR]
HIGHLIGHT: Drawing inspiration from the negative feedback mechanism, we introduce a novel training approach that uses a multi-exit mechanism as negative feedback to enhance the performance of DNN models in the presence of device variation.

415, TITLE: Sequence Modeling Is A Robust Contender for Offline Reinforcement Learning
AUTHORS: Prajjwal Bhargava ; Rohan Chitnis ; Alborz Geramifard ; Shagun Sodhani ; Amy Zhang
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: A key open question is: which paradigm is preferred under what conditions? We study this question empirically by exploring the performance of representative algorithms -- Conservative Q-Learning (CQL), Behavior Cloning (BC), and Decision Transformer (DT) -- across the commonly used D4RL and Robomimic benchmarks.

416, TITLE: Theorem Proving in Dependently-Typed Higher-Order Logic -- Extended Preprint
AUTHORS: Colin Rothgang ; Florian Rabe ; Christoph Benzmüller
CATEGORY: cs.LO [cs.LO, cs.AI, cs.FL, math.LO]
HIGHLIGHT: We introduce a dependently-typed extension DHOL of HOL that retains the style and conceptual framework of HOL.

417, TITLE: Bayesian Calibration of Differentiable Agent-based Models
AUTHORS: Arnau Quera-Bofarull ; Ayush Chopra ; Anisoara Calinescu ; Michael Wooldridge ; Joel Dyer
CATEGORY: cs.MA [cs.MA, cs.AI, stat.ML]
HIGHLIGHT: These difficulties have in turn generated research on approximate Bayesian inference methods for ABMs and on constructing differentiable approximations to arbitrary ABMs, but little work has been directed towards designing approximate Bayesian inference techniques for the specific case of differentiable ABMs. In this work, we aim to address this gap and discuss how generalised variational inference procedures may be employed to provide misspecification-robust Bayesian parameter inferences for differentiable ABMs.

418, TITLE: Selection for Short-term Empowerment Accelerates The Evolution of Homeostatic Neural Cellular Automata
AUTHORS: Caitlin Grasso ; Josh Bongard
CATEGORY: cs.NE [cs.NE, cs.AI, cs.IT, math.IT]
HIGHLIGHT: Source code for the experiments in this paper can be found at: https://github.com/caitlingrasso/empowered-nca-II.

419, TITLE: Challenges of ELA-guided Function Evolution Using Genetic Programming
AUTHORS: FU XING LONG et. al.
CATEGORY: cs.NE [cs.NE]
HIGHLIGHT: While features exist to capture low-level landscape properties, they might not always capture the intended high-level features. We show that a genetic programming (GP) approach guided by these exploratory landscape analysis (ELA) properties is not always able to find satisfying functions.

420, TITLE: Analysis of Modular CMA-ES on Strict Box-constrained Problems in The SBOX-COST Benchmarking Suite
AUTHORS: Diederick Vermetten ; Manuel López-Ibáńez ; Olaf Mersmann ; Richard Allmendinger ; Anna V. Kononova
CATEGORY: cs.NE [cs.NE]
HIGHLIGHT: This paper presents an initial study on the strict-box-constrained benchmarking suite (SBOX-COST), which is a variant of the well-known BBOB benchmark suite that enforces box-constraints by returning an invalid evaluation value for infeasible solutions.

421, TITLE: Automated Sensitivity Analysis for Probabilistic Loops
AUTHORS: Marcel Moosbrugger ; Julian Müllner ; Laura Kovács
CATEGORY: cs.PL [cs.PL]
HIGHLIGHT: We present an exact approach to analyze and quantify the sensitivity of higher moments of probabilistic loops with symbolic parameters, polynomial arithmetic and potentially uncountable state spaces.

422, TITLE: Barkour: Benchmarking Animal-level Agility with Quadruped Robots
AUTHORS: KEN CALUWAERTS et. al.
CATEGORY: cs.RO [cs.RO, cs.AI]
HIGHLIGHT: To set strong baselines, we present two methods for tackling the benchmark.

423, TITLE: EmbodiedGPT: Vision-Language Pre-Training Via Embodied Chain of Thought
AUTHORS: YAO MU et. al.
CATEGORY: cs.RO [cs.RO, cs.AI, cs.CV, cs.LG]
HIGHLIGHT: In this work, we introduce EmbodiedGPT, an end-to-end multi-modal foundation model for embodied AI, empowering embodied agents with multi-modal understanding and execution capabilities.

424, TITLE: Integrated Object Deformation and Contact Patch Estimation from Visuo-Tactile Feedback
AUTHORS: Mark Van der Merwe ; Youngsun Wi ; Dmitry Berenson ; Nima Fazeli
CATEGORY: cs.RO [cs.RO, cs.CV]
HIGHLIGHT: In this paper, we propose Neural Deforming Contact Field (NDCF), a representation that jointly models object deformations and contact patches from visuo-tactile feedback using implicit representations.

425, TITLE: A New Era in Software Security: Towards Self-Healing Software Via Large Language Models and Formal Verification
AUTHORS: YIANNIS CHARALAMBOUS et. al.
CATEGORY: cs.SE [cs.SE, cs.AI, cs.FL, cs.LG]
HIGHLIGHT: In this paper we present a novel solution that combines the capabilities of Large Language Models (LLMs) with Formal Verification strategies to verify and automatically repair software vulnerabilities.

426, TITLE: Iteratively Improving Speech Recognition and Voice Conversion
AUTHORS: Mayank Kumar Singh ; Naoya Takahashi ; Onoe Naoyuki
CATEGORY: cs.SD [cs.SD, cs.AI, eess.AS]
HIGHLIGHT: In this work, we propose a novel iterative way of improving both the ASR and VC models.

427, TITLE: Behavior Quantification As The Missing Link Between Fields: Tools for Digital Psychiatry and Their Role in The Future of Neurobiology
AUTHORS: Michaela Ennis
CATEGORY: q-bio.NC [q-bio.NC, cs.AI, cs.CY]
HIGHLIGHT: Their temporally dense nature enables a cohesive study of real-time neural and behavioral signals.

428, TITLE: A Rigorous Link Between Deep Ensembles and (Variational) Bayesian Methods
AUTHORS: Veit David Wild ; Sahra Ghalebikesabi ; Dino Sejdinovic ; Jeremias Knoblauch
CATEGORY: stat.ML [stat.ML, cs.AI, cs.LG, math.ST, stat.ME, stat.TH]
HIGHLIGHT: On a technical level, our contribution amounts to studying generalised variational inference through the lense of Wasserstein gradient flows.

429, TITLE: Music Representing Corpus Virtual: An Open Sourced Library for Explorative Music Generation, Sound Design, and Instrument Creation with Artificial Intelligence and Machine Learning
AUTHORS: Christopher Johann Clarke
CATEGORY: eess.AS [eess.AS, cs.AI]
HIGHLIGHT: The software is accessible to users of varying levels of experience, with an emphasis on providing an explorative approach to MGSDIC.

430, TITLE: On The Transferability of Whisper-based Representations for "In-the-Wild" Cross-Task Downstream Speech Applications
AUTHORS: VAMSIKRISHNA CHEMUDUPATI et. al.
CATEGORY: eess.AS [eess.AS, cs.CL, cs.LG, cs.SD]
HIGHLIGHT: Given the superiority of Whisper for ASR, in this paper we explore the transferability of the representation for four other speech tasks in SUPERB benchmark.

431, TITLE: Deep Learning-based Bio-Medical Image Segmentation Using UNet Architecture and Transfer Learning
AUTHORS: Nima Hassanpour ; Abouzar Ghavami
CATEGORY: eess.IV [eess.IV, cs.CV, cs.LG]
HIGHLIGHT: Recently, UNet architecture is found as the core of novel deep learning segmentation methods. In this paper we implement UNet architecture from scratch with using basic blocks in Pytorch and evaluate its performance on multiple biomedical image datasets.

432, TITLE: Solving Diffusion ODEs with Optimal Boundary Conditions for Better Image Super-Resolution
AUTHORS: Yiyang Ma ; Huan Yang ; Wenhan Yang ; Jianlong Fu ; Jiaying Liu
CATEGORY: eess.IV [eess.IV, cs.CV, cs.LG]
HIGHLIGHT: More in detail, we propose to steadily sample high-quality SR images from pretrained diffusion-based SR models by solving diffusion ordinary differential equations (diffusion ODEs) with optimal boundary conditions (BCs) and analyze the characteristics between the choices of BCs and their corresponding SR results.

433, TITLE: ORRN: An ODE-based Recursive Registration Network for Deformable Respiratory Motion Estimation with Lung 4DCT Images
AUTHORS: Xiao Liang ; Shan Lin ; Dimitri Schreiber ; Michael Yip
CATEGORY: eess.IV [eess.IV, cs.CV, cs.LG]
HIGHLIGHT: This paper presents ORRN, an Ordinary Differential Equations (ODE)-based recursive image registration network.

434, TITLE: Attentive Continuous Generative Self-training for Unsupervised Domain Adaptive Medical Image Translation
AUTHORS: XIAOFENG LIU et. al.
CATEGORY: eess.IV [eess.IV, cs.CV, cs.LG, physics.med-ph]
HIGHLIGHT: While self-training-based UDA has shown considerable promise on discriminative tasks, including classification and segmentation, through reliable pseudo-label filtering based on the maximum softmax probability, there is a paucity of prior work on self-training-based UDA for generative tasks, including image modality translation. To fill this gap, in this work, we seek to develop a generative self-training (GST) framework for domain adaptive image translation with continuous value prediction and regression objectives.

435, TITLE: An Accelerated Pipeline for Multi-label Renal Pathology Image Segmentation at The Whole Slide Image Level
AUTHORS: HAOJU LENG et. al.
CATEGORY: eess.IV [eess.IV, cs.CV]
HIGHLIGHT: In this paper, we propose an enhanced version of the Omni-Seg pipeline in order to reduce the repetitive computing processes and utilize a GPU to accelerate the model's prediction for both better model performance and faster speed.
