1, TITLE: CoAnnotating: Uncertainty-Guided Work Allocation Between Human and Large Language Models for Data Annotation
AUTHORS: MINZHI LI et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We propose CoAnnotating, a novel paradigm for Human-LLM co-annotation of unstructured texts at scale.

2, TITLE: Woodpecker: Hallucination Correction for Multimodal Large Language Models
AUTHORS: SHUKANG YIN et. al.
CATEGORY: cs.CV [cs.CV, cs.AI, cs.CL, cs.LG]
HIGHLIGHT: In this paper, we pave a different way, introducing a training-free method named Woodpecker.

3, TITLE: White-box Compiler Fuzzing Empowered By Large Language Models
AUTHORS: CHENYUAN YANG et. al.
CATEGORY: cs.SE [cs.SE, cs.LG, cs.PL]
HIGHLIGHT: To this end, we propose WhiteFox, the first white-box compiler fuzzer using LLMs with source-code information to test compiler optimization.

4, TITLE: Specialist or Generalist? Instruction Tuning for Specific NLP Tasks
AUTHORS: Chufan Shi ; Yixuan Su ; Cheng Yang ; Yujiu Yang ; Deng Cai
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: The potential of large language models (LLMs) to simultaneously perform a wide range of natural language processing (NLP) tasks has been the subject of extensive research.

5, TITLE: A Survey on Detection of LLMs-Generated Content
AUTHORS: XIANJUN YANG et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.CY, cs.HC, cs.LG]
HIGHLIGHT: We aim to provide a detailed overview of existing detection strategies and benchmarks, scrutinizing their differences and identifying key challenges and prospects in the field, advocating for more adaptable and robust models to enhance detection accuracy.

6, TITLE: Representation Learning with Large Language Models for Recommendation
AUTHORS: XUBIN REN et. al.
CATEGORY: cs.IR [cs.IR, cs.AI]
HIGHLIGHT: While the integration of large language models (LLMs) into traditional ID-based recommenders has gained attention, challenges such as scalability issues, limitations in text-only reliance, and prompt input constraints need to be addressed for effective implementation in practical recommender systems. To address these challenges, we propose a model-agnostic framework RLMRec that aims to enhance existing recommenders with LLM-empowered representation learning.

7, TITLE: Stanford-ORB: A Real-World 3D Object Inverse Rendering Benchmark
AUTHORS: ZHENGFEI KUANG et. al.
CATEGORY: cs.CV [cs.CV, cs.GR]
HIGHLIGHT: We introduce Stanford-ORB, a new real-world 3D Object inverse Rendering Benchmark.

8, TITLE: What Makes It Ok to Set A Fire? Iterative Self-distillation of Contexts and Rationales for Disambiguating Defeasible Social and Moral Situations
AUTHORS: KAVEL RAO et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We introduce defeasible moral reasoning: a task to provide grounded contexts that make an action more or less morally acceptable, along with commonsense rationales that justify the reasoning.

9, TITLE: UI Layout Generation with LLMs Guided By UI Grammar
AUTHORS: Yuwen Lu ; Ziang Tong ; Qinyi Zhao ; Chengzhi Zhang ; Toby Jia-Jun Li
CATEGORY: cs.HC [cs.HC, cs.AI]
HIGHLIGHT: Central to our exploration is the introduction of UI grammar -- a novel approach we proposed to represent the hierarchical structure inherent in UI screens.

10, TITLE: Synthetic Data As Validation
AUTHORS: Qixin Hu ; Alan Yuille ; Zongwei Zhou
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: In this study, we illustrate the effectiveness of synthetic data for early cancer detection in computed tomography (CT) volumes, where synthetic tumors are generated and superimposed onto healthy organs, thereby creating an extensive dataset for rigorous validation.

11, TITLE: Diverse Conventions for Human-AI Collaboration
AUTHORS: Bidipta Sarkar ; Andy Shih ; Dorsa Sadigh
CATEGORY: cs.AI [cs.AI, cs.LG, cs.MA]
HIGHLIGHT: In this work, we present a technique for generating diverse conventions by (1) maximizing their rewards during self-play, while (2) minimizing their rewards when playing with previously discovered conventions (cross-play), stimulating conventions to be semantically different.

12, TITLE: KITAB: Evaluating LLMs on Constraint Satisfaction for Information Retrieval
AUTHORS: MARAH I ABDIN et. al.
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CL, cs.IR, I.2.7]
HIGHLIGHT: Motivated by rising concerns around factual incorrectness and hallucinations of LLMs, we present KITAB, a new dataset for measuring constraint satisfaction abilities of language models.

13, TITLE: GD-COMET: A Geo-Diverse Commonsense Inference Model
AUTHORS: Mehar Bhatia ; Vered Shwartz
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we present GD-COMET, a geo-diverse version of the COMET commonsense inference model.

14, TITLE: Unpaired MRI Super Resolution with Self-Supervised Contrastive Learning
AUTHORS: HAO LI et. al.
CATEGORY: eess.IV [eess.IV, cs.CV, cs.LG]
HIGHLIGHT: In this paper, we propose an unpaired MRI SR approach that employs self-supervised contrastive learning to enhance SR performance with limited training data.

15, TITLE: Decoupled DETR: Spatially Disentangling Localization and Classification for Improved End-to-End Object Detection
AUTHORS: Manyuan Zhang ; Guanglu Song ; Yu Liu ; Hongsheng Li
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Unfortunately, such spatial misalignment between these two tasks greatly hinders DETR's training. Therefore, in this work, we focus on decoupling localization and classification tasks in DETR.

16, TITLE: Grasp Multiple Objects with One Hand
AUTHORS: YUYANG LI et. al.
CATEGORY: cs.RO [cs.RO, cs.CV]
HIGHLIGHT: This paper introduces MultiGrasp, a two-stage method for multi-object grasping on a tabletop with a multi-finger dexterous hand.

17, TITLE: Active Teacher Selection for Reinforcement Learning from Human Feedback
AUTHORS: Rachel Freedman ; Justin Svegliato ; Kyle Wray ; Stuart Russell
CATEGORY: cs.AI [cs.AI, cs.LG]
HIGHLIGHT: We propose the Hidden Utility Bandit (HUB) framework to model differences in teacher rationality, expertise, and costliness, formalizing the problem of learning from multiple teachers.

18, TITLE: Dissecting In-Context Learning of Translations in GPTs
AUTHORS: Vikas Raunak ; Hany Hassan Awadalla ; Arul Menezes
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this work, we try to better understand the role of demonstration attributes for the in-context learning of translations through perturbations of high-quality, in-domain demonstrations.

19, TITLE: ConstitutionMaker: Interactively Critiquing Large Language Models By Converting Feedback Into Principles
AUTHORS: SAVVAS PETRIDIS et. al.
CATEGORY: cs.HC [cs.HC, cs.AI]
HIGHLIGHT: However, current methods for steering a chatbot's outputs, such as prompt engineering and fine-tuning, do not support users in converting their natural feedback on the model's outputs to changes in the prompt or model. In this work, we explore how to enable users to interactively refine model outputs through their feedback, by helping them convert their feedback into a set of principles (i.e. a constitution) that dictate the model's behavior.

20, TITLE: Emergent Communication in Interactive Sketch Question Answering
AUTHORS: Zixing Lei ; Yiming Zhang ; Yuxin Xiong ; Siheng Chen
CATEGORY: cs.AI [cs.AI, cs.CV]
HIGHLIGHT: Vision-based emergent communication (EC) aims to learn to communicate through sketches and demystify the evolution of human communication.

21, TITLE: Creating A Silver Standard for Patent Simplification
AUTHORS: Silvia Casola ; Alberto Lavelli ; Horacio Saggion
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: This paper proposes an approach to automatically simplify patent text through rephrasing.

22, TITLE: Prevalence and Prevention of Large Language Model Use in Crowd Work
AUTHORS: VENIAMIN VESELOVSKY et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We show that the use of large language models (LLMs) is prevalent among crowd workers, and that targeted mitigation strategies can significantly reduce, but not eliminate, LLM use.

23, TITLE: "One-size-fits-all"? Observations and Expectations of NLG Systems Across Identity-Related Language Features
AUTHORS: Li Lucy ; Su Lin Blodgett ; Milad Shokouhi ; Hanna Wallach ; Alexandra Olteanu
CATEGORY: cs.CL [cs.CL, cs.HC]
HIGHLIGHT: We design and conduct five case studies, in which we perturb different types of identity-related language features (names, roles, locations, dialect, and style) in NLG system inputs to illuminate tensions around invariance and adaptation.

24, TITLE: What's Left? Concept Grounding with Logic-Enhanced Foundation Models
AUTHORS: Joy Hsu ; Jiayuan Mao ; Joshua B. Tenenbaum ; Jiajun Wu
CATEGORY: cs.CV [cs.CV, cs.AI, cs.CL, cs.LG, stat.ML]
HIGHLIGHT: We propose the Logic-Enhanced Foundation Model (LEFT), a unified framework that learns to ground and reason with concepts across domains with a differentiable, domain-independent, first-order logic-based program executor.

25, TITLE: Graph Deep Learning for Time Series Forecasting
AUTHORS: Andrea Cini ; Ivan Marisca ; Daniele Zambon ; Cesare Alippi
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: To fill the gap, this paper aims to introduce a comprehensive methodological framework that formalizes the forecasting problem and provides design principles for graph-based predictive models and methods to assess their performance.

26, TITLE: A Joint Matrix Factorization Analysis of Multilingual Representations
AUTHORS: Zheng Zhao ; Yftah Ziser ; Bonnie Webber ; Shay B. Cohen
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We present an analysis tool based on joint matrix factorization for comparing latent representations of multilingual and monolingual models.

27, TITLE: GradSim: Gradient-Based Language Grouping for Effective Multilingual Training
AUTHORS: Mingyang Wang ; Heike Adel ; Lukas Lange ; Jannik Str�tgen ; Hinrich Sch�tze
CATEGORY: cs.LG [cs.LG, cs.CL]
HIGHLIGHT: In this paper, we propose GradSim, a language grouping method based on gradient similarity.

28, TITLE: Self-Guard: Empower The LLM to Safeguard Itself
AUTHORS: ZEZHONG WANG et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Safeguards have proven to be of limited help. To tackle these issues, we propose a novel approach called Self-Guard, which combines the strengths of both safety methods.

29, TITLE: Random Entity Quantization for Parameter-Efficient Compositional Knowledge Graph Representation
AUTHORS: Jiaang Li ; Quan Wang ; Yi Liu ; Licheng Zhang ; Zhendong Mao
CATEGORY: cs.AI [cs.AI, cs.CL, cs.LG]
HIGHLIGHT: The dominant approach, KG Embedding (KGE), represents entities with independent vectors and faces the scalability challenge.

30, TITLE: Combining Behaviors with The Successor Features Keyboard
AUTHORS: WILKA CARVALHO et. al.
CATEGORY: cs.AI [cs.AI, cs.LG]
HIGHLIGHT: In this work, we propose the "Successor Features Keyboard" (SFK), which enables transfer with discovered state-features and task encodings.

31, TITLE: Re-Temp: Relation-Aware Temporal Representation Learning for Temporal Knowledge Graph Completion
AUTHORS: Kunze Wang ; Soyeon Caren Han ; Josiah Poon
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: However, these approaches tend to overlook the ability to skip irrelevant snapshots according to entity-related relations in the query and disregard the importance of explicit temporal information. To address this, we propose our model, Re-Temp (Relation-Aware Temporal Representation Learning), which leverages explicit temporal embedding as input and incorporates skip information flow after each timestamp to skip unnecessary information for prediction.

32, TITLE: AdaptiX -- A Transitional XR Framework for Development and Evaluation of Shared Control Applications in Assistive Robotics
AUTHORS: Max Pascher ; Felix Ferdinand Goldau ; Kirill Kronhardt ; Udo Frese ; Jens Gerken
CATEGORY: cs.HC [cs.HC, cs.AI, cs.RO, cs.SE, H.5; I.2.9; D.2.11; B.4.2]
HIGHLIGHT: This paper presents the free and open-source AdaptiX XR framework for developing and evaluating shared control applications in a high-resolution simulation environment.

33, TITLE: AutoDiff: Combining Auto-encoder and Diffusion Model for Tabular Data Synthesizing
AUTHORS: Namjoon Suh ; Xiaofeng Lin ; Din-Yin Hsieh ; Merhdad Honarkhah ; Guang Cheng
CATEGORY: stat.ML [stat.ML, cs.AI, cs.LG]
HIGHLIGHT: In this paper, we leverage the power of diffusion model for generating synthetic tabular data.

34, TITLE: Unnatural Language Processing: How Do Language Models Handle Machine-generated Prompts?
AUTHORS: Corentin Kervadec ; Francesca Franzon ; Marco Baroni
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Language model prompt optimization research has shown that semantically and grammatically well-formed manually crafted prompts are routinely outperformed by automatically generated token sequences with no apparent meaning or syntactic structure, including sequences of vectors from a model's embedding space.

35, TITLE: Hallucination Detection for Grounded Instruction Generation
AUTHORS: Lingjun Zhao ; Khanh Nguyen ; Hal Daum� III
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: We investigate the problem of generating instructions to guide humans to navigate in simulated residential environments.

36, TITLE: MuSR: Testing The Limits of Chain-of-thought with Multistep Soft Reasoning
AUTHORS: Zayne Sprague ; Xi Ye ; Kaj Bostrom ; Swarat Chaudhuri ; Greg Durrett
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We introduce MuSR, a dataset for evaluating language models on multistep soft reasoning tasks specified in a natural language narrative.

37, TITLE: FANToM: A Benchmark for Stress-testing Machine Theory of Mind in Interactions
AUTHORS: HYUNWOO KIM et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: We introduce FANToM, a new benchmark designed to stress-test ToM within information-asymmetric conversational contexts via question answering.

38, TITLE: GUPNet++: Geometry Uncertainty Propagation Network for Monocular 3D Object Detection
AUTHORS: YAN LU et. al.
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: It leads to unreliable depth inferences and also impairs training stability. To tackle this problem, we propose a novel Geometry Uncertainty Propagation Network (GUPNet++) by modeling geometry projection in a probabilistic manner.

39, TITLE: CRaSh: Clustering, Removing, and Sharing Enhance Fine-tuning Without Full Large Language Model
AUTHORS: KAIYAN ZHANG et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Simultaneously, we note subtle but potentially significant changes in representation and intermediate predictions across the layers. Inspired by these observations, we propose CRaSh, involving Clustering, Removing, and Sharing, a training-free strategy to derive improved emulators from LLMs.

40, TITLE: Machine Translation for Nko: Tools, Corpora and Baseline Results
AUTHORS: MOUSSA KOULAKO BALA DOUMBOUYA et. al.
CATEGORY: cs.CL [cs.CL, cs.CY, cs.HC, cs.LG]
HIGHLIGHT: Currently, there is no usable machine translation system for Nko, a language spoken by tens of millions of people across multiple West African countries, which holds significant cultural and educational value. To address this issue, we present a set of tools, resources, and baseline results aimed towards the development of usable machine translation systems for Nko and other languages that do not currently have sufficiently large parallel text corpora available.

41, TITLE: Do Differences in Values Influence Disagreements in Online Discussions?
AUTHORS: Michiel van der Meer ; Piek Vossen ; Catholijn M. Jonker ; Pradeep K. Murukannaiah
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We investigate a hypothesis that differences in personal values are indicative of disagreement in online discussions.

42, TITLE: MarkQA: A Large Scale KBQA Dataset with Numerical Reasoning
AUTHORS: Xiang Huang ; Sitao Cheng ; Yuheng Bao ; Shanshan Huang ; Yuzhong Qu
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we focus on the complex numerical reasoning in KBQA and propose a new task, NR-KBQA, which necessitates the ability to perform both multi-hop reasoning and numerical reasoning.

43, TITLE: Fast Propagation Is Better: Accelerating Single-Step Adversarial Training Via Sampling Subnetworks
AUTHORS: Xiaojun Jia ; Jianshu Li ; Jindong Gu ; Yang Bai ; Xiaochun Cao
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this work, we propose to exploit the interior building blocks of the model to improve efficiency.

44, TITLE: Improving Language Models Meaning Understanding and Consistency By Learning Conceptual Roles from Dictionary
AUTHORS: Myeongjun Erik Jang ; Thomas Lukasiewicz
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: To this end, we propose a practical approach that alleviates the inconsistent behaviour issue by fundamentally improving PLMs' meaning awareness.

45, TITLE: COPF: Continual Learning Human Preference Through Optimal Policy Fitting
AUTHORS: HAN ZHANG et. al.
CATEGORY: cs.LG [cs.LG, cs.CL]
HIGHLIGHT: Retraining LMs poses practical difficulties in many real-world situations due to the significant time and computational resources required, along with concerns related to data privacy. To address this limitation, we propose a new method called Continual Optimal Policy Fitting (COPF), in which we estimate a series of optimal policies using the Monte Carlo method, and then continually fit the policy sequence with the function regularization.

46, TITLE: Geometry-Aware Video Quality Assessment for Dynamic Digital Human
AUTHORS: Zicheng Zhang ; Yingjie Zhou ; Wei Sun ; Xiongkuo Min ; Guangtao Zhai
CATEGORY: cs.CV [cs.CV, eess.IV]
HIGHLIGHT: However, the VQA methods are highly dependent on viewpoints and less sensitive to geometry-based distortions. Therefore, in this paper, we propose a novel no-reference (NR) geometry-aware video quality assessment method for DDH-QA challenge.

47, TITLE: Generative and Contrastive Paradigms Are Complementary for Graph Self-Supervised Learning
AUTHORS: YUXIANG WANG et. al.
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: However, MAE and CL are considered separately in existing works for GSSL. We observe that the MAE and CL paradigms are complementary and propose the graph contrastive masked autoencoder (GCMAE) framework to unify them.

48, TITLE: Recent Advances in Multi-modal 3D Scene Understanding: A Comprehensive Survey and Evaluation
AUTHORS: YINJIE LEI et. al.
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: While there has been a surge in the development of multi-modal 3D methods over past three years, especially those integrating multi-camera images (3D+2D) and textual descriptions (3D+language), a comprehensive and in-depth review is notably absent. In this article, we present a systematic survey of recent progress to bridge this gap.

49, TITLE: Improving Biomedical Abstractive Summarisation with Knowledge Aggregation from Citation Papers
AUTHORS: Chen Tang ; Shun Wang ; Tomas Goldsack ; Chenghua Lin
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: We propose a novel attention-based citation aggregation model that integrates domain-specific knowledge from citation papers, allowing neural networks to generate summaries by leveraging both the paper content and relevant knowledge from citation papers.

50, TITLE: Enhancing Biomedical Lay Summarisation with External Knowledge Graphs
AUTHORS: Tomas Goldsack ; Zhihao Zhang ; Chen Tang ; Carolina Scarton ; Chenghua Lin
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Using both automatic and human evaluations, we systematically investigate the effectiveness of three different approaches for incorporating knowledge graphs within lay summarisation models, with each method targeting a distinct area of the encoder-decoder model architecture.

51, TITLE: Integrating View Conditions for Image Synthesis
AUTHORS: JINBIN BAI et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: This paper introduces a pioneering framework that integrates viewpoint information to enhance the control of image editing tasks.

52, TITLE: WebWISE: Web Interface Control and Sequential Exploration with Large Language Models
AUTHORS: Heyi Tao ; Sethuraman T V ; Michal Shlapentokh-Rothman ; Derek Hoiem ; Heng Ji
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: The paper investigates using a Large Language Model (LLM) to automatically perform web software tasks using click, scroll, and text input operations.

53, TITLE: Variator: Accelerating Pre-trained Models with Plug-and-Play Compression Modules
AUTHORS: CHAOJUN XIAO et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we propose Variator, a parameter-efficient acceleration method that enhances computational efficiency through plug-and-play compression plugins.

54, TITLE: On The Dimensionality of Sentence Embeddings
AUTHORS: Hongwei Wang ; Hongming Zhang ; Dong Yu
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Subsequently, to compress the dimension of sentence embeddings with minimum performance degradation, we identify two components contributing to the overall performance loss: the encoder's performance loss and the pooler's performance loss. Therefore, we propose a two-step training method for sentence representation learning models, wherein the encoder and the pooler are optimized separately to mitigate the overall performance loss in low-dimension scenarios.

55, TITLE: NoteChat: A Dataset of Synthetic Doctor-Patient Conversations Conditioned on Clinical Notes
AUTHORS: JUNDA WANG et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we introduce NoteChat, a cooperative multi-agent framework leveraging Large Language Models (LLMs) for generating synthetic doctor-patient conversations conditioned on clinical notes.

56, TITLE: Instruct and Extract: Instruction Tuning for On-Demand Information Extraction
AUTHORS: YIZHU JIAO et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: However, when it comes to information extraction - a classic task in natural language processing - most task-specific systems cannot align well with long-tail ad hoc extraction use cases for non-expert users. To address this, we propose a novel paradigm, termed On-Demand Information Extraction, to fulfill the personalized demands of real-world users.

57, TITLE: Breaking The Language Barrier: Improving Cross-Lingual Reasoning with Structured Self-Attention
AUTHORS: Negar Foroutan ; Mohammadreza Banaei ; Karl Aberer ; Antoine Bosselut
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this work, we study whether multilingual language models (MultiLMs) can transfer logical reasoning abilities to other languages when they are fine-tuned for reasoning in a different language.

58, TITLE: TRAMS: Training-free Memory Selection for Long-range Language Modeling
AUTHORS: Haofei Yu ; Cunxiang wang ; Yue Zhang ; Wei Bi
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this study, we present a plug-and-play strategy, known as TRAining-free Memory Selection (TRAMS), that selects tokens participating in attention calculation based on one simple metric.

59, TITLE: Generative Language Models Exhibit Social Identity Biases
AUTHORS: TIANCHENG HU et. al.
CATEGORY: cs.CL [cs.CL, cs.CY]
HIGHLIGHT: In this study, we investigate whether ingroup solidarity and outgroup hostility, fundamental social biases known from social science, are present in 51 large language models.

60, TITLE: Probing Representations for Document-level Event Extraction
AUTHORS: Barry Wang ; Xinya Du ; Claire Cardie
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: The probing classifiers framework has been employed for interpreting deep neural network models for a variety of natural language processing (NLP) applications.

61, TITLE: CRoW: Benchmarking Commonsense Reasoning in Real-World Tasks
AUTHORS: Mete Ismayilzada ; Debjit Paul ; Syrielle Montariol ; Mor Geva ; Antoine Bosselut
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this work, we present CRoW, a manually-curated, multi-task benchmark that evaluates the ability of models to apply commonsense reasoning in the context of six real-world NLP tasks.

62, TITLE: Multimodal Representations for Teacher-Guided Compositional Visual Reasoning
AUTHORS: Wafa Aissa ; Marin Ferecatu ; Michel Crucianu
CATEGORY: cs.CL [cs.CL, cs.CV, cs.LG]
HIGHLIGHT: To improve the effectiveness of NMNs we propose to exploit features obtained by a large-scale cross-modal encoder.

63, TITLE: Retrieval-based Knowledge Transfer: An Effective Approach for Extreme Large Language Model Compression
AUTHORS: JIDUAN LIU et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this paper, we introduce a novel compression paradigm called Retrieval-based Knowledge Transfer (RetriKT), which effectively transfers the knowledge of LLMs to extremely small-scale models (e.g., 1%).

64, TITLE: Towards Possibilities & Impossibilities of AI-generated Text Detection: A Survey
AUTHORS: SOUMYA SUVRA GHOSAL et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this survey, we aim to provide a concise categorization and overview of current work encompassing both the prospects and the limitations of AI-generated text detection.

65, TITLE: Efficient Algorithms for Recognizing Weighted Tree-Adjoining Languages
AUTHORS: Alexandra Butoi ; Tim Vieira ; Ryan Cotterell ; David Chiang
CATEGORY: cs.CL [cs.CL, cs.FL]
HIGHLIGHT: These four formalisms are equivalent to tree-adjoining grammars (TAG), linear indexed grammars (LIG), pushdown-adjoining automata (PAA), and embedded pushdown automata (EPDA). We define semiring-weighted versions of the above two-level formalisms, and we design new algorithms for computing their stringsums (the weight of all derivations of a string) and allsums (the weight of all derivations).

66, TITLE: Contrastive Learning-based Sentence Encoders Implicitly Weight Informative Words
AUTHORS: Hiroto Kurita ; Goro Kobayashi ; Sho Yokoi ; Kentaro Inui
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: This paper theoretically and experimentally shows that contrastive-based sentence encoders implicitly weight words based on information-theoretic quantities; that is, more informative words receive greater weight, while others receive less.

67, TITLE: This Is Not A Dataset: A Large Negation Benchmark to Challenge Large Language Models
AUTHORS: Iker Garc�a-Ferrero ; Bego�a Altuna ; Javier �lvez ; Itziar Gonzalez-Dios ; German Rigau
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We introduce a large semi-automatically generated dataset of circa 400,000 descriptive sentences about commonsense knowledge that can be true or false in which negation is present in about 2/3 of the corpus in different forms.

68, TITLE: Region-controlled Style Transfer
AUTHORS: Junjie Kang ; Jinsong Wu ; Shiqi Jiang
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: However, they fail to control the strength of textures in different regions of the content image. To address this issue, we propose a training method that uses a loss function to constrain the style intensity in different regions.

69, TITLE: Large Language Models Are Temporal and Causal Reasoners for Video Question Answering
AUTHORS: Dohwan Ko ; Ji Soo Lee ; Wooyoung Kang ; Byungseok Roh ; Hyunwoo J. Kim
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we develop LLaMA-VQA by applying Flipped-VQA to LLaMA, and it outperforms both LLMs-based and non-LLMs-based models on five challenging VideoQA benchmarks.

70, TITLE: Transitivity Recovering Decompositions: Interpretable and Robust Fine-Grained Relationships
AUTHORS: Abhra Chaudhuri ; Massimiliano Mancini ; Zeynep Akata ; Anjan Dutta
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: The relational representations relied upon by such methods, however, are abstract. We aim to deconstruct this abstraction by expressing them as interpretable graphs over image views.

71, TITLE: LXMERT Model Compression for Visual Question Answering
AUTHORS: Maryam Hashemi ; Ghazaleh Mahmoudi ; Sara Kodeiri ; Hadi Sheikhi ; Sauleh Eetemadi
CATEGORY: cs.CV [cs.CV, cs.CL, cs.LG]
HIGHLIGHT: According to the lottery ticket hypothesis, NLP and computer vision models contain smaller subnetworks capable of being trained in isolation to full performance. In this paper, we combine these observations to evaluate whether such trainable subnetworks exist in LXMERT when fine-tuned on the VQA task.

72, TITLE: The Janus Interface: How Fine-Tuning in Large Language Models Amplifies The Privacy Risks
AUTHORS: XIAOYI CHEN et. al.
CATEGORY: cs.CR [cs.CR, cs.CL]
HIGHLIGHT: This paper reports the first endeavor to seek the answer to the question, particularly our discovery of a new LLM exploitation avenue, called the Janus attack.

73, TITLE: Course Correcting Koopman Representations
AUTHORS: MAHAN FATHI et. al.
CATEGORY: cs.LG [cs.LG, cs.AI, cs.RO, cs.SY, eess.SY]
HIGHLIGHT: Theoretically, such features can be used to simplify many problems in modeling and control of NLDS. In this work we study autoencoder formulations of this problem, and different ways they can be used to model dynamics, specifically for future state prediction over long horizons.

74, TITLE: HetGPT: Harnessing The Power of Prompt Tuning in Pre-Trained Heterogeneous Graph Neural Networks
AUTHORS: Yihong Ma ; Ning Yan ; Jiayu Li ; Masood Mortazavi ; Nitesh V. Chawla
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: However, existing graph prompting techniques are tailored to homogeneous graphs, neglecting the inherent heterogeneity of Web graphs. To bridge this gap, we propose HetGPT, a general post-training prompting framework to improve the predictive performance of pre-trained heterogeneous graph neural networks (HGNNs).

75, TITLE: Causal Understanding of Why Users Share Hate Speech on Social Media
AUTHORS: Dominique Geissler ; Abdurahman Maarouf ; Stefan Feuerriegel
CATEGORY: cs.SI [cs.SI, cs.AI, cs.CY]
HIGHLIGHT: In this paper, we present a comprehensive, causal analysis of the user attributes that make users reshare hate speech.

76, TITLE: YOLO-Angio: An Algorithm for Coronary Anatomy Segmentation
AUTHORS: Tom Liu ; Hui Lin ; Aggelos K. Katsaggelos ; Adrienne Kline
CATEGORY: eess.IV [eess.IV, cs.CV]
HIGHLIGHT: Here, we present our solution to the Automatic Region-based Coronary Artery Disease diagnostics using X-ray angiography images (ARCADE) challenge held at MICCAI 2023.

77, TITLE: A New Approach to Template Banks of Gravitational Waves with Higher Harmonics: Reducing Matched-filtering Cost By Over An Order of Magnitude
AUTHORS: DIGVIJAY WADEKAR et. al.
CATEGORY: gr-qc [gr-qc, astro-ph.HE, astro-ph.IM, cs.AI, cs.LG]
HIGHLIGHT: We use a combination of post-Newtonian formulae and machine learning tools to model aligned-spin $(3,3)$, $(4,4)$ waveforms corresponding to a given $(2,2)$ waveform.

78, TITLE: Posterior Estimation for Dynamic PET Imaging Using Conditional Variational Inference
AUTHORS: XIAOFENG LIU et. al.
CATEGORY: physics.med-ph [physics.med-ph, cs.AI, eess.SP]
HIGHLIGHT: We propose a deep-learning-based framework for efficient posterior estimation.

79, TITLE: Neural Network with Local Converging Input (NNLCI) for Supersonic Flow Problems with Unstructured Grids
AUTHORS: Weiming Ding ; Haoxiang Huang ; Tzu Jung Lee ; Yingjie Liu ; Vigor Yang
CATEGORY: math.NA [math.NA, cs.AI, cs.LG, cs.NA, physics.flu-dyn, 35Q31]
HIGHLIGHT: In the present study, we develop a neural network with local converging input (NNLCI) for high-fidelity prediction using unstructured data.

80, TITLE: Moral Foundations of Large Language Models
AUTHORS: MARWA ABDULHAI et. al.
CATEGORY: cs.AI [cs.AI, cs.CL, cs.CY]
HIGHLIGHT: People vary in the weight they place on these dimensions when making moral decisions, in part due to their cultural upbringing and political ideology. As large language models (LLMs) are trained on datasets collected from the internet, they may reflect the biases that are present in such corpora.

81, TITLE: AI Alignment and Social Choice: Fundamental Limitations and Policy Implications
AUTHORS: Abhilash Mishra
CATEGORY: cs.AI [cs.AI, cs.CL, cs.CY, cs.HC, cs.LG]
HIGHLIGHT: In this paper, we investigate a specific challenge in building RLHF systems that respect democratic norms.

82, TITLE: Systematic AI Approach for AGI: Addressing Alignment, Energy, and AGI Grand Challenges
AUTHORS: Eren Kurshan
CATEGORY: cs.AI [cs.AI, cs.LG]
HIGHLIGHT: We posit that system design is the missing piece in overcoming the grand challenges.We present a Systematic AI Approach for AGI that utilizes system design principles for AGI, while providing ways to overcome the energy wall and the alignment challenges.

83, TITLE: Solving Large Flexible Job Shop Scheduling Instances By Generating A Diverse Set of Scheduling Policies with Deep Reinforcement Learning
AUTHORS: Imanol Echeverria ; Maialen Murua ; Roberto Santana
CATEGORY: cs.AI [cs.AI, cs.LG]
HIGHLIGHT: Nonetheless, there is still room for improvement, particularly in the larger FJSSP instances which are common in real-world scenarios. Therefore, the objective of this paper is to propose a method capable of robustly solving large instances of the FJSSP.

84, TITLE: Learning-based Scheduling for Information Accuracy and Freshness in Wireless Networks
AUTHORS: Hitesh Gudwani
CATEGORY: cs.AI [cs.AI, cs.NI]
HIGHLIGHT: We model our scheduling problem as a variant of the multi-arm bandit problem with sources as different arms.

85, TITLE: Towards Automated Recipe Genre Classification Using Semi-Supervised Learning
AUTHORS: Nazmus Sakib ; G. M. Shahariar ; Md. Mohsinul Kabir ; Md. Kamrul Hasan ; Hasan Mahmud
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this study, we present a dataset named the ``Assorted, Archetypal, and Annotated Two Million Extended (3A2M+) Cooking Recipe Dataset" that contains two million culinary recipes labeled in respective categories with extended named entities extracted from recipe descriptions.

86, TITLE: Let The Pretrained Language Models "Imagine" for Short Texts Topic Modeling
AUTHORS: Pritom Saha Akash ; Jie Huang ; Kevin Chen-Chuan Chang
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we take a new approach to short-text topic modeling to address the data-sparsity issue by extending short text into longer sequences using existing pre-trained language models (PLMs).

87, TITLE: Expression Syntax Information Bottleneck for Math Word Problems
AUTHORS: Jing Xiong ; Chengming Li ; Min Yang ; Xiping Hu ; Bin Hu
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we turn our attention in the opposite direction, and work on how to discard redundant features containing spurious correlations for MWP.

88, TITLE: Beyond Sentiment: Leveraging Topic Metrics for Political Stance Classification
AUTHORS: Weihong Qi
CATEGORY: cs.CL [cs.CL, cs.CY]
HIGHLIGHT: This study introduces topic metrics, dummy variables converted from extracted topics, as both an alternative and complement to sentiment metrics in stance classification.

89, TITLE: Is Probing All You Need? Indicator Tasks As An Alternative to Probing Embedding Spaces
AUTHORS: Tal Levy ; Omer Goldman ; Reut Tsarfaty
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: As a result, contemporary works on probing include tasks that do not involve training of auxiliary models. In this work we introduce the term indicator tasks for non-trainable tasks which are used to query embedding spaces for the existence of certain properties, and claim that this kind of tasks may point to a direction opposite to probes, and that this contradiction complicates the decision on whether a property exists in an embedding space.

90, TITLE: Do Stochastic Parrots Have Feelings Too? Improving Neural Detection of Synthetic Text Via Emotion Recognition
AUTHORS: Alan Cowap ; Yvette Graham ; Jennifer Foster
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: With this in mind, we draw inspiration from psychological studies which suggest that people can be driven by emotion and encode emotion in the text they compose. We hypothesize that pretrained language models (PLMs) have an affective deficit because they lack such an emotional driver when generating text and consequently may generate synthetic text which has affective incoherence i.e. lacking the kind of emotional coherence present in human-authored text.

91, TITLE: How Much Context Does My Attention-Based ASR System Need?
AUTHORS: Robert Flynn ; Anton Ragni
CATEGORY: cs.CL [cs.CL, cs.SD, eess.AS]
HIGHLIGHT: In this work, we examine the effect of scaling the sequence length used to train/evaluate (dense-attention based) acoustic and language models on speech recognition performance.

92, TITLE: Characterizing Mechanisms for Factual Recall in Language Models
AUTHORS: Qinan Yu ; Jack Merullo ; Ellie Pavlick
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: Language Models (LMs) often must integrate facts they memorized in pretraining with new information that appears in a given context.

93, TITLE: A Diffusion Weighted Graph Framework for New Intent Discovery
AUTHORS: WENKAI SHI et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: Without considering structure relationships between samples, previous methods generate noisy supervisory signals which cannot strike a balance between quantity and quality, hindering the formation of new intent clusters and effective transfer of the pre-training knowledge. To mitigate this limitation, we propose a novel Diffusion Weighted Graph Framework (DWGF) to capture both semantic similarities and structure relationships inherent in data, enabling more sufficient and reliable supervisory signals.

94, TITLE: MUSER: A Multi-View Similar Case Retrieval Dataset
AUTHORS: QINGQUAN LI et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this work, we present MUSER, a similar case retrieval dataset based on multi-view similarity measurement and comprehensive legal element with sentence-level legal element annotations.

95, TITLE: NuTrea: Neural Tree Search for Context-guided Multi-hop KGQA
AUTHORS: Hyeong Kyu Choi ; Seunghun Lee ; Jaewon Chu ; Hyunwoo J. Kim
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: To make matters worse, KG nodes often represent proper noun entities and are sometimes encrypted, being uninformative in selecting between paths. To address these problems, we propose Neural Tree Search (NuTrea), a tree search-based GNN model that incorporates the broader KG context.

96, TITLE: Reference Free Domain Adaptation for Translation of Noisy Questions with Question Specific Rewards
AUTHORS: BABAN GAIN et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: Creating a synthetic parallel corpus from such data is also difficult due to its noisy nature. To address this issue, we propose a training methodology that fine-tunes the NMT system only using source-side data.

97, TITLE: Using Artificial French Data to Understand The Emergence of Gender Bias in Transformer Language Models
AUTHORS: Lina Conti ; Guillaume Wisniewski
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: We propose to use an artificial corpus generated by a PCFG based on French to precisely control the gender distribution in the training data and determine under which conditions a model correctly captures gender information or, on the contrary, appears gender-biased.

98, TITLE: CONTRASTE: Supervised Contrastive Pre-training With Aspect-based Prompts For Aspect Sentiment Triplet Extraction
AUTHORS: Rajdeep Mukherjee ; Nithish Kannen ; Saurabh Kumar Pandey ; Pawan Goyal
CATEGORY: cs.CL [cs.CL, cs.AI, I.2.7]
HIGHLIGHT: Instead, our motivation is to come up with a generic approach that can improve the downstream performances of multiple ABSA tasks simultaneously. Towards this, we present CONTRASTE, a novel pre-training strategy using CONTRastive learning to enhance the ASTE performance.

99, TITLE: POE: Process of Elimination for Multiple Choice Reasoning
AUTHORS: Chenkai Ma ; Xinya Du
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: To this end, we present the Process of Elimination (POE), a two-step scoring method.

100, TITLE: Natural Language Processing for Drug Discovery Knowledge Graphs: Promises and Pitfalls
AUTHORS: J. Charles G. Jeynes ; Tim James ; Matthew Corney
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this article, we discuss promises and pitfalls of using natural language processing (NLP) to mine unstructured text typically from scientific literature as a data source for KGs.

101, TITLE: Interpreting Answers to Yes-No Questions in User-Generated Content
AUTHORS: Shivam Mathur ; Keun Hee Park ; Dhivya Chinnappa ; Saketh Kotamraju ; Eduardo Blanco
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we present a new corpus of 4,442 yes-no question-answer pairs from Twitter.

102, TITLE: Visually Grounded Continual Language Learning with Selective Specialization
AUTHORS: Kyra Ahrens ; Lennart Bengtson ; Jae Hee Lee ; Stefan Wermter
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Thus, our aim with this work is to provide an extensive analysis of selection strategies for visually grounded continual language learning.

103, TITLE: Rosetta Stone at KSAA-RD Shared Task: A Hop From Language Modeling To Word--Definition Alignment
AUTHORS: Ahmed ElBakry ; Mohamed Gabr ; Muhammad ElNokrashy ; Badr AlKhamissi
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this work, we present our winning solution for the Arabic Reverse Dictionary shared task.

104, TITLE: SteloCoder: A Decoder-Only LLM for Multi-Language to Python Code Translation
AUTHORS: JIALING PAN et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: However, there is still a need for improvement in code translation functionality with efficient training techniques. In response to this, we introduce SteloCoder, a decoder-only StarCoder-based LLM designed specifically for multi-programming language-to-Python code translation.

105, TITLE: Toward A Critical Toponymy Framework for Named Entity Recognition: A Case Study of Airbnb in New York City
AUTHORS: MIKAEL BRUNILA et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.CY]
HIGHLIGHT: Here, we develop computational methods to measure how cultural and economic capital shape the ways in which people refer to places, through a novel annotated dataset of 47,440 New York City Airbnb listings from the 2010s. Building on this dataset, we introduce a new named entity recognition (NER) model able to identify important discourse categories integral to the characterization of place.

106, TITLE: Career Path Prediction Using Resume Representation Learning and Skill-based Matching
AUTHORS: Jens-Joris Decorte ; Jeroen Van Hautte ; Johannes Deleu ; Chris Develder ; Thomas Demeester
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: We propose leveraging the unexplored textual descriptions that are part of work experience sections in resumes.

107, TITLE: TCRA-LLM: Token Compression Retrieval Augmented Large Language Model for Inference Cost Reduction
AUTHORS: Junyi Liu ; Liangzhi Li ; Tong Xiang ; Bowen Wang ; Yiming Qian
CATEGORY: cs.CL [cs.CL, cs.IR]
HIGHLIGHT: One problem of deploying commercial retrieval-augmented LLMs is the cost due to the additionally retrieved context that largely increases the input token size of the LLMs. To mitigate this, we propose a token compression scheme that includes two methods: summarization compression and semantic compression.

108, TITLE: GPT-4 As An Effective Zero-Shot Evaluator for Scientific Figure Captions
AUTHORS: TING-YAO HSU et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: This paper investigates using large language models (LLMs) as a cost-effective, reference-free method for evaluating figure captions.

109, TITLE: DALE: Generative Data Augmentation for Low-Resource Legal NLP
AUTHORS: SREYAN GHOSH et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: We present DALE, a novel and effective generative Data Augmentation framework for low-resource LEgal NLP.

110, TITLE: Unveiling Multilinguality in Transformer Models: Exploring Language Specificity in Feed-Forward Networks
AUTHORS: Sunit Bhattacharya ; Ondrej Bojar
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: This leads to an incremental process of prediction that gradually converges towards the final token choice near the output layers. This interesting perspective raises questions about how multilingual models might leverage this mechanism.

111, TITLE: EpiK-Eval: Evaluation for Language Models As Epistemic Models
AUTHORS: Gabriele Prato ; Jerry Huang ; Prasannna Parthasarathi ; Shagun Sodhani ; Sarath Chandar
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: Despite their growing prevalence, their capacity to consolidate knowledge from different training documents - a crucial ability in numerous applications - remains unexplored. This paper presents the first study examining the capability of LLMs to effectively combine such information within their parameter space.

112, TITLE: Continual Event Extraction with Semantic Confusion Rectification
AUTHORS: Zitao Wang ; Xinyi Wang ; Wei Hu
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: This paper proposes a novel continual event extraction model with semantic confusion rectification.

113, TITLE: BianQue: Balancing The Questioning and Suggestion Ability of Health LLMs with Multi-turn Health Conversations Polished By ChatGPT
AUTHORS: YIRONG CHEN et. al.
CATEGORY: cs.CL [cs.CL, cs.HC]
HIGHLIGHT: To improve the CoQ of LLMs, we propose BianQue, a ChatGLM-based LLM finetuned with the self-constructed health conversation dataset BianQueCorpus that is consist of multiple turns of questioning and health suggestions polished by ChatGPT.

114, TITLE: Mind The Gap Between Conversations for Improved Long-Term Dialogue Generation
AUTHORS: Qiang Zhang ; Jason Naradowsky ; Yusuke Miyao
CATEGORY: cs.CL [cs.CL, cs.AI, cs.HC]
HIGHLIGHT: In this work we explore the idea of making dialogue models aware of time, and present GapChat, a multi-session dialogue dataset in which the time between each session varies.

115, TITLE: Irreducible Curriculum for Language Model Pretraining
AUTHORS: Simin Fan ; Martin Jaggi
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: It is difficult to apply traditional datapoint selection methods on large language models: most online batch selection methods perform two-times forward or backward passes, which introduces considerable extra costs with large-scale models. To mitigate these obstacles, we propose irreducible curriculum as a curriculum learning algorithm for language model pretraining, which prioritizes samples with higher learnability.

116, TITLE: ScanDL: A Diffusion Model for Generating Synthetic Scanpaths on Texts
AUTHORS: LENA S. BOLLIGER et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Following recent advances in adapting diffusion processes to discrete data, we propose ScanDL, a novel discrete sequence-to-sequence diffusion model that generates synthetic scanpaths on texts.

117, TITLE: Tips for Making The Most of 64-bit Architectures in Langage Design, Libraries or Garbage Collection
AUTHORS: Beno�t Sonntag ; Dominique Colnet
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: The 64-bit architectures that have become standard today offer unprecedented low-level programming possibilities. For the first time in the history of computing, the size of address registers far exceeded the physical capacity of their bus.After a brief reminder of the possibilities offered by the small size of addresses compared to the available 64 bits,we develop three concrete examples of how the vacant bits of these registers can be used.Among these examples, two of them concern the implementation of a library for a new statically typed programming language.Firstly, the implementation of multi-precision integers, with the aim of improving performance in terms of both calculation speed and RAM savings.The second example focuses on the library's handling of UTF-8 character strings.Here, the idea is to make indexing easier by ignoring the physical size of each UTF-8 characters.Finally, the third example is a possible enhancement of garbage collectors, in particular the mark \& sweep for the object marking phase.

118, TITLE: K-HATERS: A Hate Speech Detection Corpus in Korean with Target-Specific Ratings
AUTHORS: Chaewon Park ; Soohwan Kim ; Kyubyong Park ; Kunwoo Park
CATEGORY: cs.CL [cs.CL, cs.SI]
HIGHLIGHT: This study introduces K-HATERS, a new corpus for hate speech detection in Korean, comprising approximately 192K news comments with target-specific offensiveness ratings.

119, TITLE: Why LLMs Hallucinate, and How to Get (Evidential) Closure: Perceptual, Intensional, and Extensional Learning for Faithful Natural Language Generation
AUTHORS: Adam Bouyamourn
CATEGORY: cs.CL [cs.CL, cs.AI, I.2.7]
HIGHLIGHT: We show that LLMs hallucinate because their output is not constrained to be synonymous with claims for which they have evidence: a condition that we call evidential closure.

120, TITLE: TaskDiff: A Similarity Metric for Task-Oriented Conversations
AUTHORS: Ankita Bhaumik ; Praveen Venkateswaran ; Yara Rizk ; Vatche Isahagian
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: While many similarity metrics have been proposed in the literature, they have not proven effective for task-oriented conversations as they do not take advantage of unique conversational features. To address this gap, we present TaskDiff, a novel conversational similarity metric that utilizes different dialogue components (utterances, intents, and slots) and their distributions to compute similarity.

121, TITLE: Adaptive End-to-End Metric Learning for Zero-Shot Cross-Domain Slot Filling
AUTHORS: Yuanjun Shi ; Linzhi Wu ; Minglai Shao
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Considering simplicity, efficiency and generalizability, we present a cascade-style joint learning framework coupled with context-aware soft label representations and slot-level contrastive representation learning to mitigate the data and label shift problems effectively.

122, TITLE: MindLLM: Pre-training Lightweight Large Language Model from Scratch, Evaluations and Domain Applications
AUTHORS: YIZHE YANG et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: While general artificial intelligence is leveraged by developing increasingly large-scale models, there could be another branch to develop lightweight custom models that better serve certain domains, taking into account the high cost of training and deploying LLMs and the scarcity of resources. In this paper, we present MindLLM, a novel series of bilingual lightweight large language models, trained from scratch, alleviating such burdens by offering models with 1.3 billion and 3 billion parameters.

123, TITLE: DeTiME: Diffusion-Enhanced Topic Modeling Using Encoder-decoder Based LLM
AUTHORS: Weijie Xu ; Wenxiang Hu ; Fanyou Wu ; Srinivasan Sengamedu
CATEGORY: cs.CL [cs.CL, cs.AI, 68T50, I.2.7]
HIGHLIGHT: Despite this, NTMs primarily utilize contextual embeddings from LLMs, which are not optimal for clustering or capable for topic generation. Our study addresses this gap by introducing a novel framework named Diffusion-Enhanced Topic Modeling using Encoder-Decoder-based LLMs (DeTiME).

124, TITLE: BLESS: Benchmarking Large Language Models on Sentence Simplification
AUTHORS: TANNON KEW et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We present BLESS, a comprehensive performance benchmark of the most recent state-of-the-art large language models (LLMs) on the task of text simplification (TS).

125, TITLE: Ensemble of Task-Specific Language Models for Brain Encoding
AUTHORS: Sanjai Kumaran ; Arvindh Arun ; Jerrin John
CATEGORY: cs.CL [cs.CL, cs.NE]
HIGHLIGHT: Language models have been shown to be rich enough to encode fMRI activations of certain Regions of Interest in our Brains.

126, TITLE: Mixture of Tokens: Efficient LLMs Through Cross-Example Aggregation
AUTHORS: SZYMON ANTONIAK et. al.
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: Existing techniques designed to address these concerns, such as auxiliary losses or balance-aware matching, result either in lower model performance or are more difficult to train. In response to these issues, we propose Mixture of Tokens, a fully-differentiable model that retains the benefits of MoE architectures while avoiding the aforementioned difficulties.

127, TITLE: Data Augmentation Techniques for Machine Translation of Code-Switched Texts: A Comparative Study
AUTHORS: Injy Hamed ; Nizar Habash ; Ngoc Thang Vu
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this work, we compare three popular approaches: lexical replacements, linguistic theories, and back-translation (BT), in the context of Egyptian Arabic-English CSW.

128, TITLE: RAPL: A Relation-Aware Prototype Learning Approach for Few-Shot Document-Level Relation Extraction
AUTHORS: SHIAO MENG et. al.
CATEGORY: cs.CL [cs.CL, 68T50, I.2.7]
HIGHLIGHT: In this paper, we propose a relation-aware prototype learning method for FSDLRE to strengthen the relational semantics of prototype representations.

129, TITLE: In-Context Learning Creates Task Vectors
AUTHORS: Roee Hendel ; Mor Geva ; Amir Globerson
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In particular, it is challenging to map it to the "standard" machine learning framework, where one uses a training set $S$ to find a best-fitting function $f(x)$ in some hypothesis class. Here we make progress on this problem by showing that the functions learned by ICL often have a very simple structure: they correspond to the transformer LLM whose only inputs are the query $x$ and a single "task vector" calculated from the training set.

130, TITLE: Accented Speech Recognition With Accent-specific Codebooks
AUTHORS: Darshan Prabhu ; Preethi Jyothi ; Sriram Ganapathy ; Vinit Unni
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: In this work, we propose a novel accent adaptation approach for end-to-end ASR systems using cross-attention with a trainable set of codebooks.

131, TITLE: Failures Pave The Way: Enhancing Large Language Models Through Tuning-free Rule Accumulation
AUTHORS: Zeyuan Yang ; Peng Li ; Yang Liu
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this work, we propose our Tuning-free Rule Accumulation (TRAN) framework, which guides LLMs in improving their performance by learning from previous mistakes.

132, TITLE: Integrating Language Models Into Direct Speech Translation: An Inference-Time Solution to Control Gender Inflection
AUTHORS: DENNIS FUCCI et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: The existing solutions to do so, though effective, are hardly feasible in practice as they involve dedicated model re-training on gender-labeled ST data. To overcome these limitations, we propose the first inference-time solution to control speaker-related gender inflections in ST. Our approach partially replaces the (biased) internal language model (LM) implicitly learned by the ST decoder with gender-specific external LMs.

133, TITLE: Exploring The Potential of Large Language Models in Generating Code-Tracing Questions for Introductory Programming Courses
AUTHORS: Aysa Xuemo Fan ; Ranran Haoran Zhang ; Luc Paquette ; Rui Zhang
CATEGORY: cs.CL [cs.CL, cs.CY]
HIGHLIGHT: In this paper, we explore the application of large language models (LLMs) for generating code-tracing questions in introductory programming courses.

134, TITLE: Learning From Free-Text Human Feedback -- Collect New Datasets Or Extend Existing Ones?
AUTHORS: Dominic Petrak ; Nafise Sadat Moosavi ; Ye Tian ; Nikolai Rozanov ; Iryna Gurevych
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: However, to assess the feasibility of such an effort, it is important to know the types and frequency of free-text human feedback included in these datasets. In this work, we investigate this question for a variety of commonly used dialog datasets, including MultiWoZ, SGD, BABI, PersonaChat, Wizards-of-Wikipedia, and the human-bot split of the Self-Feeding Chatbot.

135, TITLE: Fighting Fire with Fire: The Dual Role of LLMs in Crafting and Detecting Elusive Disinformation
AUTHORS: JASON LUCAS et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: i.e, generating large-scale harmful and misleading content). To combat this emerging risk of LLMs, we propose a novel "Fighting Fire with Fire" (F3) strategy that harnesses modern LLMs' generative and emergent reasoning capabilities to counter human-written and LLM-generated disinformation.

136, TITLE: MuLMS: A Multi-Layer Annotated Text Corpus for Information Extraction in The Materials Science Domain
AUTHORS: Timo Pierre Schrader ; Matteo Finco ; Stefan Gr�newald ; Felix Hildebrand ; Annemarie Friedrich
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: However, these datasets focus on sub-problems such as parsing synthesis procedures or on sub-domains, e.g., solid oxide fuel cells. In this resource paper, we present MuLMS, a new dataset of 50 open-access articles, spanning seven sub-domains of materials science.

137, TITLE: G2-MonoDepth: A General Framework of Generalized Depth Inference from Monocular RGB+X Data
AUTHORS: Haotian Wang ; Meng Yang ; Nanning Zheng
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: This paper investigates a unified task of monocular depth inference, which infers high-quality depth maps from all kinds of input raw data from various robots in unseen scenes.

138, TITLE: Leveraging Vision-Centric Multi-Modal Expertise for 3D Object Detection
AUTHORS: LINYAN HUANG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: To this end, we introduce VCD, a framework to improve the camera-only apprentice model, including an apprentice-friendly multi-modal expert and temporal-fusion-friendly distillation supervision.

139, TITLE: Salient Object Detection in RGB-D Videos
AUTHORS: AO MOU et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In pursuit of effective feature enhancement, refinement, and fusion for precise final prediction, we propose two modules: the multi-modal attention module (MAM) and the refinement fusion module (RFM).

140, TITLE: Automatic Aorta Segmentation with Heavily Augmented, High-Resolution 3-D ResUNet: Contribution to The SEG.A Challenge
AUTHORS: Marek Wodzinski ; Henning M�ller
CATEGORY: cs.CV [cs.CV, cs.AI, cs.LG]
HIGHLIGHT: We propose a fully automated algorithm based on deep encoder-decoder architecture.

141, TITLE: SequenceMatch: Revisiting The Design of Weak-strong Augmentations for Semi-supervised Learning
AUTHORS: Khanh-Binh Nguyen
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: However, one issue that many SSL methods face is the confirmation bias, which occurs when the model is overfitted to the small labeled training dataset and produces overconfident, incorrect predictions. To address this issue, we propose SequenceMatch, an efficient SSL method that utilizes multiple data augmentations.

142, TITLE: Mean Teacher DETR with Masked Feature Alignment: A Robust Domain Adaptive Detection Transformer Framework
AUTHORS: Weixi Weng ; Chun Yuan
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Methods mentioned above have not yet explore how to utilize the third related domain such as target-like domain to assist adaptation. To address these issues, we propose a two-stage framework named MTM, i.e. Mean Teacher-DETR with Masked Feature Alignment.

143, TITLE: SAM-CLIP: Merging Vision Foundation Models Towards Semantic and Spatial Understanding
AUTHORS: HAOXIANG WANG et. al.
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: In this work, we introduce a simple recipe to efficiently merge VFMs into a unified model that assimilates their expertise.

144, TITLE: Deep Integrated Explanations
AUTHORS: OREN BARKAN et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: This paper presents Deep Integrated Explanations (DIX) - a universal method for explaining vision models.

145, TITLE: Breaking of Brightness Consistency in Optical Flow with A Lightweight CNN Network
AUTHORS: Yicheng Lin ; Shuo Wang ; Yunlong Jiang ; Bin Han
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this work, a lightweight network is used to extract illumination robust convolutional features and corners with strong invariance.

146, TITLE: Remote Heart Rate Monitoring in Smart Environments from Videos with Self-supervised Pre-training
AUTHORS: Divij Gupta ; Ali Etemad
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: To address this issue, self-supervised learning has emerged as a promising avenue. Building on this, we introduce a solution that utilizes self-supervised contrastive learning for the estimation of remote photoplethysmography (PPG) and heart rate monitoring, thereby reducing the dependence on labeled data and enhancing performance.

147, TITLE: CVPR 2023 Text Guided Video Editing Competition
AUTHORS: JAY ZHANGJIE WU et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper we present a retrospective on the competition and describe the winning method.

148, TITLE: Visual Cropping Improves Zero-Shot Question Answering of Multimodal Large Language Models
AUTHORS: Jiarui Zhang ; Mahyar Khayatkhoei ; Prateek Chhikara ; Filip Ilievski
CATEGORY: cs.CV [cs.CV, cs.CL]
HIGHLIGHT: In this work, we investigate whether multimodal LLMs can perceive small details as well as large details in images.

149, TITLE: From Posterior Sampling to Meaningful Diversity in Image Restoration
AUTHORS: Noa Cohen ; Hila Manor ; Yuval Bahat ; Tomer Michaeli
CATEGORY: cs.CV [cs.CV, cs.LG, eess.IV]
HIGHLIGHT: In this paper, we initiate the study of meaningfully diverse image restoration.

150, TITLE: Nighttime Thermal Infrared Image Colorization with Feedback-based Object Appearance Learning
AUTHORS: FU-YA LUO et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Despite the impressive progress made in the NTIR2DC task, how to improve the translation performance of small object classes is under-explored. To address this problem, we propose a generative adversarial network incorporating feedback-based object appearance learning (FoalGAN).

151, TITLE: Learning with Noisy Labels Using Collaborative Sample Selection and Contrastive Semi-Supervised Learning
AUTHORS: QING MIAO et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: This mixture of clean and noisy samples leads to misguidance in DNN training during SSL, resulting in impaired generalization performance due to confirmation bias caused by error accumulation in sample selection. To address this issue, we propose a method called Collaborative Sample Selection (CSS), which leverages the large-scale pre-trained model CLIP.

152, TITLE: 3D Masked Autoencoders for Enhanced Privacy in MRI Scans
AUTHORS: Lennart Alexander Van der Goten ; Kevin Smith
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: In this work, we propose CP-MAE, a model that de-identifies the face using masked autoencoders and that outperforms all previous approaches in terms of downstream task performance as well as de-identification.

153, TITLE: Vision-Language Pseudo-Labels for Single-Positive Multi-Label Learning
AUTHORS: XIN XING et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: This paper presents a novel approach to Single-Positive Multi-label Learning.

154, TITLE: Query-adaptive DETR for Crowded Pedestrian Detection
AUTHORS: Feng Gao ; Jiaxu Leng ; Ji Gan ; Xinbo Gao
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Based on the predicted rank, we design an adaptive selection method that can adaptively select coarse detection results produced by the encoder to generate queries.

155, TITLE: Interpretable Medical Image Classification Using Prototype Learning and Privileged Information
AUTHORS: Luisa Gallee ; Meinrad Beer ; Michael Goetz
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this work, we investigate whether additional information available during the training process can be used to create an understandable and powerful model.

156, TITLE: Mitigate Domain Shift By Primary-Auxiliary Objectives Association for Generalizing Person ReID
AUTHORS: Qilei Li ; Shaogang Gong
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We consider that a deep learning model is heavily influenced and therefore biased towards domain-specific characteristics, e.g., background clutter, scale and viewpoint variations, limiting the generalizability of the learned model, and hypothesize that the pedestrians are domain invariant owning they share the same structural characteristics. To enable the ReID model to be less domain-specific from these pure pedestrians, we introduce a method that guides model learning of the primary ReID instance classification objective by a concurrent auxiliary learning objective on weakly labeled pedestrian saliency detection.

157, TITLE: Cross-view Self-localization from Synthesized Scene-graphs
AUTHORS: Ryogo Yamamoto ; Kanji Tanaka
CATEGORY: cs.CV [cs.CV, cs.RO]
HIGHLIGHT: In this study, we explore a new hybrid scene model that combines the advantages of view-invariant appearance features computed from raw images and view-dependent spatial-semantic features computed from synthesized images.

158, TITLE: Language-driven Scene Synthesis Using Multi-conditional Diffusion Model
AUTHORS: AN VUONG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we propose a language-driven scene synthesis task, which is a new task that integrates text prompts, human motion, and existing objects for scene synthesis.

159, TITLE: ShARc: Shape and Appearance Recognition for Person Identification In-the-wild
AUTHORS: Haidong Zhu ; Wanrong Zheng ; Zhaoheng Zheng ; Ram Nevatia
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we present ShARc, a multimodal approach for video-based person identification in uncontrolled environments that emphasizes 3-D body shape, pose, and appearance.

160, TITLE: GNeSF: Generalizable Neural Semantic Fields
AUTHORS: Hanlin Chen ; Chen Li ; Mengqi Guo ; Zhiwen Yan ; Gim Hee Lee
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: However, existing approaches still requires expensive per-scene optimization that prohibits generalization to novel scenes during inference. To circumvent this problem, we introduce a generalizable 3D segmentation framework based on implicit representation.

161, TITLE: Videoprompter: An Ensemble of Foundational Models for Zero-shot Video Understanding
AUTHORS: Adeel Yousaf ; Muzammal Naseer ; Salman Khan ; Fahad Shahbaz Khan ; Mubarak Shah
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we propose a framework which combines pre-trained discriminative VLMs with pre-trained generative video-to-text and text-to-text models.

162, TITLE: I$^2$MD: 3D Action Representation Learning with Inter- and Intra-modal Mutual Distillation
AUTHORS: YUNYAO MAO et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this work, we tackle the aforementioned problems by introducing a general Inter- and Intra-modal Mutual Distillation (I$^2$MD) framework.

163, TITLE: Debiasing, Calibrating, and Improving Semi-supervised Learning Performance Via Simple Ensemble Projector
AUTHORS: Khanh-Binh Nguyen
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: In this paper, we propose a simple method named Ensemble Projectors Aided for Semi-supervised Learning (EPASS), which focuses mainly on improving the learned embeddings to boost the performance of the existing contrastive joint-training semi-supervised learning frameworks.

164, TITLE: SecV: Secure Code Partitioning Via Multi-Language Secure Values
AUTHORS: PETERSON YUHALA et. al.
CATEGORY: cs.CR [cs.CR, cs.PL]
HIGHLIGHT: They cannot be reused for other languages and there is thus a need for tools that transcend this language barrier. We address this challenge by proposing a multi-language technique to specify sensitive code or data, as well as a multi-language tool to analyse and partition the resulting programs for trusted execution environments like Intel SGX.

165, TITLE: Facial Data Minimization: Shallow Model As Your Privacy Filter
AUTHORS: YUWEN PU et. al.
CATEGORY: cs.CR [cs.CR, cs.CV]
HIGHLIGHT: Hence, in this paper, by fully considering two cases of uploading facial images and facial features, which are very typical in face recognition service systems, we proposed a data privacy minimization transformation (PMT) method.

166, TITLE: Semantic Data Management in Data Lakes
AUTHORS: Sayed Hoseini ; Johannes Theissen-Lipp ; Christoph Quix
CATEGORY: cs.DB [cs.DB, cs.AI, cs.CL, cs.HC]
HIGHLIGHT: In each category, we cover the main techniques and their background, and compare latest research.

167, TITLE: DeepIron: Predicting Unwarped Garment Texture from A Single Image
AUTHORS: Hyun-Song Kwon ; Sung-Hee Lee
CATEGORY: cs.GR [cs.GR, cs.CV]
HIGHLIGHT: This paper presents a novel framework that reconstructs the texture map for 3D garments from a single image with pose.

168, TITLE: PromptInfuser: How Tightly Coupling AI and UI Design Impacts Designers' Workflows
AUTHORS: Savvas Petridis ; Michael Terry ; Carrie J. Cai
CATEGORY: cs.HC [cs.HC, cs.AI]
HIGHLIGHT: We investigate how coupling prompt and UI design affects designers' workflows.

169, TITLE: Facilitating Self-Guided Mental Health Interventions Through Human-Language Model Interaction: A Case Study of Cognitive Restructuring
AUTHORS: Ashish Sharma ; Kevin Rushton ; Inna Wanyin Lin ; Theresa Nguyen ; Tim Althoff
CATEGORY: cs.HC [cs.HC, cs.CL]
HIGHLIGHT: In this paper, we study how human-language model interaction can support self-guided mental health interventions.

170, TITLE: Robust Representation Learning for Unified Online Top-K Recommendation
AUTHORS: MINFANG LU et. al.
CATEGORY: cs.IR [cs.IR, cs.AI]
HIGHLIGHT: The existence of redundant information across different domains introduces interference and competition among experts, while the distinct learning objectives of each domain lead to varying optimization challenges among experts. To tackle these issues, we propose robust representation learning for the unified online top-k recommendation.

171, TITLE: Topology-aware Debiased Self-supervised Graph Learning for Recommendation
AUTHORS: Lei Han ; Hui Yan ; Zhicheng Qiao
CATEGORY: cs.IR [cs.IR, cs.AI]
HIGHLIGHT: However, the random negative sampling strategy in these GCL-based CF models neglects the semantic structure of users (items), which not only introduces false negatives (negatives that are similar to anchor user (item)) but also ignores the potential positive samples. To tackle the above issues, we propose Topology-aware Debiased Self-supervised Graph Learning (TDSGL) for recommendation, which constructs contrastive pairs according to the semantic similarity between users (items).

172, TITLE: Recurrent Linear Transformers
AUTHORS: Subhojeet Pramanik ; Esraa Elelimy ; Marlos C. Machado ; Adam White
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: In this paper we introduce recurrent alternatives to the transformer self-attention mechanism that offer a context-independent inference cost, leverage long-range dependencies effectively, and perform well in practice.

173, TITLE: Physics-Informed with Power-Enhanced Residual Network for Interpolation and Inverse Problems
AUTHORS: Amir Noorizadegan ; D. L. Young ; Y. C. Hon ; C. S. Chen
CATEGORY: cs.LG [cs.LG, cs.CV, math.AP]
HIGHLIGHT: This paper introduces a novel neural network structure called the Power-Enhancing residual network, designed to improve interpolation capabilities for both smooth and non-smooth functions in 2D and 3D settings.

174, TITLE: Nominality Score Conditioned Time Series Anomaly Detection By Point/Sequential Reconstruction
AUTHORS: Chih-Yu Lai ; Fan-Keng Sun ; Zhengqi Gao ; Jeffrey H. Lang ; Duane S. Boning
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: In this paper, we propose a framework for unsupervised time series anomaly detection that utilizes point-based and sequence-based reconstruction models.

175, TITLE: Fractal Landscapes in Policy Optimization
AUTHORS: Tao Wang ; Sylvia Herbert ; Sicun Gao
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: Despite much success, it is often observed in practice that RL training with policy gradient can fail for many reasons, even on standard control problems with known solutions. We propose a framework for understanding one inherent limitation of the policy gradient approach: the optimization landscape in the policy space can be extremely non-smooth or fractal for certain classes of MDPs, such that there does not exist gradient to be estimated in the first place.

176, TITLE: On Responsible Machine Learning Datasets with Fairness, Privacy, and Regulatory Norms
AUTHORS: SURBHI MITTAL et. al.
CATEGORY: cs.LG [cs.LG, cs.CV]
HIGHLIGHT: In this study, we discuss the importance of Responsible Machine Learning Datasets and propose a framework to evaluate the datasets through a responsible rubric.

177, TITLE: Using Slisemap to Interpret Physical Data
AUTHORS: Lauri Sepp�l�inen ; Anton Bj�rklund ; Vitus Besel ; Kai Puolam�ki
CATEGORY: cs.LG [cs.LG, cs.AI, cs.HC]
HIGHLIGHT: In this paper we apply a recently introduced manifold visualisation method, called Slise, on datasets from physics and chemistry.

178, TITLE: VMAF Re-implementation on PyTorch: Some Experimental Results
AUTHORS: Kirill Aistov ; Maxim Koroteev
CATEGORY: cs.LG [cs.LG, cs.CV]
HIGHLIGHT: Based on the standard VMAF implementation we propose an implementation of VMAF using PyTorch framework.

179, TITLE: Discriminator Guidance for Autoregressive Diffusion Models
AUTHORS: Filip Ekstr�m Kelvinius ; Fredrik Lindsten
CATEGORY: cs.LG [cs.LG, cs.AI, stat.ML]
HIGHLIGHT: We introduce discriminator guidance in the setting of Autoregressive Diffusion Models.

180, TITLE: Empowering Distributed Solutions in Renewable Energy Systems and Grid Optimization
AUTHORS: Mohammad Mohammadi ; Ali Mohammadi
CATEGORY: cs.LG [cs.LG, cs.AI, cs.SY, eess.SY]
HIGHLIGHT: The research investigates various ML applications within the realms of solar energy, wind energy, and electric distribution and storage, illustrating their potential to optimize energy systems.

181, TITLE: Improving Generalization in Large Language Models By Learning Prefix Subspaces
AUTHORS: Louis Falissard ; Vincent Guigue ; Laure Soulier
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CL]
HIGHLIGHT: We propose a method to increase the generalization capabilities of LLMs based on neural network subspaces.

182, TITLE: Finetuning Offline World Models in The Real World
AUTHORS: Yunhai Feng ; Nicklas Hansen ; Ziyan Xiong ; Chandramouli Rajagopalan ; Xiaolong Wang
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CV, cs.RO]
HIGHLIGHT: In this work, we seek to get the best of both worlds: we consider the problem of pretraining a world model with offline data collected on a real robot, and then finetuning the model on online data collected by planning with the learned model.

183, TITLE: What Algorithms Can Transformers Learn? A Study in Length Generalization
AUTHORS: HATTIE ZHOU et. al.
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CL, stat.ML]
HIGHLIGHT: Here, we propose a unifying framework to understand when and how Transformers can exhibit strong length generalization on a given task.

184, TITLE: DoGE: Domain Reweighting with Generalization Estimation
AUTHORS: Simin Fan ; Matteo Pagliardini ; Martin Jaggi
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CL]
HIGHLIGHT: However, current methods lack a principled way to optimize domain weights for ultimate goal for generalization. We propose DOmain reweighting with Generalization Estimation (DoGE), where we reweigh the sampling probability from each domain based on its contribution to the final generalization objective assessed by a gradient-based generalization estimation function.

185, TITLE: Detecting Intentional AIS Shutdown in Open Sea Maritime Surveillance Using Self-Supervised Deep Learning
AUTHORS: PIERRE BERNAB� et. al.
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: This paper presents a novel approach for the detection of abnormal AIS missing reception based on self-supervised deep learning techniques and transformer models.

186, TITLE: KirchhoffNet: A Circuit Bridging Message Passing and Continuous-Depth Models
AUTHORS: Zhengqi Gao ; Fan-Keng Sun ; Duane S. Boning
CATEGORY: cs.LG [cs.LG, cs.AI, cs.AR]
HIGHLIGHT: In this paper, we exploit a fundamental principle of analog electronic circuitry, Kirchhoff's current law, to introduce a unique class of neural network models that we refer to as KirchhoffNet.

187, TITLE: E-Sparse: Boosting The Large Language Model Inference Through Entropy-based N:M Sparsity
AUTHORS: YUN LI et. al.
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CL]
HIGHLIGHT: For the first time, we introduce the information entropy of hidden state features into a pruning metric design, namely E-Sparse, to improve the accuracy of N:M sparsity on LLM.

188, TITLE: Improving Robustness and Reliability in Medical Image Classification with Latent-Guided Diffusion and Nested-Ensembles
AUTHORS: Xing Shen ; Hengguan Huang ; Brennan Nichyporuk ; Tal Arbel
CATEGORY: cs.LG [cs.LG, cs.CV]
HIGHLIGHT: In this paper, we introduce a novel three-stage approach based on transformers coupled with conditional diffusion models, with the goal of improving model robustness to the kinds of imaging variability commonly encountered in practice without the need for pre-determined data augmentation strategies.

189, TITLE: Serverless Federated Learning with Flwr-serverless
AUTHORS: Sanjeev V. Namjoshi ; Reese Green ; Krishi Sharma ; Zhangzhang Si
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: However, to date, Flower is only able to run synchronous federated learning which can be costly and time-consuming to run because the process is bottlenecked by client-side training jobs that are slow or fragile. Here, we introduce \texttt{flwr-serverless}, a wrapper around the Flower package that extends its functionality to allow for both synchronous and asynchronous federated learning with minimal modification to Flower's design paradigm.

190, TITLE: A Pure Demand Operational Semantics With Applications to Program Analysis
AUTHORS: Scott Smith ; Robert Zhang
CATEGORY: cs.PL [cs.PL]
HIGHLIGHT: We both give a formal definition of the analysis and describe our current implementation.

191, TITLE: TagE: Enabling An Embodied Agent to Understand Human Instructions
AUTHORS: Chayan Sarkar ; Avik Mitra ; Pradip Pramanick ; Tapas Nayak
CATEGORY: cs.RO [cs.RO, cs.AI, cs.LG]
HIGHLIGHT: The inherent ambiguity and incompleteness inherent in natural language present challenges for intelligent agents striving to decipher human intention. To tackle this predicament head-on, we introduce a novel system known as task and argument grounding for Embodied agents (tagE).

192, TITLE: Human-in-the-Loop Task and Motion Planning for Imitation Learning
AUTHORS: Ajay Mandlekar ; Caelan Garrett ; Danfei Xu ; Dieter Fox
CATEGORY: cs.RO [cs.RO, cs.AI, cs.CV, cs.LG]
HIGHLIGHT: In this paper, we present Human-in-the-Loop Task and Motion Planning (HITL-TAMP), a novel system that leverages the benefits of both approaches.

193, TITLE: ConvBKI: Real-Time Probabilistic Semantic Mapping Network with Quantifiable Uncertainty
AUTHORS: JOEY WILSON et. al.
CATEGORY: cs.RO [cs.RO, cs.CV]
HIGHLIGHT: In this paper, we develop a modular neural network for real-time semantic mapping in uncertain environments, which explicitly updates per-voxel probabilistic distributions within a neural network layer.

194, TITLE: SyncFusion: Multimodal Onset-synchronized Video-to-Audio Foley Synthesis
AUTHORS: MARCO COMUNIT� et. al.
CATEGORY: cs.SD [cs.SD, cs.CV, cs.LG, cs.MM, eess.AS]
HIGHLIGHT: We propose a system to extract repetitive actions onsets from a video, which are then used - in conjunction with audio or textual embeddings - to condition a diffusion model trained to generate a new synchronized sound effects audio track.

195, TITLE: The Mason-Alberta Phonetic Segmenter: A Forced Alignment System Based on Deep Neural Networks and Interpolation
AUTHORS: Matthew C. Kelley ; Scott James Perry ; Benjamin V. Tucker
CATEGORY: eess.AS [eess.AS, cs.CL, cs.LG, cs.SD]
HIGHLIGHT: In the present paper, we describe a new neural network-based forced alignment system, the Mason-Alberta Phonetic Segmenter (MAPS).

196, TITLE: Towards Contrast-agnostic Soft Segmentation of The Spinal Cord
AUTHORS: SANDRINE B�DARD et. al.
CATEGORY: eess.IV [eess.IV, cs.CV]
HIGHLIGHT: In this work, we present a deep learning-based method that produces soft segmentations of the spinal cord.

197, TITLE: PET Synthesis Via Self-supervised Adaptive Residual Estimation Generative Adversarial Network
AUTHORS: YUXIN XUE et. al.
CATEGORY: eess.IV [eess.IV, cs.CV, cs.LG]
HIGHLIGHT: We introduce (1) An adaptive residual estimation mapping mechanism, AE-Net, designed to dynamically rectify the preliminary synthesized PET images by taking the residual map between the low-dose PET and synthesized output as the input, and (2) A self-supervised pre-training strategy to enhance the feature representation of the coarse generator.

198, TITLE: Vicinal Feature Statistics Augmentation for Federated 3D Medical Volume Segmentation
AUTHORS: YONGSONG HUANG et. al.
CATEGORY: eess.IV [eess.IV, cs.AI, cs.CV, cs.LG, physics.med-ph]
HIGHLIGHT: In this work, we aim to develop a vicinal feature-level data augmentation (VFDA) scheme to efficiently alleviate the local feature shift and facilitate collaborative training for privacy-aware FL segmentation.

199, TITLE: DeepVox and SAVE-CT: A Contrast- and Dose-independent 3D Deep Learning Approach for Thoracic Aorta Segmentation and Aneurysm Prediction Using Computed Tomography Scans
AUTHORS: MATHEUS DEL-VALLE et. al.
CATEGORY: eess.IV [eess.IV, cs.CV, cs.LG, I.2; I.4]
HIGHLIGHT: In this study, it was selected 587 unique CT scans including control and TAA patients, acquired with low and standard dose protocols, with or without contrast enhancement.
