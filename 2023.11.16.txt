1, TITLE: Towards Evaluating AI Systems for Moral Status Using Self-Reports
AUTHORS: Ethan Perez ; Robert Long
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CL]
HIGHLIGHT: To make self-reports more appropriate for this purpose, we propose to train models to answer many kinds of questions about themselves with known answers, while avoiding or limiting training incentives that bias self-reports.

2, TITLE: 2D-RC: Two-Dimensional Neural Network Approach for OTFS Symbol Detection
AUTHORS: Jiarui Xu ; Karim Said ; Lizhong Zheng ; Lingjia Liu
CATEGORY: eess.SP [eess.SP, cs.AI, cs.LG]
HIGHLIGHT: This paper introduces a novel two-dimensional RC (2D-RC) method that incorporates the structural knowledge of the OTFS system into the design for online symbol detection on a subframe basis.

3, TITLE: ACID: Abstractive, Content-Based IDs for Document Retrieval with Language Models
AUTHORS: Haoxin Li ; Phillip Keung ; Daniel Cheng ; Jungo Kasai ; Noah A. Smith
CATEGORY: cs.CL [cs.CL, cs.IR]
HIGHLIGHT: We introduce ACID, in which each document's ID is composed of abstractive keyphrases generated by a large language model, rather than an integer ID sequence as done in past work.

4, TITLE: Asking More Informative Questions for Grounded Retrieval
AUTHORS: Sedrick Keh ; Justin T. Chiu ; Daniel Fried
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We present an approach that formulates more informative, open-ended questions.

5, TITLE: Social Meme-ing: Measuring Linguistic Variation in Memes
AUTHORS: Naitian Zhou ; David Jurgens ; David Bamman
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we argue that memes, as multimodal forms of language comprised of visual templates and text, also exhibit meaningful social variation.

6, TITLE: AbsPyramid: Benchmarking The Abstraction Ability of Language Models with A Unified Entailment Graph
AUTHORS: ZHAOWEI WANG et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this paper, we present AbsPyramid, a unified entailment graph of 221K textual descriptions of abstraction knowledge.

7, TITLE: DEED: Dynamic Early Exit on Decoder for Accelerating Encoder-Decoder Transformer Models
AUTHORS: PENG TANG et. al.
CATEGORY: cs.CV [cs.CV, cs.CL, cs.LG]
HIGHLIGHT: To accelerate the inference, we propose an approach of performing Dynamic Early Exit on Decoder (DEED).

8, TITLE: Exploring The Potential of Large Language Models in Computational Argumentation
AUTHORS: Guizhen Chen ; Liying Cheng ; Luu Anh Tuan ; Lidong Bing
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: This work aims to embark on an assessment of LLMs, such as ChatGPT, Flan models and LLaMA2 models, under zero-shot and few-shot settings within the realm of computational argumentation.

9, TITLE: Jailbreaking GPT-4V Via Self-Adversarial Attacks with System Prompts
AUTHORS: Yuanwei Wu ; Xiang Li ; Yixin Liu ; Pan Zhou ; Lichao Sun
CATEGORY: cs.CR [cs.CR, cs.AI, cs.LG]
HIGHLIGHT: Through carefully designed dialogue, we successfully steal the internal system prompts of GPT-4V. This finding indicates potential exploitable security risks in MLLMs; 2)Based on the acquired system prompts, we propose a novel MLLM jailbreaking attack method termed SASP (Self-Adversarial Attack via System Prompt).

10, TITLE: Single-Image 3D Human Digitization with Shape-Guided Diffusion
AUTHORS: BADOUR ALBAHAR et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We present an approach to generate a 360-degree view of a person with a consistent, high-resolution appearance from a single input image.

11, TITLE: Navigating The Ocean of Biases: Political Bias Attribution in Language Models Via Causal Structures
AUTHORS: David F. Jenny ; Yann Billeter ; Mrinmaya Sachan ; Bernhard Sch�lkopf ; Zhijing Jin
CATEGORY: cs.CL [cs.CL, cs.AI, cs.CY, cs.SI]
HIGHLIGHT: In this study, we undertake an exploration of decision-making processes and inherent biases within LLMs, exemplified by ChatGPT, specifically contextualizing our analysis within political debates.

12, TITLE: How Well Do Large Language Models Truly Ground?
AUTHORS: HYUNJI LEE et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: Yet, previous research is often confined to a narrow view of the term "grounding", often only focusing on whether the response contains the correct answer or not, which does not ensure the reliability of the entire response. To address this limitation, we introduce a strict definition of grounding: a model is considered truly grounded when its responses (1) fully utilize necessary knowledge from the provided context, and (2) don't exceed the knowledge within the contexts.

13, TITLE: Parameter-Efficient Multilingual Summarisation: An Empirical Study
AUTHORS: CHENXI WHITEHOUSE et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: This paper investigates the potential of Parameter-Efficient Fine-Tuning, focusing on Low-Rank Adaptation (LoRA), for complex and under-explored multilingual summarisation tasks.

14, TITLE: Correlation-guided Query-Dependency Calibration in Video Representation Learning for Temporal Grounding
AUTHORS: WonJun Moon ; Sangeek Hyun ; SuBeen Lee ; Jae-Pil Heo
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, our goal is to provide clues for query-associated video clips within the crossmodal encoding process.

15, TITLE: R-Spin: Efficient Speaker and Noise-invariant Representation Learning with Acoustic Pieces
AUTHORS: Heng-Jui Chang ; James Glass
CATEGORY: cs.CL [cs.CL, cs.SD, eess.AS]
HIGHLIGHT: This paper introduces Robust Spin (R-Spin), a data-efficient self-supervised fine-tuning framework for speaker and noise-invariant speech representations by learning discrete acoustic units with speaker-invariant clustering (Spin).

16, TITLE: Factcheck-GPT: End-to-End Fine-Grained Document-Level Fact-Checking and Correction of LLM Output
AUTHORS: YUXIA WANG et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this work, we present a holistic end-to-end solution for annotating the factuality of LLM-generated responses, which encompasses a multi-stage annotation scheme designed to yield detailed labels concerning the verifiability and factual inconsistencies found in LLM outputs.

17, TITLE: Aligning Neural Machine Translation Models: Human Feedback in Training and Inference
AUTHORS: Miguel Moura Ramos ; Patrick Fernandes ; Ant�nio Farinhas ; Andr� F. T. Martins
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this study, we comprehensively explore and compare techniques for integrating quality metrics as reward models into the MT pipeline.

18, TITLE: Towards Verifiable Text Generation with Symbolic References
AUTHORS: LUCAS TORROBA HENNIGEN et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: This paper proposes symbolically grounded generation (SymGen) as a simple approach for enabling easier validation of an LLM's output.

19, TITLE: Routing to The Expert: Efficient Reward-guided Ensemble of Large Language Models
AUTHORS: KEMING LU et. al.
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: We propose Zooter, a reward-guided routing method distilling rewards on training queries to train a routing function, which can precisely distribute each query to the LLM with expertise about it.

20, TITLE: When Is Multilinguality A Curse? Language Modeling for 250 High- and Low-Resource Languages
AUTHORS: Tyler A. Chang ; Catherine Arnett ; Zhuowen Tu ; Benjamin K. Bergen
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Multilingual language models are widely used to extend NLP systems to low-resource languages.

21, TITLE: Defending Large Language Models Against Jailbreaking Attacks Through Goal Prioritization
AUTHORS: Zhexin Zhang ; Junxiao Yang ; Pei Ke ; Minlie Huang
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: To counter jailbreaking attacks, we propose to integrate goal prioritization at both training and inference stages.

22, TITLE: MAVEN-Arg: Completing The Puzzle of All-in-One Event Understanding Dataset with Event Argument Annotation
AUTHORS: XIAOZHI WANG et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we introduce MAVEN-Arg, which augments MAVEN datasets with event argument annotations, making the first all-in-one dataset supporting event detection, event argument extraction (EAE), and event relation extraction.

23, TITLE: When Does In-context Learning Fall Short and Why? A Study on Specification-Heavy Tasks
AUTHORS: HAO PENG et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this paper, we find that ICL falls short of handling specification-heavy tasks, which are tasks with complicated and extensive task specifications, requiring several hours for ordinary humans to master, such as traditional information extraction tasks.

24, TITLE: Grounding or Guesswork? Large Language Models Are Presumptive Grounders
AUTHORS: OMAR SHAIKH et. al.
CATEGORY: cs.CL [cs.CL, cs.HC]
HIGHLIGHT: To this end, we curate a set of grounding acts and propose corresponding metrics that quantify attempted grounding.

25, TITLE: Are You Sure? Challenging LLMs Leads to Performance Drops in The FlipFlop Experiment
AUTHORS: Philippe Laban ; Lidiya Murakhovs'ka ; Caiming Xiong ; Chien-Sheng Wu
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we propose the FlipFlop experiment: in the first round of the conversation, an LLM responds to a prompt containing a classification task.

26, TITLE: PEARL: Personalizing Large Language Model Writing Assistants with Generation-Calibrated Retrievers
AUTHORS: SHESHERA MYSORE et. al.
CATEGORY: cs.CL [cs.CL, cs.HC, cs.IR]
HIGHLIGHT: However, a barrier to effective assistance is the lack of personalization in LLM outputs to the author's communication style and specialized knowledge. In this paper, we address this challenge by proposing PEARL, a retrieval-augmented LLM writing assistant personalized with a generation-calibrated retriever.

27, TITLE: Interpretable By Design: Wrapper Boxes Combine Neural Performance with Faithful Explanations
AUTHORS: Yiheng Su ; Juni Jessy Li ; Matthew Lease
CATEGORY: cs.LG [cs.LG, cs.AI, cs.HC]
HIGHLIGHT: We present wrapper boxes, a general approach to generate faithful, example-based explanations for model predictions while maintaining predictive performance.

28, TITLE: Toucan: Token-Aware Character Level Language Modeling
AUTHORS: William Fleshman ; Benjamin Van Durme
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: Learning to combine character representations into tokens has made training these models more efficient, but they still require decoding characters individually. We propose Toucan, an augmentation to character-level models to make them "token-aware".

29, TITLE: Can Large Language Models Follow Concept Annotation Guidelines? A Case Study on Scientific and Financial Domains
AUTHORS: Marcio Fonseca ; Shay B. Cohen
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: Importantly, only proprietary models such as GPT-3.5 and GPT-4 can recognize nonsensical guidelines, which we hypothesize is due to more sophisticated alignment methods.

30, TITLE: Benchmarking Generation and Evaluation Capabilities of Large Language Models for Instruction Controllable Summarization
AUTHORS: YIXIN LIU et. al.
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: To this end, we curate an evaluation-only dataset for this task setting and conduct human evaluation on 5 LLM-based summarization systems.

31, TITLE: Controllable Text Summarization: Unraveling Challenges, Approaches, and Prospects -- A Survey
AUTHORS: Ashok Urlana ; Pruthwik Mishra ; Tathagato Roy ; Rahul Mishra
CATEGORY: cs.CL [cs.CL, cs.AI, I.2.7]
HIGHLIGHT: In this survey, we formalize the Controllable Text Summarization (CTS) task, categorize controllable aspects according to their shared characteristics and objectives, and present a thorough examination of existing methods and datasets within each category.

32, TITLE: Evaluating Gender Bias in The Translation of Gender-Neutral Languages Into English
AUTHORS: Spencer Rarrick ; Ranjita Naik ; Sundar Poudel ; Vishal Chowdhary
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: Despite numerous studies into gender bias in translations from gender-neutral languages such as Turkish into more strongly gendered languages like English, there are no benchmarks for evaluating this phenomenon or for assessing mitigation strategies. To address this gap, we introduce GATE X-E, an extension to the GATE (Rarrick et al., 2023) corpus, that consists of human translations from Turkish, Hungarian, Finnish, and Persian into English.

33, TITLE: OFA: A Framework of Initializing Unseen Subword Embeddings for Efficient Large-scale Multilingual Continued Pretraining
AUTHORS: Yihong Liu ; Peiqin Lin ; Mingyang Wang ; Hinrich Sch�tze
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: However, this method usually randomly initializes the embeddings of new subwords and introduces substantially more embedding parameters to the language model, thus weakening the efficiency. To address these issues, we propose a novel framework: \textbf{O}ne \textbf{F}or \textbf{A}ll (\textbf{\textsc{Ofa}}), which wisely initializes the embeddings of unseen subwords from target languages and thus can adapt a PLM to multiple languages efficiently and effectively.

34, TITLE: TableLlama: Towards Open Large Generalist Models for Tables
AUTHORS: Tianshu Zhang ; Xiang Yue ; Yifei Li ; Huan Sun
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We will open-source our dataset and trained model to boost future work on developing open generalist models for tables.

35, TITLE: Explore Spurious Correlations at The Concept Level in Language Models for Text Classification
AUTHORS: YUHANG ZHOU et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: Second, we propose a data rebalancing method to mitigate the spurious correlations by adding the LLM-generated counterfactual data to make a balanced label distribution for each concept. We verify the effectiveness of our mitigation method and show its superiority over the token removal method.

36, TITLE: Accelerating Toeplitz Neural Network with Constant-time Inference Complexity
AUTHORS: Zhen Qin ; Yiran Zhong
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we aim to combine the strengths of TNNs and SSMs by converting TNNs to SSMs during inference, thereby enabling TNNs to achieve the same constant inference complexities as SSMs.

37, TITLE: MAgIC: Benchmarking Large Language Model Powered Multi-Agent in Cognition, Adaptability, Rationality and Collaboration
AUTHORS: LIN XU et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: This work introduces a novel benchmarking framework specifically tailored to assess LLMs within multi-agent settings, providing quantitative metrics to evaluate their judgment, reasoning, deception, self-awareness, collaboration, coordination, and rationality.

38, TITLE: DALA: A Distribution-Aware LoRA-Based Adversarial Attack Against Pre-trained Language Models
AUTHORS: Yibo Wang ; Xiangjue Dong ; James Caverlee ; Philip S. Yu
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: As a result, they are easy to detect using very simple detection methods, diminishing the actual effectiveness of these attack methods. To solve this problem, we propose a Distribution-Aware LoRA-based Adversarial Attack (DALA) method, which considers the distribution shift of adversarial examples to improve attack effectiveness under detection methods.

39, TITLE: Leveraging Foundation Models to Improve Lightweight Clients in Federated Learning
AUTHORS: XIDONG WU et. al.
CATEGORY: cs.LG [cs.LG, cs.CV, cs.DC]
HIGHLIGHT: We introduce foundation model distillation to assist in the federated training of lightweight client models and increase their performance under heterogeneous data settings while keeping inference costs low.

40, TITLE: Towards A Unified View of Answer Calibration for Multi-Step Reasoning
AUTHORS: Shumin Deng ; Ningyu Zhang ; Nay Oo ; Bryan Hooi
CATEGORY: cs.CL [cs.CL, cs.AI, cs.IR, cs.LG]
HIGHLIGHT: While effective, there remains a significant gap in our understanding of the key factors that drive their success. In this paper, we break down the design of recent answer calibration strategies and present a unified view which establishes connections between them.

41, TITLE: Chain-of-Note: Enhancing Robustness in Retrieval-Augmented Language Models
AUTHORS: WENHAO YU et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In situations where knowledge is lacking, these systems should ideally respond with "unknown" when the answer is unattainable. In response to these challenges, we introduces Chain-of-Noting (CoN), a novel approach aimed at improving the robustness of RALMs in facing noisy, irrelevant documents and in handling unknown scenarios.

42, TITLE: Generate, Filter, and Fuse: Query Expansion Via Multi-Step Keyword Generation for Zero-Shot Neural Rankers
AUTHORS: MINGHAN LI et. al.
CATEGORY: cs.IR [cs.IR, cs.AI]
HIGHLIGHT: To this end, we propose GFF, a pipeline that includes a large language model and a neural ranker, to Generate, Filter, and Fuse query expansions more effectively in order to improve the zero-shot ranking metrics such as nDCG@10.

43, TITLE: Review of AlexNet for Medical Image Classification
AUTHORS: Wenhao Tang ; Junding Sun ; Shuihua Wang ; Yudong Zhang
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: After reviewing over 40 papers, including journal papers and conference papers, we give a narrative on the technical details, advantages, and application areas of AlexNet.

44, TITLE: Ever: Mitigating Hallucination in Large Language Models Through Real-Time Verification and Rectification
AUTHORS: Haoqiang Kang ; Juntong Ni ; Huaxiu Yao
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: This issue is common in both non-retrieval-based generation and retrieval-augmented generation approaches, and existing post-hoc rectification methods may not address the accumulated hallucination errors that may be caused by the "snowballing" issue, especially in reasoning tasks. To tackle these challenges, we introduce a novel approach called Real-time Verification and Rectification (Ever).

45, TITLE: Identifying Linear Relational Concepts in Large Language Models
AUTHORS: David Chanin ; Anthony Hunter ; Oana-Maria Camburu
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: We present a technique called linear relational concepts (LRC) for finding concept directions corresponding to human-interpretable concepts at a given hidden layer in a transformer LM by first modeling the relation between subject and object as a linear relational embedding (LRE).

46, TITLE: Token Prediction As Implicit Classification to Identify LLM-Generated Text
AUTHORS: YUTIAN CHEN et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: This paper introduces a novel approach for identifying the possible large language models (LLMs) involved in text generation.

47, TITLE: MAP's Not Dead Yet: Uncovering True Language Model Modes By Conditioning Away Degeneracy
AUTHORS: Davis Yoshida ; Kartik Goyal ; Kevin Gimpel
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: Contrastingly in this work, we emphasize that degenerate modes can even occur in the absence of any model error, due to contamination of the training data.

48, TITLE: Self-Annotated 3D Geometric Learning for Smeared Points Removal
AUTHORS: Miaowei Wang ; Daniel Morris
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Trained network-based point removal faces difficulty in obtaining sufficient annotated data. To address this, we propose a fully self-annotated method to train a smeared point removal classifier.

49, TITLE: Attribute Diversity Determines The Systematicity Gap in VQA
AUTHORS: Ian Berlot-Attwell ; A. Michael Carrell ; Kumar Krishna Agrawal ; Yash Sharma ; Naomi Saphra
CATEGORY: cs.LG [cs.LG, cs.CL, cs.CV]
HIGHLIGHT: In this work, we study the systematicity gap in visual question answering: the performance difference between reasoning on previously seen and unseen combinations of object attributes.

50, TITLE: Spatio-Temporal Graph Neural Point Process for Traffic Congestion Event Prediction
AUTHORS: Guangyin Jin ; Lingbo Liu ; Fuxian Li ; Jincai Huang
CATEGORY: cs.LG [cs.LG, cs.AI, cs.SI]
HIGHLIGHT: However, most conventional works about NPP cannot model the complex spatio-temporal dependencies and congestion evolution patterns. To address these limitations, we propose a spatio-temporal graph neural point process framework, named STGNPP for traffic congestion event prediction.

51, TITLE: Refining Perception Contracts: Case Studies in Vision-based Safe Auto-landing
AUTHORS: Yangge Li ; Benjamin C Yang ; Yixuan Jia ; Daniel Zhuang ; Sayan Mitra
CATEGORY: cs.RO [cs.RO, cs.CV]
HIGHLIGHT: This paper presents the analysis of two 6 and 12-dimensional flight control systems that use multi-stage, heterogeneous, ML-enabled perception.

52, TITLE: Autonomous Large Language Model Agents Enabling Intent-Driven Mobile GUI Testing
AUTHORS: Juyeon Yoon ; Robert Feldt ; Shin Yoo
CATEGORY: cs.SE [cs.SE, cs.AI]
HIGHLIGHT: We propose DroidAgent, an autonomous GUI testing agent for Android, for semantic, intent-driven automation of GUI testing.

53, TITLE: Speculative Contrastive Decoding
AUTHORS: Hongyi Yuan ; Keming Lu ; Fei Huang ; Zheng Yuan ; Chang Zhou
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We proposed Speculative Contrastive Decoding (SCD), an accelerated decoding method leveraging the natural contrast between expert and amateur models in speculative decoding.

54, TITLE: Imagine The Unseen World: A Benchmark for Systematic Generalization in Visual World Models
AUTHORS: Yeongbin Kim ; Gautam Singh ; Junyeong Park ; Caglar Gulcehre ; Sungjin Ahn
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: While there has been considerable progress in the language domain, efforts towards systematic visual imagination, or envisioning the dynamical implications of a visual observation, are in their infancy. We introduce the Systematic Visual Imagination Benchmark (SVIB), the first benchmark designed to address this problem head-on.

55, TITLE: Method for Text Entity Linking in Power Distribution Scheduling Oriented to Power Distribution Network Knowledge Graph
AUTHORS: Xiang Li ; Che Wang ; Bing Li ; Hao Chen ; Sizhe Li
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: This method leverages the unique features of entities in both the power distribution network's knowledge graph and the dispatch texts, focusing on their semantic, phonetic, and syntactic characteristics.

56, TITLE: SentAlign: Accurate and Scalable Sentence Alignment
AUTHORS: Stein��r Steingr�msson ; Hrafn Loftsson ; Andy Way
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We present SentAlign, an accurate sentence alignment tool designed to handle very large parallel document pairs.

57, TITLE: Counting Small Induced Subgraphs with Edge-monotone Properties
AUTHORS: Simon D�ring ; D�niel Marx ; Philip Wellnitz
CATEGORY: cs.CC [cs.CC, cs.DS]
HIGHLIGHT: We study the parameterized complexity of #IndSub($\Phi$), where given a graph $G$ and an integer $k$, the task is to count the number of induced subgraphs on $k$ vertices that satisfy the graph property $\Phi$.

58, TITLE: Correlation-aware Active Learning for Surgery Video Segmentation
AUTHORS: Fei Wu ; Pablo Marquez-Neila ; Mingyi Zheng ; Hedyeh Rafii-Tari ; Raphael Sznitman
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: This work proposes a novel AL strategy for surgery video segmentation, \COALSamp{}, COrrelation-aWare Active Learning.

59, TITLE: Spiking NeRF: Representing The Real-World Geometry By A Discontinuous Representation
AUTHORS: Zhanfeng Liao ; Qian Zheng ; Yan Liu ; Gang Pan
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: To this end, this paper proposes spiking NeRF, which leverages spiking neuron and a hybrid Artificial Neural Network (ANN)-Spiking Neural Network (SNN) framework to build a discontinuous density field for faithful geometry representation.

60, TITLE: End-to-end Task-oriented Dialogue: A Survey of Tasks, Methods, and Future Directions
AUTHORS: LIBO QIN et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we present a thorough review and provide a unified perspective to summarize existing approaches as well as recent trends to advance the development of EToD research.

61, TITLE: Multi-Set Inoculation: Assessing Model Robustness Across Multiple Challenge Sets
AUTHORS: Vatsal Gupta ; Pranshu Pandya ; Tushar Kataria ; Vivek Gupta ; Dan Roth
CATEGORY: cs.CL [cs.CL, cs.AI, cs.IR]
HIGHLIGHT: In this study, we propose a framework to study the effect of input perturbations on language models of different scales, from pre-trained models to large language models (LLMs).

62, TITLE: Improved Dense Nested Attention Network Based on Transformer for Infrared Small Target Detection
AUTHORS: CHUN BAO et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: However, the features of infrared small targets gradually weaken as the depth of convolutional neural network (CNN) increases. To address this issue, we propose a novel method for detecting infrared small targets called improved dense nested attention network (IDNANet), which is based on the transformer architecture.

63, TITLE: Self-Supervised Disentanglement By Leveraging Structure in Data Augmentations
AUTHORS: CIAN EASTWOOD et. al.
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CV, stat.ML]
HIGHLIGHT: However, with downstream tasks generally unknown at training time, it is difficult to deduce a priori which attributes of the data are indeed "style" and can be safely discarded. To address this, we introduce a more principled approach that seeks to disentangle style features rather than discard them.

64, TITLE: Data Augmentations in Deep Weight Spaces
AUTHORS: AVIV SHAMSIAN et. al.
CATEGORY: cs.LG [cs.LG, cs.CV]
HIGHLIGHT: This poses a significant challenge because generating data for this learning setup is laborious and time-consuming since each data sample is a full set of network weights that has to be trained. In this paper, we address this difficulty by investigating data augmentations for weight spaces, a set of techniques that enable generating new data examples on the fly without having to train additional input weight space elements.

65, TITLE: Social Bias Probing: Fairness Benchmarking for Language Models
AUTHORS: Marta Marchiori Manerba ; Karolina Sta?czak ; Riccardo Guidotti ; Isabelle Augenstein
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we propose an original framework for probing language models for societal biases.

66, TITLE: ConvNet Vs Transformer, Supervised Vs CLIP: Beyond ImageNet Accuracy
AUTHORS: Kirill Vishniakov ; Zhiqiang Shen ; Zhuang Liu
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: In this work, we conduct an in-depth comparative analysis of model behaviors beyond ImageNet accuracy, for both ConvNet and Vision Transformer architectures, each across supervised and CLIP training paradigms.

67, TITLE: Frequency Domain-based Dataset Distillation
AUTHORS: Donghyeok Shin ; Seungjae Shin ; Il-Chul Moon
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CV]
HIGHLIGHT: This paper presents FreD, a novel parameterization method for dataset distillation, which utilizes the frequency domain to distill a small-sized synthetic dataset from a large-sized original dataset.

68, TITLE: Cross-view and Cross-pose Completion for 3D Human Understanding
AUTHORS: MATTHIEU ARMANDO et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: On the other hand, collecting domain specific ground truth such as 2D or 3D labels does not scale well. Therefore, we propose a pre-training approach based on self-supervised learning that works on human-centric data using only images.

69, TITLE: Contrastive Transformer Learning with Proximity Data Generation for Text-Based Person Search
AUTHORS: HEFENG WU et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we propose a simple yet effective dual Transformer model for text-based person search.

70, TITLE: CodeScope: An Execution-based Multilingual Multitask Multidimensional Benchmark for Evaluating LLMs on Code Understanding and Generation
AUTHORS: WEIXIANG YAN et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.SE]
HIGHLIGHT: Second, most benchmarks also fail to consider the actual executability and the consistency of execution results of the generated code. To bridge these gaps between existing benchmarks and expectations from practical applications, we introduce CodeScope, an execution-based, multilingual, multi-task, multi-dimensional evaluation benchmark for comprehensively gauging LLM capabilities on coding tasks.

71, TITLE: DMV3D: Denoising Multi-View Diffusion Using 3D Large Reconstruction Model
AUTHORS: YINGHAO XU et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We propose \textbf{DMV3D}, a novel 3D generation approach that uses a transformer-based 3D large reconstruction model to denoise multi-view diffusion.

72, TITLE: Thread of Thought Unraveling Chaotic Contexts
AUTHORS: YUCHENG ZHOU et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Nevertheless, they encounter difficulties when confronted with chaotic contexts (e.g., distractors rather than long irrelevant context), leading to the inadvertent omission of certain details within the chaotic context. In response to these challenges, we introduce the "Thread of Thought" (ThoT) strategy, which draws inspiration from human cognitive processes.

73, TITLE: HFORD: High-Fidelity and Occlusion-Robust De-identification for Face Privacy Protection
AUTHORS: Dongxin Chen ; Mingrui Zhu ; Nannan Wang ; Xinbo Gao
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: The existing facial de-identification methods have revealed several problems, including the impact on the realism of anonymized results when faced with occlusions and the inability to maintain identity-irrelevant details in anonymized results. We present a High-Fidelity and Occlusion-Robust De-identification (HFORD) method to deal with these issues.

74, TITLE: PEMA: Plug-in External Memory Adaptation for Language Models
AUTHORS: HyunJin Kim ; Young Jin Kim ; JinYeong Bak
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: To overcome the limitations, we introduce Plug-in External Memory Adaptation (PEMA), a Parameter-Efficient Fine-Tuning (PEFT) approach designed for fine-tuning PLMs without the need for all weights.

75, TITLE: A Diffusion Model Based Quality Enhancement Method for HEVC Compressed Video
AUTHORS: Zheng Liu ; Honggang Qi
CATEGORY: eess.IV [eess.IV, cs.CV]
HIGHLIGHT: This makes existing methods have their limitations in improving video quality. To tackle this problem, this work proposes a diffusion model based post-processing method for compressed videos.

76, TITLE: Forms of Understanding of XAI-Explanations
AUTHORS: HENDRIK BUSCHMEIER et. al.
CATEGORY: cs.AI [cs.AI]
HIGHLIGHT: However, what it means to 'understand' is still not clearly defined, and the concept itself is rarely the subject of scientific investigation. This conceptual article aims to present a model of forms of understanding in the context of XAI and beyond.

77, TITLE: Proceedings Fifth International Workshop on Formal Methods for Autonomous Systems
AUTHORS: Marie Farrell ; Matt Luckcuck ; Mario Gleirscher ; Maike Schwammberger
CATEGORY: cs.AI [cs.AI, cs.RO]
HIGHLIGHT: After each paper was reviewed by three members of our Programme Committee we accepted a total of 15 papers: 8 long papers and 7 short papers.

78, TITLE: Graph-Induced Syntactic-Semantic Spaces in Transformer-Based Variational AutoEncoders
AUTHORS: Yingji Zhang ; Marco Valentino ; Danilo S. Carvalho ; Ian Pratt-Hartmann ; Andr� Freitas
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we investigate latent space separation methods for structural syntactic injection in Transformer-based VAE architectures (i.e., Optimus).

79, TITLE: Llamas Know What GPTs Don't Show: Surrogate Models for Confidence Estimation
AUTHORS: Vaishnavi Shrivastava ; Percy Liang ; Ananya Kumar
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: Llamas Know What GPTs Don't Show: Surrogate Models for Confidence Estimation

80, TITLE: Gaussian Approximation of Convex Sets By Intersections of Halfspaces
AUTHORS: Anindya De ; Shivam Nadimpalli ; Rocco A. Servedio
CATEGORY: cs.CC [cs.CC, cs.DS, math.MG, math.PR]
HIGHLIGHT: We study the approximability of general convex sets in $\mathbb{R}^n$ by intersections of halfspaces, where the approximation quality is measured with respect to the standard Gaussian distribution $N(0,I_n)$ and the complexity of an approximation is the number of halfspaces used.

81, TITLE: Fast Certification of Vision-Language Models Using Incremental Randomized Smoothing
AUTHORS: A K Nirala ; A Joshi ; C Hegde ; S Sarkar
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this work, we introduce Open Vocabulary Certification (OVC), a fast certification method designed for open-vocabulary models like CLIP via randomized smoothing techniques.

82, TITLE: MADG: Margin-based Adversarial Learning for Domain Generalization
AUTHORS: AVEEN DAYAL et. al.
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: In contrast, the margin loss-based discrepancy metric has the following advantages: more informative, tighter, practical, and efficiently optimizable. To mitigate this gap, this work proposes a novel adversarial learning DG algorithm, MADG, motivated by a margin loss-based discrepancy metric.

83, TITLE: Drivable 3D Gaussian Avatars
AUTHORS: WOJCIECH ZIELONKA et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We present Drivable 3D Gaussian Avatars (D3GA), the first 3D controllable model for human bodies rendered with Gaussian splats.

84, TITLE: Robust Brain MRI Image Classification with SIBOW-SVM
AUTHORS: Liyun Zeng ; Hao Helen Zhang
CATEGORY: stat.ME [stat.ME, cs.CV]
HIGHLIGHT: In this paper, we propose a novel brain tumor image classification method, called SIBOW-SVM, which integrates the Bag-of-Features (BoF) model with SIFT feature extraction and weighted Support Vector Machines (wSVMs).

85, TITLE: Topology of Surface Electromyogram Signals: Hand Gesture Decoding on Riemannian Manifolds
AUTHORS: Harshavardhana T. Gowda ; Lee M. Miller
CATEGORY: eess.SP [eess.SP, cs.CV, cs.HC, q-bio.QM, 53, G.3]
HIGHLIGHT: As we show here, analyzing spatial patterns using covariance matrices on Riemannian manifolds allows us to robustly model complex interactions across spatially distributed MUs and provides a flexible and transparent framework to quantify differences in sEMG signals across individuals. The proposed method is novel in the study of sEMG signals and its performance exceeds the current benchmarks while maintaining exceptional computational efficiency.

86, TITLE: Surrogate Modeling for Computationally Expensive Simulations of Supernovae in High-Resolution Galaxy Simulations
AUTHORS: KEIYA HIRASHIMA et. al.
CATEGORY: astro-ph.GA [astro-ph.GA, cs.AI, cs.LG]
HIGHLIGHT: We develop a method combining machine learning and Gibbs sampling to predict how a supernova (SN) affects the surrounding gas.

87, TITLE: Probabilistic Reconstruction of Dark Matter Fields from Biased Tracers Using Diffusion Models
AUTHORS: Core Francisco Park ; Victoria Ono ; Nayantara Mudur ; Yueying Ni ; Carolina Cuesta-Lazaro
CATEGORY: astro-ph.CO [astro-ph.CO, astro-ph.GA, cs.AI]
HIGHLIGHT: Based on state-of-the-art galaxy formation simulation suites with varied cosmological parameters and sub-grid astrophysics, we develop a diffusion generative model to predict the unbiased posterior distribution of the underlying dark matter fields from the given stellar mass fields, while being able to marginalize over the uncertainties in cosmology and galaxy formation.

88, TITLE: Unsupervised Segmentation of Irradiation$\unicode{x2010}$induced Order$\unicode{x2010}$disorder Phase Transitions in Electron Microscopy
AUTHORS: ARMAN H TER-PETROSYAN et. al.
CATEGORY: cond-mat.mtrl-sci [cond-mat.mtrl-sci, cs.CV, cs.LG, eess.IV]
HIGHLIGHT: We present a method for the unsupervised segmentation of electron microscopy images, which are powerful descriptors of materials and chemical systems.

89, TITLE: Debate Helps Supervise Unreliable Experts
AUTHORS: JULIAN MICHAEL et. al.
CATEGORY: cs.AI [cs.AI, cs.CL, I.2.0]
HIGHLIGHT: In this work, we show that debate between two unreliable experts can help a non-expert judge more reliably identify the truth.

90, TITLE: Three Conjectures on Unexpectedeness
AUTHORS: Giovanni Sileno ; Jean-Louis Dessalles
CATEGORY: cs.AI [cs.AI, cs.CL, cs.IT, cs.SY, eess.SY, math.IT]
HIGHLIGHT: Three Conjectures on Unexpectedeness

91, TITLE: LLMs Cannot Find Reasoning Errors, But Can Correct Them!
AUTHORS: Gladys Tyen ; Hassan Mansoor ; Peter Chen ; Tony Mak ; Victor C?rbune
CATEGORY: cs.AI [cs.AI, cs.CL, cs.LG]
HIGHLIGHT: In this paper, we break down the self-correction process into two core components: mistake finding and output correction.

92, TITLE: Leveraging AI for Natural Disaster Management : Takeaways From The Moroccan Earthquake
AUTHORS: Morocco Solidarity Hackathon
CATEGORY: cs.AI [cs.AI]
HIGHLIGHT: This paper provides (i) a comprehensive literature review, (ii) an overview of winning projects, (iii) key insights and challenges, namely real-time open-source data, data scarcity, and interdisciplinary collaboration barriers, and (iv) a community-call for further action.

93, TITLE: A* Search Algorithm for An Optimal Investment Problem in Vehicle-sharing Systems
AUTHORS: Ba Luat Le ; Layla Martin ; Emrah Demir ; Duc Minh Vu
CATEGORY: cs.AI [cs.AI]
HIGHLIGHT: This property introduces a set-dependent aspect to the duration required for opening a new station, and the optimal investment problem can be viewed as a variant of the Traveling Salesman Problem (TSP) with set-dependent cost. We propose an A* search algorithm to address this particular variant of the TSP.

94, TITLE: DeepThought: An Architecture for Autonomous Self-motivated Systems
AUTHORS: Arlindo L. Oliveira ; Tiago Domingos ; M�rio Figueiredo ; Pedro U. Lima
CATEGORY: cs.AI [cs.AI, I.2]
HIGHLIGHT: By combining insights from complementary learning systems, global neuronal workspace, and attention schema theories, we propose to integrate LLMs and other deep learning systems into an architecture for cognitive language agents able to exhibit properties akin to agency, self-motivation, even some features of meta-cognition.

95, TITLE: Advances in ACL2 Proof Debugging Tools
AUTHORS: Matt Kaufmann ; J Strother Moore
CATEGORY: cs.AI [cs.AI, cs.LO, cs.SE]
HIGHLIGHT: We focus on changes made after ACL2 Version 8.5: the improved break-rewrite utility and the new utility, with-brr-data.

96, TITLE: Disinformation Capabilities of Large Language Models
AUTHORS: IVAN VYKOPAL et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: This paper presents a comprehensive study of the disinformation capabilities of the current generation of LLMs to generate false news articles in English language.

97, TITLE: Alignment Is Not Sufficient to Prevent Large Language Models from Generating Harmful Information: A Psychoanalytic Perspective
AUTHORS: Zi Yin ; Wei Ding ; Jia Liu
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: Drawing an analogy to the human psyche's conflict between evolutionary survival instincts and societal norm adherence elucidated in Freud's psychoanalysis theory, we argue that LLMs suffer a similar fundamental conflict, arising between their inherent desire for syntactic and semantic continuity, established during the pre-training phase, and the post-training alignment with human values.

98, TITLE: Functionality Learning Through Specification Instructions
AUTHORS: Pedro Henrique Luz de Araujo ; Benjamin Roth
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We combine the obtained specification instructions to create specification-augmented prompts, which we feed to language models pre-trained on natural instruction data to generate suite predictions.

99, TITLE: Selecting Shots for Demographic Fairness in Few-Shot Learning with Large Language Models
AUTHORS: Carlos Aguirre ; Kuleen Sasse ; Isabel Cachola ; Mark Dredze
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this work, we explore the effect of shots, which directly affect the performance of models, on the fairness of LLMs as NLP classification systems.

100, TITLE: Temporal Knowledge Question Answering Via Abstract Reasoning Induction
AUTHORS: Ziyang Chen ; Dongfang Li ; Xiang Zhao ; Baotian Hu ; Min Zhang
CATEGORY: cs.CL [cs.CL, cs.AI, I.2.7]
HIGHLIGHT: In this paper, we tackle the significant challenge of temporal knowledge reasoning in Large Language Models (LLMs), an area where such models frequently encounter difficulties.

101, TITLE: SiRA: Sparse Mixture of Low Rank Adaptation
AUTHORS: YUN ZHU et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We found this less effective empirically using the example of LoRA that introducing more trainable parameters does not help. Motivated by this we investigate the importance of leveraging "sparse" computation and propose SiRA: sparse mixture of low rank adaption.

102, TITLE: X-Eval: Generalizable Multi-aspect Text Evaluation Via Augmented Instruction Tuning with Auxiliary Evaluation Aspects
AUTHORS: MINQIAN LIU et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: In this paper, we introduce X-Eval, a two-stage instruction tuning framework to evaluate the text in both seen and unseen aspects customized by end users.

103, TITLE: Does Pre-trained Language Model Actually Infer Unseen Links in Knowledge Graph Completion?
AUTHORS: Yusuke Sakai ; Hidetaka Kamigaito ; Katsuhiko Hayashi ; Taro Watanabe
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: For this purpose, we propose a method for constructing synthetic datasets specified in this analysis and conclude that PLMs acquire the inference abilities required for KGC through pre-training, even though the performance improvements mostly come from textual information of entities and relations.

104, TITLE: "We Demand Justice!": Towards Grounding Political Text in Social Context
AUTHORS: Rajkumar Pujari ; Chengfei Wu ; Dan Goldwasser
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: For instance, "We need to keep our students safe from mass shootings" may signal either "arming teachers to stop the shooter" or "banning guns to reduce mass shootings" depending on who says it and their political stance on the issue. In this paper, we define and characterize the context that is required to fully understand such ambiguous statements in a computational setting and ground them in real-world entities, actions, and attitudes.

105, TITLE: Extending Multilingual Machine Translation Through Imitation Learning
AUTHORS: Wen Lai ; Viktor Hangya ; Alexander Fraser
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We aim to extend large-scale MNMT models to a new language, allowing for translation between the newly added and all of the already supported languages in a challenging scenario: using only a parallel corpus between the new language and English.

106, TITLE: Structural Priming Demonstrates Abstract Grammatical Representations in Multilingual Language Models
AUTHORS: James A. Michaelov ; Catherine Arnett ; Tyler A. Chang ; Benjamin K. Bergen
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We find evidence for abstract monolingual and crosslingual grammatical representations in the models that function similarly to those found in humans.

107, TITLE: The Role of Chain-of-Thought in Complex Vision-Language Reasoning Task
AUTHORS: YIFAN WU et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.CV]
HIGHLIGHT: We present the "Description then Decision" strategy, which is inspired by how humans process signals.

108, TITLE: Never Lost in The Middle: Improving Large Language Models Via Attention Strengthening Question Answering
AUTHORS: HE JUNQING et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: The "lost in the middle" problem challenges most LLMs, referring to the dramatic decline in accuracy when correct information is located in the middle. To overcome this crucial issue, this paper proposes to enhance the information searching and reflection ability of LLMs in long contexts via specially designed tasks called Attention Strengthening Multi-doc QA (ASM QA).

109, TITLE: Natural Language Processing for Financial Regulation
AUTHORS: Ixandra Achitouv ; Dragos Gorduza ; Antoine Jacquier
CATEGORY: cs.CL [cs.CL, cs.LG, q-fin.CP]
HIGHLIGHT: This article provides an understanding of Natural Language Processing techniques in the framework of financial regulation, more specifically in order to perform semantic matching search between rules and policy when no dataset is available for supervised learning.

110, TITLE: ContraDoc: Understanding Self-Contradictions in Documents with Large Language Models
AUTHORS: Jierui Li ; Vipul Raheja ; Dhruv Kumar
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this work, we introduce ContraDoc, the first human-annotated dataset to study self-contradictions in long documents across multiple domains, varying document lengths, self-contradictions types, and scope.

111, TITLE: PsyEval: A Comprehensive Large Language Model Evaluation Benchmark for Mental Health
AUTHORS: Haoan Jin ; Siyuan Chen ; Mengyue Wu ; Kenny Q. Zhu
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Recently, there has been a growing interest in utilizing large language models (LLMs) in mental health research, with studies showcasing their remarkable capabilities, such as disease detection.

112, TITLE: Safer-Instruct: Aligning Language Models with Automated Preference Data
AUTHORS: Taiwei Shi ; Kai Chen ; Jieyu Zhao
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In response, we present Safer-Instruct, a novel pipeline for semi-automatically constructing large-scale preference datasets.

113, TITLE: Self-Improving for Zero-Shot Named Entity Recognition with Large Language Models
AUTHORS: Tingyu Xie ; Qi Li ; Yan Zhang ; Zuozhu Liu ; Hongwei Wang
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We propose a self-improving framework, which utilize an unlabeled corpus to stimulate the self-learning ability of LLMs on NER.

114, TITLE: An Eye on Clinical BERT: Investigating Language Model Generalization for Diabetic Eye Disease Phenotyping
AUTHORS: Keith Harrigian ; Tina Tang ; Anthony Gonzales ; Cindy X. Cai ; Mark Dredze
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: Alas, much of the information necessary to support these goals is found only in the free text of the electronic medical record. To fill this information gap, we introduce a system for extracting evidence from clinical text of 19 clinical concepts related to diabetic eye disease and inferring relevant attributes for each.

115, TITLE: Enhancing Emergency Decision-making with Knowledge Graphs and Large Language Models
AUTHORS: MINZE CHEN et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this work, we develop a system called Enhancing Emergency decision-making with Knowledge Graph and LLM (E-KELL), which provides evidence-based decision-making in various emergency stages.

116, TITLE: GRIM: GRaph-based Interactive Narrative Visualization for GaMes
AUTHORS: JORGE LEANDRO et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: The narratives of these may take years to write and typically involve a large creative team. In this work, we demonstrate the potential of large generative text models to assist this process.

117, TITLE: UNcommonsense Reasoning: Abductive Reasoning About Uncommon Situations
AUTHORS: WENTING ZHAO et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: To instead investigate the ability to model unusual, unexpected, and unlikely situations, we explore the task of uncommonsense abductive reasoning.

118, TITLE: Assessing Translation Capabilities of Large Language Models Involving English and Indian Languages
AUTHORS: VANDAN MUJADIA et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this work, our aim is to explore the multilingual capabilities of large language models by using machine translation as a task involving English and 22 Indian languages.

119, TITLE: Reasoning Over Description Logic-based Contexts with Transformers
AUTHORS: Angelos Poulis ; Eleni Tsalapati ; Manolis Koubarakis
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this work, we seek to answer the question how well a transformer-based model will perform reasoning over expressive contexts.

120, TITLE: Mind's Mirror: Distilling Self-Evaluation Capability and Comprehensive Thinking from Large Language Models
AUTHORS: WEIZE LIU et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Large language models (LLMs) have achieved remarkable advancements in the field of natural language processing.

121, TITLE: Data Similarity Is Not Enough to Explain Language Model Performance
AUTHORS: Gregory Yauney ; Emily Reif ; David Mimno
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: Large language models achieve high performance on many but not all downstream tasks.

122, TITLE: GLiNER: Generalist Model for Named Entity Recognition Using Bidirectional Transformer
AUTHORS: Urchade Zaratiana ; Nadi Tomeh ; Pierre Holat ; Thierry Charnois
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: In this paper, we introduce a compact NER model trained to identify any type of entity.

123, TITLE: MELA: Multilingual Evaluation of Linguistic Acceptability
AUTHORS: ZIYIN ZHANG et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: Recent benchmarks for Large Language Models (LLMs) have mostly focused on application-driven tasks such as complex reasoning and code generation, and this has led to a scarcity in purely linguistic evaluation of LLMs. Against this background, we introduce Multilingual Evaluation of Linguistic Acceptability -- MELA, the first multilingual benchmark on linguistic acceptability with 48K samples covering 10 languages from a diverse set of language families.

124, TITLE: RRescue: Ranking LLM Responses to Enhance Reasoning Over Context
AUTHORS: YIKUN WANG et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we present a novel approach to optimize LLMs using ranking metrics, which teaches LLMs to rank a collection of contextually-grounded candidate responses.

125, TITLE: Fusion-Eval: Integrating Evaluators with LLMs
AUTHORS: LEI SHU et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: We introduce "Fusion-Eval", a system that employs LLMs not solely for direct evaluations, but to skillfully integrate insights from diverse evaluators.

126, TITLE: Decomposing Uncertainty for Large Language Models Through Input Clarification Ensembling
AUTHORS: BAIRU HOU et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we introduce an uncertainty decomposition framework for LLMs, called input clarifications ensemble, which bypasses the need to train new models.

127, TITLE: Universal NER: A Gold-Standard Multilingual Named Entity Recognition Benchmark
AUTHORS: STEPHEN MAYHEW et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We introduce Universal NER (UNER), an open, community-driven project to develop gold-standard NER benchmarks in many languages.

128, TITLE: Think-in-Memory: Recalling and Post-thinking Enable LLMs with Long-Term Memory
AUTHORS: LEI LIU et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: On the contrary, humans can keep thoughts in the memory and recall them without repeated reasoning. Motivated by this human capability, we propose a novel memory mechanism called TiM (Think-in-Memory) that enables LLMs to maintain an evolved memory for storing historical thoughts along the conversation stream.

129, TITLE: Assessing Knowledge Editing in Language Models Via Relation Perspective
AUTHORS: YIFAN WEI et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this paper, we establish a suite of innovative metrics for evaluation and conduct comprehensive experiments involving various knowledge editing baselines.

130, TITLE: Uncertainty Estimation on Sequential Labeling Via Uncertainty Transmission
AUTHORS: Jianfeng He ; Linlin Yu ; Shuo Lei ; Chang-Tien Lu ; Feng Chen
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Previous uncertainty estimation models often overlook two unique characteristics of NER: the connection between entities (i.e., one entity embedding is learned based on the other ones) and wrong span cases in the entity extraction subtask. Therefore, we propose a Sequential Labeling Posterior Network (SLPN) to estimate uncertainty scores for the extracted entities, considering uncertainty transmitted from other tokens.

131, TITLE: GRASP: A Novel Benchmark for Evaluating Language GRounding And Situated Physics Understanding in Multimodal Language Models
AUTHORS: SERWAN JASSIM et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: This paper presents GRASP, a novel benchmark to evaluate the language grounding and physical understanding capabilities of video-based multimodal large language models (LLMs).

132, TITLE: CLEAN-EVAL: Clean Evaluation on Contaminated Large Language Models
AUTHORS: WENHONG ZHU et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: To save our precious time, we propose a novel and useful method, Clean-Eval, which mitigates the issue of data contamination and evaluates the LLMs in a cleaner manner.

133, TITLE: Improving Large-scale Deep Biasing with Phoneme Features and Text-only Data in Streaming Transducer
AUTHORS: JIN QIU et. al.
CATEGORY: cs.CL [cs.CL, cs.SD, eess.AS]
HIGHLIGHT: In this paper, we combine the phoneme and textual information of rare words in Transducers to distinguish words with similar pronunciation or spelling.

134, TITLE: Understanding Calibration for Multilingual Question Answering Models
AUTHORS: Yahan Yang ; Soham Dan ; Dan Roth ; Insup Lee
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: In this paper, we study the calibration properties of several pre-trained multilingual large language models (LLMs) on a variety of question-answering tasks.

135, TITLE: It Takes Two to Negotiate: Modeling Social Exchange in Online Multiplayer Games
AUTHORS: Kokil Jaidka ; Hansin Ahuja ; Lynnette Ng
CATEGORY: cs.CL [cs.CL, cs.GT, cs.LG]
HIGHLIGHT: We annotated a dataset of over 10,000 chat messages for different negotiation strategies and empirically examined their importance in predicting long- and short-term game outcomes.

136, TITLE: CoRE-CoG: Conversational Recommendation of Entities Using Constrained Generation
AUTHORS: Harshvardhan Srivastava ; Kanav Pruthi ; Soumen Chakrabarti
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We introduce a new CRS we call CoRE-CoG.

137, TITLE: Combining Transfer Learning with In-context Learning Using Blackbox LLMs for Zero-shot Knowledge Base Question Answering
AUTHORS: Mayur Patidar ; Avinash Singh ; Riya Sawhney ; Indrajit Bhattacharya
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: More recently, few-shot in-context learning using Black-box Large Language Models (BLLMs) has been adapted for KBQA without considering any source domain data. In this work, we show how to meaningfully combine these two paradigms for KBQA so that their benefits add up.

138, TITLE: How Multilingual Is Multilingual LLM?
AUTHORS: Fei Yuan ; Shuai Yuan ; Zhiyong Wu ; Lei Li
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: This study endeavors to evaluate the multilingual capacity of LLMs by conducting an exhaustive analysis across 101 languages, and classifies languages with similar characteristics into four distinct quadrants. By delving into each quadrant, we shed light on the rationale behind their categorization and offer actionable guidelines for tuning these languages.

139, TITLE: Large Language Models Are Legal But They Are Not: Making The Case for A Powerful LegalLLM
AUTHORS: Thanmay Jayakumar ; Fauzan Farooqui ; Luqman Farooqui
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this study, we aim to quantify how general LLMs perform in comparison to legal-domain models (be it an LLM or otherwise).

140, TITLE: Evaluating Robustness of Dialogue Summarization Models in The Presence of Naturally Occurring Variations
AUTHORS: ANKITA GUPTA et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Overall, our work highlights robustness challenges in dialogue summarization and provides insights for future research.

141, TITLE: Do Localization Methods Actually Localize Memorized Data in LLMs?
AUTHORS: Ting-Yun Chang ; Jesse Thomason ; Robin Jia
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We evaluate five localization methods on our two benchmarks, and both show similar rankings.

142, TITLE: Efficient Continual Pre-training for Building Domain Specific Large Language Models
AUTHORS: Yong Xie ; Karan Aggarwal ; Aitzaz Ahmad
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this work, we explore an alternative strategy of continual pre-training as a means to develop domain-specific LLMs.

143, TITLE: HELLaMA: LLaMA-based Table to Text Generation By Highlighting The Important Evidence
AUTHORS: Junyi Bian ; Xiaolei Qin ; Wuhe Zou ; Mengzuo Huang ; Weidong Zhang
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this study, we conducted parameter-efficient fine-tuning on the LLaMA2 model.

144, TITLE: Identifying Self-Disclosures of Use, Misuse and Addiction in Community-based Social Media Posts
AUTHORS: CHENGHAO YANG et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Community-based social media platforms such as Reddit allow self-disclosure for users to discuss otherwise sensitive drug-related behaviors, often acting as indicators for opioid use disorder. Towards this, we present a moderate size corpus of 2500 opioid-related posts from various subreddits spanning 6 different phases of opioid use: Medical Use, Misuse, Addiction, Recovery, Relapse, Not Using.

145, TITLE: PLUG: Leveraging Pivot Language in Cross-Lingual Instruction Tuning
AUTHORS: ZHIHAN ZHANG et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Despite the success in high-resource languages, its application in lower-resource ones faces challenges due to the imbalanced foundational abilities of LLMs across different languages, stemming from the uneven language distribution in their pre-training data. To tackle this issue, we propose pivot language guided generation (PLUG), an approach that utilizes a high-resource language, primarily English, as the pivot to enhance instruction tuning in lower-resource languages.

146, TITLE: Semi-Structured Chain-of-Thought: Integrating Multiple Sources of Knowledge for Improved Language Model Reasoning
AUTHORS: Xin Su ; Tiep Le ; Steven Bethard ; Phillip Howard
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Most existing prompting methods either rely solely on one or two of these sources, or require repeatedly invoking large language models to generate similar or identical content. In this work, we overcome these limitations by introducing a novel semi-structured prompting approach that seamlessly integrates the model's parametric memory with unstructured knowledge from text documents and structured knowledge from knowledge graphs.

147, TITLE: UT5: Pretraining Non Autoregressive T5 with Unrolled Denoising
AUTHORS: Mahmoud G. Salem ; Jiayu Ye ; Chu-Cheng Lin ; Frederick Liu
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Many non-autoregressive (NAR) research are aiming to address this sequentiality bottleneck, albeit many have focused on a dedicated architecture in supervised benchmarks. In this work, we studied unsupervised pretraining for non auto-regressive T5 models via unrolled denoising and shown its SoTA results in downstream generation tasks such as SQuAD question generation and XSum.

148, TITLE: The Uli Dataset: An Exercise in Experience Led Annotation of OGBV
AUTHORS: ARNAV ARORA et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.SI]
HIGHLIGHT: In this paper we present a dataset on gendered abuse in three languages- Hindi, Tamil and Indian English.

149, TITLE: German FinBERT: A German Pre-trained Language Model
AUTHORS: Moritz Scherrmann
CATEGORY: cs.CL [cs.CL, stat.ML]
HIGHLIGHT: This study presents German FinBERT, a novel pre-trained German language model tailored for financial textual data.

150, TITLE: Towards Generalizable SER: Soft Labeling and Data Augmentation for Modeling Temporal Emotion Shifts in Large-Scale Multilingual Speech
AUTHORS: Mohamed Osman ; Tamer Nadeem ; Ghada Khoriba
CATEGORY: cs.CL [cs.CL, cs.LG, eess.AS]
HIGHLIGHT: We propose a soft labeling system to capture gradational emotional intensities.

151, TITLE: StrategyLLM: Large Language Models As Strategy Generators, Executors, Optimizers, and Evaluators for Problem Solving
AUTHORS: Chang Gao ; Haiyun Jiang ; Deng Cai ; Shuming Shi ; Wai Lam
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Most existing chain-of-thought (CoT) prompting methods suffer from the issues of generalizability and consistency, as they often rely on instance-specific solutions that may not be applicable to other cases and lack task-level consistency in their reasoning steps. To address these limitations, we propose a comprehensive framework, StrategyLLM, harnessing the capabilities of LLMs to tackle various tasks.

152, TITLE: XplainLLM: A QA Explanation Dataset for Understanding LLM Decision-Making
AUTHORS: Zichen Chen ; Jianda Chen ; Mitali Gaidhani ; Ambuj Singh ; Misha Sra
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: Despite their remarkable performance, understanding their decision-making process remains a big challenge. In this paper, we look into bringing some transparency to this process by introducing a new explanation dataset for question answering (QA) tasks that integrates knowledge graphs (KGs) in a novel way.

153, TITLE: Multistage Collaborative Knowledge Distillation from Large Language Models
AUTHORS: JIACHEN ZHAO et. al.
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: This happens when a task, such as parsing, is expensive to annotate and also unfamiliar to a pretrained LLM. In this paper, we present a discovery that student models distilled from a prompted LLM can often generalize better than their teacher on such tasks.

154, TITLE: Enabling Large Language Models to Learn from Rules
AUTHORS: Wenkai Yang ; Yankai Lin ; Jie Zhou ; Jirong Wen
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: That is, humans can grasp the new tasks or knowledge quickly and generalize well given only a detailed rule and a few optional examples. Therefore, in this paper, we aim to explore the feasibility of this new learning paradigm, which encodes the rule-based knowledge into LLMs.

155, TITLE: CLIMB: Curriculum Learning for Infant-inspired Model Building
AUTHORS: RICHARD DIEHL MARTINEZ et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We describe our team's contribution to the STRICT-SMALL track of the BabyLM Challenge.

156, TITLE: Formal Proofs As Structured Explanations: Proposing Several Tasks on Explainable Natural Language Inference
AUTHORS: Lasha Abzianidze
CATEGORY: cs.CL [cs.CL, 68T50, I.2.7]
HIGHLIGHT: In this position paper, we propose a way of exploiting formal proofs to put forward several explainable natural language inference (NLI) tasks.

157, TITLE: The Chromatic Number of Kneser Hypergraphs Via Consensus Division
AUTHORS: Ishay Haviv
CATEGORY: cs.CC [cs.CC, cs.DM, math.AT, math.CO]
HIGHLIGHT: We show that the Consensus Division theorem implies lower bounds on the chromatic number of Kneser hypergraphs, offering a novel proof for a result of Alon, Frankl, and Lov\'{a}sz (Trans.

158, TITLE: Violet: A Vision-Language Model for Arabic Image Captioning with Gemini Decoder
AUTHORS: Abdelrahman Mohamed ; Fakhraddin Alwajih ; El Moatez Billah Nagoudi ; Alcides Alcoba Inciarte ; Muhammad Abdul-Mageed
CATEGORY: cs.CV [cs.CV, cs.CL]
HIGHLIGHT: To train our model, we introduce a new method for automatically acquiring data from available English datasets.

159, TITLE: MUDD: A New Re-Identification Dataset with Efficient Annotation for Off-Road Racers in Extreme Conditions
AUTHORS: Jacob Tyo ; Motolani Olarinre ; Youngseog Chung ; Zachary C. Lipton
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We introduce the Muddy Racer re-IDentification Dataset (MUDD), the first large-scale benchmark for matching identities of motorcycle racers during off-road competitions.

160, TITLE: WildlifeDatasets: An Open-source Toolkit for Animal Re-identification
AUTHORS: Vojt?ch ?erm�k ; Lukas Picek ; Luk�? Adam ; Kostas Papafitsoros
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we present WildlifeDatasets (https://github.com/WildlifeDatasets/wildlife-datasets) - an open-source toolkit intended primarily for ecologists and computer-vision / machine-learning researchers.

161, TITLE: Guided Scale Space Radon Transform for Linear Structures Detection
AUTHORS: Aicha Baya Goumeidane ; Djemel Ziou ; Nafaa Nacereddine
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: As an integral transform, the Scale Space Radon Transform (SSRT) suffers from such drawbacks, even with its great abilities for thick lines detection. In this work, we propose a method to address this issue for automatic detection of thick linear structures in gray scale and binary images using the SSRT, whatever the image background content.

162, TITLE: RBPGAN: Recurrent Back-Projection GAN for Video Super Resolution
AUTHORS: DAREEN HUSSEIN et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we propose Recurrent Back-Projection Generative Adversarial Network (RBPGAN) for VSR in an attempt to generate temporally coherent solutions while preserving spatial details.

163, TITLE: Physical Adversarial Examples for Multi-Camera Systems
AUTHORS: Ana R?du?oiu ; Jan-Philipp Schulze ; Philip Sperl ; Konstantin B�ttinger
CATEGORY: cs.CV [cs.CV, cs.CR, cs.LG]
HIGHLIGHT: We propose a novel attack method that we call Transcender-MC, where we incorporate online 3D renderings and perspective projections in the training process.

164, TITLE: Domain Aligned CLIP for Few-shot Classification
AUTHORS: MUHAMMAD WALEED GONDAL et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this work, we introduce a sample-efficient domain adaptation strategy for CLIP, termed Domain Aligned CLIP (DAC), which improves both intra-modal (image-image) and inter-modal alignment on target distributions without fine-tuning the main model.

165, TITLE: Leveraging Activation Maximization and Generative Adversarial Training to Recognize and Explain Patterns in Natural Areas in Satellite Imagery
AUTHORS: Ahmed Emam ; Timo T. Stomberg ; Ribana Roscher
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: To this end, we propose a novel framework that uses activation maximization and a generative adversarial model.

166, TITLE: CP-EB: Talking Face Generation with Controllable Pose and Eye Blinking Embedding
AUTHORS: JIANZONG WANG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: This paper proposes a talking face generation method named "CP-EB" that takes an audio signal as input and a person image as reference, to synthesize a photo-realistic people talking video with head poses controlled by a short video clip and proper eye blinking embedding.

167, TITLE: Progressive Feedback-Enhanced Transformer for Image Forgery Localization
AUTHORS: Haochen Zhu ; Gang Cao ; Xianglin Huang
CATEGORY: cs.CV [cs.CV, cs.CR]
HIGHLIGHT: In this paper, we propose a Progressive FeedbACk-enhanced Transformer (ProFact) network to achieve coarse-to-fine image forgery localization.

168, TITLE: Unsupervised Approaches Based on Optimal Transport and Convex Analysis for Inverse Problems in Imaging
AUTHORS: Marcello Carioni ; Subhadip Mukherjee ; Hong Ye Tan ; Junqi Tang
CATEGORY: cs.CV [cs.CV, cs.LG, math.OC]
HIGHLIGHT: In this chapter, we review theoretically principled unsupervised learning schemes for solving imaging inverse problems, with a particular focus on methods rooted in optimal transport and convex analysis.

169, TITLE: Finding AI-Generated Faces in The Wild
AUTHORS: Gonzalo J. Aniano Porcile ; Jack Gindi ; Shivansh Mundra ; James R. Verbus ; Hany Farid
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: As the general problem of detecting any type of manipulated or synthesized content is receiving increasing attention, here we focus on a more narrow task of distinguishing a real face from an AI-generated face.

170, TITLE: Efficient Rotation Invariance in Deep Neural Networks Through Artificial Mental Rotation
AUTHORS: Lukas Tuggener ; Thilo Stadelmann ; J�rgen Schmidhuber
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: Here we present artificial mental rotation (AMR), a novel deep learning paradigm for dealing with in-plane rotations inspired by the neuro-psychological concept of mental rotation.

171, TITLE: Structural-Based Uncertainty in Deep Learning Across Anatomical Scales: Analysis in White Matter Lesion Segmentation
AUTHORS: NATALIIA MOLCHANOVA et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We hypothesize that uncertainty at each scale is related to specific types of errors. Our study aims to confirm this relationship by conducting separate analyses for in-domain and out-of-domain settings.

172, TITLE: Combining Past, Present and Future: A Self-Supervised Approach for Class Incremental Learning
AUTHORS: Xiaoshuang Chen ; Zhongyi Sun ; Ke Yan ; Shouhong Ding ; Hongtao Lu
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: To address the problem, we propose a self-supervised CIL framework CPPF, meaning Combining Past, Present and Future.

173, TITLE: Improving Zero-shot Visual Question Answering Via Large Language Models with Reasoning Question Prompts
AUTHORS: YUNSHI LAN et. al.
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: To this end, we present Reasoning Question Prompts for VQA tasks, which can further activate the potential of LLMs in zero-shot scenarios.

174, TITLE: 4K-Resolution Photo Exposure Correction at 125 FPS with ~8K Parameters
AUTHORS: YIJIE ZHOU et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we propose extremely light-weight (with only ~8K parameters) Multi-Scale Linear Transformation (MSLT) networks under the multi-layer perception architecture, which can process 4K-resolution sRGB images at 125 Frame-Per-Second (FPS) by a Titan RTX GPU.

175, TITLE: Personalized Video Relighting Using Casual Light Stage
AUTHORS: Jun Myeong Choi ; Max Christman ; Roni Sengupta
CATEGORY: cs.CV [cs.CV, cs.GR]
HIGHLIGHT: In this paper, we develop a personalized video relighting algorithm that produces high-quality and temporally consistent relit video under any pose, expression, and lighting conditions in real-time.

176, TITLE: Simple But Effective Unsupervised Classification for Specified Domain Images: A Case Study on Fungi Images
AUTHORS: ZHAOCONG LIU et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: As a result, efficiently procuring high-quality labeled datasets remains a pressing challenge for specialized domain images devoid of annotated data. Addressing this, an unsupervised classification method with three key ideas is introduced: 1) dual-step feature dimensionality reduction using a pre-trained model and manifold learning, 2) a voting mechanism from multiple clustering algorithms, and 3) post-hoc instead of prior manual annotation.

177, TITLE: AdapterShadow: Adapting Segment Anything Model for Shadow Detection
AUTHORS: Leiping Jie ; Hui Zhang
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: To overcome the problems, we propose AdapterShadow, which adapts SAM model for shadow detection.

178, TITLE: Language Semantic Graph Guided Data-Efficient Learning
AUTHORS: Wenxuan Ma ; Shuang Li ; Lincan Cai ; Jingxuan Kang
CATEGORY: cs.CV [cs.CV, cs.MM]
HIGHLIGHT: In this paper, we propose a novel perspective on data efficiency that involves exploiting the semantic information contained in the labels of the available data.

179, TITLE: ConeQuest: A Benchmark for Cone Segmentation on Mars
AUTHORS: Mirali Purohit ; Jacob Adler ; Hannah Kerner
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: We propose two benchmark tasks using ConeQuest: (i) Spatial Generalization and (ii) Cone-size Generalization.

180, TITLE: A Spectral Diffusion Prior for Hyperspectral Image Super-Resolution
AUTHORS: Jianjun Liu ; Zebin Wu ; Liang Xiao
CATEGORY: cs.CV [cs.CV, eess.IV]
HIGHLIGHT: Motivated by the success of diffusion models, we propose a novel spectral diffusion prior for fusion-based HSI super-resolution.

181, TITLE: Applications of Computer Vision in Autonomous Vehicles: Methods, Challenges and Future Directions
AUTHORS: Xingshuai Dong ; Massimiliano L. Cappuccio
CATEGORY: cs.CV [cs.CV, cs.RO]
HIGHLIGHT: This paper reviews publications on computer vision and autonomous driving that are published during the last ten years.

182, TITLE: Multiple-Question Multiple-Answer Text-VQA
AUTHORS: Peng Tang ; Srikar Appalaraju ; R. Manmatha ; Yusheng Xie ; Vijay Mahadevan
CATEGORY: cs.CV [cs.CV, cs.CL, cs.LG]
HIGHLIGHT: We present Multiple-Question Multiple-Answer (MQMA), a novel approach to do text-VQA in encoder-decoder transformer models.

183, TITLE: Toulouse Hyperspectral Data Set: A Benchmark Data Set to Assess Semi-supervised Spectral Representation Learning and Pixel-wise Classification Techniques
AUTHORS: Romain Thoreau ; Laurent Risser ; V�ronique Achard ; B�atrice Berthelot ; Xavier Briottet
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Yet, the publicly available hyperspectral data sets commonly used to benchmark machine learning models are not totally suited to evaluate their generalization performances due to one or several of the following properties: a limited geographical coverage (which does not reflect the spectral diversity in metropolitan areas), a small number of land cover classes and a lack of appropriate standard train / test splits for semi-supervised and self-supervised learning. Therefore, we release in this paper the Toulouse Hyperspectral Data Set that stands out from other data sets in the above-mentioned respects in order to meet key issues in spectral representation learning and classification over large-scale hyperspectral images with very few labeled pixels.

184, TITLE: Controlling The Output of A Generative Model By Latent Feature Vector Shifting
AUTHORS: R�bert Belanec ; Peter Lacko ; Krist�na Malinovsk�
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Here we present our novel method for latent vector shifting for controlled output image modification utilizing semantic features of the generated images.

185, TITLE: Low-light Pedestrian Detection in Visible and Infrared Image Feeds: Issues and Challenges
AUTHORS: Hrishikesh Vachhani ; Thangarajah Akilan ; Yash Devmurari ; Nisharaff Shaik ; Dhruvisha Patel
CATEGORY: cs.CV [cs.CV, cs.AI, cs.LG]
HIGHLIGHT: Low-light Pedestrian Detection in Visible and Infrared Image Feeds: Issues and Challenges

186, TITLE: SparseSpikformer: A Co-Design Framework for Token and Weight Pruning in Spiking Transformer
AUTHORS: Yue Liu ; Shanlin Xiao ; Bo Li ; Zhiyi Yu
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: Based on that, we present SparseSpikformer, a co-design framework aimed at achieving sparsity in Spikformer through token and weight pruning techniques.

187, TITLE: Painterly Image Harmonization Via Adversarial Residual Learning
AUTHORS: Xudong Wang ; Li Niu ; Junyan Cao ; Yan Hong ; Liqing Zhang
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this work, we employ adversarial learning to bridge the domain gap between foreground feature map and background feature map.

188, TITLE: Incremental Object-Based Novelty Detection with Feedback Loop
AUTHORS: Simone Caldarella ; Elisa Ricci ; Rahaf Aljundi
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this work, we propose a novel framework for object-based ND, assuming that human feedback can be requested on the predicted output and later incorporated to refine the ND model without negatively affecting the main object detection performance.

189, TITLE: One-Shot Federated Learning with Classifier-Guided Diffusion Models
AUTHORS: Mingzhao Yang ; Shangchao Su ; Bin Li ; Xiangyang Xue
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: In this paper, we explore the novel opportunities that diffusion models bring to OSFL and propose FedCADO, utilizing guidance from client classifiers to generate data that complies with clients' distributions and subsequently training the aggregated model on the server.

190, TITLE: Artificial General Intelligence, Existential Risk, and Human Risk Perception
AUTHORS: David R. Mandel
CATEGORY: cs.CY [cs.CY, cs.AI]
HIGHLIGHT: Artificial General Intelligence, Existential Risk, and Human Risk Perception

191, TITLE: Safety, Trust, and Ethics Considerations for Human-AI Teaming in Aerospace Control
AUTHORS: Kerianne L. Hobbs ; Bernard Li
CATEGORY: cs.CY [cs.CY, cs.AI, cs.SY, eess.SY]
HIGHLIGHT: Safe, trusted, and ethical use of AI are often used interchangeably; however, a system can be safely used but not trusted or ethical, have a trusted use that is not safe or ethical, and have an ethical use that is not safe or trusted. This manuscript serves as a primer to illuminate the nuanced differences between these concepts, with a specific focus on applications of Human-AI teaming in aerospace system control, where humans may be in, on, or out-of-the-loop of decision-making.

192, TITLE: Aligned: A Platform-based Process for Alignment
AUTHORS: Ethan Shaotran ; Ido Pesok ; Sam Jones ; Emi Liu
CATEGORY: cs.CY [cs.CY, cs.AI]
HIGHLIGHT: We aim to set the foundation for a more trustworthy, public-facing approach to safety: a constitutional committee framework.

193, TITLE: MOSAIC: A Multi-Objective Optimization Framework for Sustainable Datacenter Management
AUTHORS: Sirui Qi ; Dejan Milojicic ; Cullen Bash ; Sudeep Pasricha
CATEGORY: cs.DC [cs.DC, cs.NE]
HIGHLIGHT: To co-optimize the energy cost, carbon emissions, and water footprint of datacenter operation from a global perspective, we propose a novel framework for multi-objective sustainable datacenter management (MOSAIC) that integrates adaptive local search with a collaborative decomposition-based evolutionary algorithm to intelligently manage geographical workload distribution and datacenter operations.

194, TITLE: Exploring Links Between Conversational Agent Design Challenges and Interdisciplinary Collaboration
AUTHORS: Malak Sadek ; C�line Mougenot
CATEGORY: cs.HC [cs.HC, cs.AI]
HIGHLIGHT: Focusing on a recent scoping review of the socio-technical challenges of CA creation, this opinion paper calls for an examination of the extent to which interdisciplinary collaboration (IDC) challenges might contribute towards socio-technical CA design challenges. The paper proposes a taxonomy of CA design challenges using IDC as a lens, and proposes practical strategies to overcome them which complement existing design principles.

195, TITLE: On The Computation of The Gaussian Rate-Distortion-Perception Function
AUTHORS: Giuseppe Serra ; Photios A. Stavrou ; Marios Kountouris
CATEGORY: cs.IT [cs.IT, cs.CV, cs.LG, cs.NI, math.IT]
HIGHLIGHT: In this paper, we study the computation of the rate-distortion-perception function (RDPF) for a multivariate Gaussian source under mean squared error (MSE) distortion and, respectively, Kullback-Leibler divergence, geometric Jensen-Shannon divergence, squared Hellinger distance, and squared Wasserstein-2 distance perception metrics.

196, TITLE: Joint User Pairing and Beamforming Design of Multi-STAR-RISs-Aided NOMA in The Indoor Environment Via Multi-Agent Reinforcement Learning
AUTHORS: Yu Min Park ; Yan Kyaw Tun ; Choong Seon Hong
CATEGORY: cs.IT [cs.IT, cs.AI, cs.NI, math.IT]
HIGHLIGHT: Motivated by the above, we study the joint user pairing for NOMA and beamforming design of Multi-STAR-RISs in an indoor environment.

197, TITLE: HEALNet -- Hybrid Multi-Modal Fusion for Heterogeneous Biomedical Data
AUTHORS: Konstantin Hemker ; Nikola Smidjievski ; Mateja Jamnik
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: This paper presents the Hybrid Early-fusion Attention Learning Network (HEALNet): a flexible multi-modal fusion architecture, which a) preserves modality-specific structural information, b) captures the cross-modal interactions and structural information in a shared latent space, c) can effectively handle missing modalities during training and inference, and d) enables intuitive model inspection by learning on the raw data input instead of opaque embeddings.

198, TITLE: DLAS: An Exploration and Assessment of The Deep Learning Acceleration Stack
AUTHORS: Perry Gibson ; Jos� Cano ; Elliot J. Crowley ; Amos Storkey ; Michael O'Boyle
CATEGORY: cs.LG [cs.LG, cs.CV, cs.PF]
HIGHLIGHT: Since such devices are where many emerging deep learning applications lie (e.g., drones, vision-based medical technology), significant bodies of work from both the machine learning and systems communities have attempted to provide optimizations to accelerate DNNs. To help unify these two perspectives, in this paper we combine machine learning and systems techniques within the Deep Learning Acceleration Stack (DLAS), and demonstrate how these layers can be tightly dependent on each other with an across-stack perturbation study.

199, TITLE: Confident Naturalness Explanation (CNE): A Framework to Explain and Assess Patterns Forming Naturalness
AUTHORS: Ahmed Emam ; Mohamed Farag ; Ribana Roscher
CATEGORY: cs.LG [cs.LG, cs.CV]
HIGHLIGHT: In this paper, we propose a novel framework called the Confident Naturalness Explanation (CNE) framework.

200, TITLE: Supported Trust Region Optimization for Offline Reinforcement Learning
AUTHORS: Yixiu Mao ; Hongchang Zhang ; Chen Chen ; Yi Xu ; Xiangyang Ji
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: We propose Supported Trust Region optimization (STR) which performs trust region policy optimization with the policy constrained within the support of the behavior policy, enjoying the less restrictive support constraint.

201, TITLE: Assessing The Robustness of Intelligence-Driven Reinforcement Learning
AUTHORS: Lorenzo Nodari ; Federico Cerutti
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CR]
HIGHLIGHT: This paper considers the problem of the robustness of intelligence-driven reinforcement learning based on reward machines.

202, TITLE: Scalable Federated Learning for Clients with Different Input Image Sizes and Numbers of Output Categories
AUTHORS: Shuhei Nitta ; Taiji Suzuki ; Albert Rodr�guez Mulet ; Atsushi Yaguchi ; Ryusuke Hirai
CATEGORY: cs.LG [cs.LG, cs.CR, cs.CV]
HIGHLIGHT: In this paper, we propose an effective federated learning method named ScalableFL, where the depths and widths of the local models for each client are adjusted according to the clients' input image size and the numbers of output categories.

203, TITLE: Learning Fair Division from Bandit Feedback
AUTHORS: Hakuei Yamada ; Junpei Komiyama ; Kenshi Abe ; Atsushi Iwasaki
CATEGORY: cs.LG [cs.LG, cs.AI, stat.ML]
HIGHLIGHT: We introduce wrapper algorithms utilizing \textit{dual averaging}, enabling gradual learning of both the type distribution of arriving items and agents' values through bandit feedback.

204, TITLE: Adversarial Imitation Learning On Aggregated Data
AUTHORS: Pierre Le Pelletier de Woillemont ; R�mi Labory ; Vincent Corruble
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: Such constraints make IRL approaches either not scalable or not usable on certain existing systems. In this work we propose an approach which removes these requirements through a dynamic, adaptive method called Adversarial Imitation Learning on Aggregated Data (AILAD).

205, TITLE: Adversarial Attacks to Reward Machine-based Reinforcement Learning
AUTHORS: Lorenzo Nodari
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CR]
HIGHLIGHT: With my thesis, I aim to provide the first analysis of the security of RM-based reinforcement learning techniques, with the hope of motivating further research in the field, and I propose and evaluate a novel class of attacks on RM-based techniques: blinding attacks.

206, TITLE: ACL2 Proofs of Nonlinear Inequalities with Imandra
AUTHORS: Grant Passmore
CATEGORY: cs.LO [cs.LO, cs.SC]
HIGHLIGHT: We present a proof-producing integration of ACL2 and Imandra for proving nonlinear inequalities.

207, TITLE: Verification of A Rust Implementation of Knuth's Dancing Links Using ACL2
AUTHORS: David S. Hardin
CATEGORY: cs.LO [cs.LO, cs.DS, cs.PL, F.3.1]
HIGHLIGHT: In this paper, we describe the RAR Rust subset, describe our improved prototype RAR toolchain, and detail the design and verification of a circular doubly-linked list data structure employing the Dancing Links optimization in RAR, with full proofs of functional correctness accomplished using the ACL2 theorem prover.

208, TITLE: Formal Verification of Zero-Knowledge Circuits
AUTHORS: Alessandro Coglio ; Eric McCarthy ; Eric W. Smith
CATEGORY: cs.LO [cs.LO, cs.CR, cs.SC]
HIGHLIGHT: Zero-knowledge circuits are sets of equality constraints over arithmetic expressions interpreted in a prime field; they are used to encode computations in cryptographic zero-knowledge proofs. We make the following contributions to the problem of ensuring that a circuit correctly encodes a computation: a formal framework for circuit correctness; an ACL2 library for prime fields; an ACL2 model of the existing R1CS (Rank-1 Constraint Systems) formalism to represent circuits, along with ACL2 and Axe tools to verify circuits of this form; a novel PFCS (Prime Field Constraint Systems) formalism to represent hierarchically structured circuits, along with an ACL2 model of it and ACL2 tools to verify circuits of this form in a compositional and scalable way; verification of circuits, ranging from simple to complex; and discovery of bugs and optimizations in existing zero-knowledge systems.

209, TITLE: SceneScore: Learning A Cost Function for Object Arrangement
AUTHORS: Ivan Kapelyukh ; Edward Johns
CATEGORY: cs.RO [cs.RO, cs.CV, cs.LG]
HIGHLIGHT: We learn the distribution of training arrangements offline using an energy-based model, solely from example images without requiring environment interaction or human supervision.

210, TITLE: ICRA Roboethics Challenge 2023: Intelligent Disobedience in An Elderly Care Home
AUTHORS: Sveta Paster ; Kantwon Rogers ; Gordon Briggs ; Peter Stone ; Reuth Mirsky
CATEGORY: cs.RO [cs.RO, cs.AI]
HIGHLIGHT: In this report, we propose to leverage the Intelligent Disobedience framework in order to give the robot the ability to perform a deliberation process over decisions with potential ethical implications.

211, TITLE: I Was Blind But Now I See: Implementing Vision-Enabled Dialogue in Social Robots
AUTHORS: Giulio Antonio Abbo ; Tony Belpaeme
CATEGORY: cs.RO [cs.RO, cs.AI, cs.HC]
HIGHLIGHT: This paper presents an initial implementation of a dialogue manager that leverages the latest progress in Large Language Models (e.g., GPT-4, IDEFICS) to enhance the traditional text-based prompts with real-time visual input.

212, TITLE: EyeLS: Shadow-Guided Instrument Landing System for Intraocular Target Approaching in Robotic Eye Surgery
AUTHORS: JUNJIE YANG et. al.
CATEGORY: cs.RO [cs.RO, cs.CV]
HIGHLIGHT: Meanwhile, due to 2D perspective projection and thus the loss of depth information, current image-based methods cannot effectively estimate the needle tip's trajectory towards both retinal and floating targets. To address this limitation, we propose to use the shadow positions of the target and the instrument tip to estimate their relative depth position and accordingly optimize the instrument tip's insertion trajectory until the tip approaches targets within iOCT's scanning area.

213, TITLE: AART: AI-Assisted Red-Teaming with Diverse Data Generation for New LLM-powered Applications
AUTHORS: Bhaktipriya Radharapu ; Kevin Robinson ; Lora Aroyo ; Preethi Lahoti
CATEGORY: cs.SE [cs.SE, cs.AI, cs.CL]
HIGHLIGHT: We introduce a novel approach for automated generation of adversarial evaluation datasets to test the safety of LLM generations on new downstream applications.

214, TITLE: Can MusicGen Create Training Data for MIR Tasks?
AUTHORS: Nadine Kroher ; Helena Cuesta ; Aggelos Pikrakis
CATEGORY: cs.SD [cs.SD, cs.AI, eess.AS]
HIGHLIGHT: We are investigating the broader concept of using AI-based generative music systems to generate training data for Music Information Retrieval (MIR) tasks.

215, TITLE: ExpM+NF: Differentially Private Machine Learning That Surpasses DPSGD
AUTHORS: Robert A. Bridges ; Vandy J. Tombs ; Christopher B. Stanley
CATEGORY: stat.ML [stat.ML, cs.AI, cs.CR, cs.LG, math.PR]
HIGHLIGHT: In this pioneering work we formulate ExpM+NF, a method for training machine learning (ML) on private data with pre-specified differentially privacy guarantee $\varepsilon>0, \delta=0$, by using the Exponential Mechanism (ExpM) and an auxiliary Normalizing Flow (NF).

216, TITLE: Deep Neural Network Identification of Limnonectes Species and New Class Detection Using Image Data
AUTHORS: LI XU et. al.
CATEGORY: stat.ML [stat.ML, cs.CV, cs.LG, eess.IV]
HIGHLIGHT: One such challenge is presented by species complexes in which the morphological similarities among the group members make it difficult to reliably identify known species and detect new ones. We address this challenge by developing new tools using the principles of machine learning to resolve two specific questions related to species complexes.

217, TITLE: Identification and Estimation for Nonignorable Missing Data: A Data Fusion Approach
AUTHORS: Zixiao Wang ; AmirEmad Ghassami ; Ilya Shpitser
CATEGORY: stat.ME [stat.ME, cs.AI]
HIGHLIGHT: In this paper, we take an alternative approach and introduce a method inspired by data fusion, where information in an MNAR dataset is augmented by information in an auxiliary dataset subject to missingness at random (MAR).

218, TITLE: Performance of Machine Learning Classification in Mammography Images Using BI-RADS
AUTHORS: Malitha Gunawardhana ; Norbert Zolek
CATEGORY: eess.IV [eess.IV, cs.CV]
HIGHLIGHT: This research aims to investigate the classification accuracy of various state-of-the-art image classification models across different categories of breast ultrasound images, as defined by the Breast Imaging Reporting and Data System (BI-RADS).

219, TITLE: Two-stage Joint Transductive and Inductive Learning for Nuclei Segmentation
AUTHORS: Hesham Ali ; Idriss Tondji ; Mennatullah Siam
CATEGORY: eess.IV [eess.IV, cs.CV, cs.LG]
HIGHLIGHT: In this study, we propose a novel approach to nuclei segmentation that leverages the available labelled and unlabelled data.

220, TITLE: Cross-dataset Domain Adaptation for The Classification COVID-19 Using Chest Computed Tomography Images
AUTHORS: Ridha Ouni ; Haikel Alhichri
CATEGORY: eess.IV [eess.IV, cs.CV, cs.LG]
HIGHLIGHT: To train the COVID19-DANet model, we propose a combined loss function that is composed of the standard cross-entropy loss for class discrimination and another entropy loss computed over the unlabelled target set only.

221, TITLE: Automated Volume Corrected Mitotic Index Calculation Through Annotation-Free Deep Learning Using Immunohistochemistry As Reference Standard
AUTHORS: JONAS AMMELING et. al.
CATEGORY: eess.IV [eess.IV, cs.CV, cs.LG]
HIGHLIGHT: In this work, we show that using a deep learning pipeline solely trained with an annotation-free, immunohistochemistry-based approach, provides accurate estimations of epithelial segmentation in canine breast carcinomas.

222, TITLE: Target-oriented Domain Adaptation for Infrared Image Super-Resolution
AUTHORS: Yongsong Huang ; Tomo Miyazaki ; Xiaofeng Liu ; Yafei Dong ; Shinichiro Omachi
CATEGORY: eess.IV [eess.IV, cs.CV]
HIGHLIGHT: However, this direct adaptation approach often becomes a double-edged sword, as it improves texture at the cost of introducing noise and blurring artifacts. To address these challenges, we propose the Target-oriented Domain Adaptation SRGAN (DASRGAN), an innovative framework specifically engineered for robust IR super-resolution model adaptation.
